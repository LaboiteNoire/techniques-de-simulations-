\documentclass[10pt,a4paper]{article}
\title{Techniques de Simulations}
\author{
  PRISCILLA, GOGUY\\
  \texttt{priscilla.goguy@etu.univ-lyon1.fr}
  \and
  MAHLÎ, REINETTE\\
  \texttt{mahli.reinette@etu.univ-lyon1.fr}
}
\date{13/10/2025}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[french]{babel}
\usepackage{graphicx}
\usepackage{hyperref}

\usepackage{listings}
\usepackage{xcolor}


\usepackage[many]{tcolorbox}
\usepackage{lipsum}
\usepackage{tikz}
\usetikzlibrary{automata, positioning, arrows}
\usepackage{pgfplots}
\usepackage{xcolor}
\usepackage{amsfonts}
\usepackage{dsfont}
\usepackage{xr-hyper} 
\usepackage{hyperref} 
\usepackage{algpseudocode}
\usepackage{algorithm}
\externaldocument[B-]{docB}[Annexe01.pdf]% <- full or relative path


% le préambule











% initialisation des couleurs
\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}
\definecolor{mymauve}{rgb}{0.58,0,0.82}






%block de code 
\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},   
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,         
    breaklines=true,                 
    captionpos=b,                    
    keepspaces=true,                 
    numbers=left,                    
    numbersep=5pt,                  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    tabsize=2
}

\lstset{style=mystyle}






%initialisation graphics
\tikzset{
->,
node distance = 2cm}



















% le corps du document






% le préambule
\begin{document}
%titre
\pagecolor{black!20}
\maketitle


\begin{center}
\textbf{\textit{M1 Actuariat}}

\textbf{\textit{ISFA}}

\includegraphics[width=4cm,height=2cm]{img1}

\href{https://github.com/LaboiteNoire/techniques-de-simulations-}{\includegraphics[width=1cm,height=1cm]{img2}}

\end{center}


\newpage

\phantom{aaaaaa}

\tableofcontents

\newpage

\part{Préambule}

\subsection{Avant-propos}
\begin{center}
\begin{minipage}[r]{0.1\textwidth}

\end{minipage}
\begin{minipage}[r]{0.8\textwidth}

Toutes les ressources utilisées seront présentes en annexes et sur le \href{https://github.com/LaboiteNoire/techniques-de-simulations-}{\textit{\textbf{repository}}} github ci-dessus.
Dans une optique de rigueur absolue, nous tenterons de commenter chaque partie de notre code et essaierons de justifier nos méthodes de simulation.

\end{minipage}
\end{center}


\subsection{Notations}

\begin{description}

\item[\bsc{* $\mathcal{P}(\textbf{X})$ : }]

\textit{Soit \textbf{$\Omega$}, un ensemble quelconque.}

\phantom{aaaaaaa} — \textit{On note $\mathcal{P}(\Omega)$, l'ensemble des parties de $\Omega$.}

\item[\bsc{* $\sigma$-Algèbre de $\Omega$ : }]

\textit{Soit $\Omega$, un ensemble quelconque. $\mathcal{A} \subseteq \mathcal{P}(\Omega)$ est dite $\sigma$-Algèbre de $\Omega$ si :}

\phantom{aaaaaaa} — \textit{$\Omega$ $\in \mathcal{A}$}

\phantom{aaaaaaa} — \textit{$\forall A \in \mathcal{A}$, $\bar{A} \in \mathcal{A}$}

\phantom{aaaaaaa} — \textit{$\forall (A_n)_{n \in \mathbb{N}} \in \mathcal{A}^{\mathbb{N}}$, $\bigcup_{n \in \mathbb{N}} A_n \in \mathcal{A}$}

\phantom{aaaaaaaaaaaaaaa} — \textit{On notera la « tribu borélienne » : $\mathbb{B}(\mathbb{R}^n)$ et \phantom{aaaaaaaaaaaaaa} $\lambda$ : « mesure de Lebesgue ».}


\item[\bsc{* $\mu$ Mesure de probabilité sur $(\Omega, \mathcal{A})$ : }]

\textit{Soit $(\Omega, \mathcal{A})$, un couple dit « espace probabilisable »}

\phantom{aaaaaaa} — \textit{$\mu : \mathcal{A} \longrightarrow [0,1]$}

\phantom{aaaaaaa} — \textit{$\mu(\emptyset) = 0$}

\phantom{aaaaaaa} — \textit{$\forall (A_n)_{n \in \mathbb{N}} \in \mathcal{A}^{\mathbb{N}}$, une famille disjointe, $\mu(\bigsqcup_{n \in \mathbb{N}} A_n)$ = \phantom{aaaaaaaaaaaaaa} $\sum_{n \in \mathbb{N}} \mu(A_n)$}

\phantom{aaaaaaaaaaaaaaa} — \textit{On notera la « probabilité historique » : $\mathbb{P}$.}

\phantom{aaaaaaaaaaaaaaa} — \textit{On notera $(\Omega, \mathcal{A}, \mu)$ : « espace probabilisé ».}


\item[\bsc{* \textbf{X}, une variable aléatoire sur $(\Omega, \mathcal{A}, \mathbb{P})$ : }]

\textit{Soit $(\Omega, \mathcal{A}, \mathbb{P})$ : « espace probabilisé »}

\phantom{aaaaaaa} — \textit{$(\textbf{E}, \mathcal{E})$ : « espace mesurable »}

\phantom{aaaaaaa} — \textit{\textbf{X : } $(\Omega, \mathcal{A}, \mathbb{P})$ $\longrightarrow$ $(\textbf{E}, \mathcal{E})$}

\phantom{aaaaaaaaaaaaaaa} — \textit{$\forall B \in \mathcal{E}$, $\mathbb{P}_{X}(B)$ = $\mathbb{P}(\{ \omega \in \Omega | X(\omega) \in \mathcal{B} \})$}


\item[\bsc{* \textbf{X}, une variable aléatoire continue sur $(\Omega, \mathcal{A}, \mathbb{P})$ : }]

\textit{Soit $(\Omega, \mathcal{A}, \mathbb{P})$ : « espace probabilisé »}

\phantom{aaaaaaa} — \textit{$(\mathbb{R}^n, \mathbb{B}(\mathbb{R}^n), \lambda)$ : « espace mesuré »}

\phantom{aaaaaaa} — \textit{\textbf{X : } $(\Omega, \mathcal{A}, \mathbb{P})$ $\longrightarrow$ $(\mathbb{R}^n, \mathbb{B}(\mathbb{R}^n), \lambda)$}

\phantom{aaaaaaa} — \textit{$\mathbb{P}_{X}$ << $\lambda$\footnotemark[1]}

\phantom{aaaaaaaaaaaaaaa} — \textit{$\exists ! \rho : (\mathbb{R}^n, \mathbb{B}(\mathbb{R}^n), \lambda) \longrightarrow \mathbb{R}^{+}$\footnotemark[2], mesurable, tel que :}

\[ \mathbb{P}_{X}(A) = \int_{A} \rho(x) \,dx \]

\end{description}


\footnotetext[1]{$\forall A \in \mathbb{B}(\mathbb{R}^n)$, tel que $\lambda(A) = 0 \Longrightarrow \mathbb{P}_{X}(A) = 0$.}

\footnotetext[2]{Dite : \textit{« densité de \textbf{X} ».}}








\begin{description}

\item[\bsc{* Espérance \textbf{E[X]}, de la variable aléatoire \textbf{X} : }]

\textit{Soit \textbf{X}, une variable aléatoire sur $(\Omega, \mathcal{A}, \mathbb{P})$}

\phantom{aaaaaaa} — \textit{On note} \textbf{E[X]}, \textit{« l'espérance de \textbf{X} ».}

\phantom{aaaaaaaaaaaaaaa} — \textit{Si \textbf{X}, est discrète\footnotemark[1], alors :}

\[ \textbf{E[X]} = \sum_{k \in X(\Omega)} k \mathbb{P}_{X}(\{ k \}) \]

\phantom{aaaaaaaaaaaaaaa} — \textit{Si \textbf{X}, est continue de densité $\rho$, alors :}

\[  \textbf{E[X]} = \int x\rho(x) \,dx \]



\item[\bsc{* Fonction de Répartition $F_X$, de la variable aléatoire \textbf{X} : }]

\textit{Soit \textbf{X}, une variable aléatoire sur $(\Omega, \mathcal{A}, \mathbb{P})$}

\phantom{aaaaaaa} — \textit{On note} $\forall x \in \mathbb{R}$, $F_X(x) = \mathbb{P}_{X}(]-\infty, x])$ \textit{« la fonction de \phantom{aaaaaaaaaaaaaaa} répartition de \textbf{X} ».}



\item[\bsc{* Espace $L^p(\Omega, \mathcal{A}, \mathbb{P})$ : }]

\textit{Soit $(\Omega, \mathcal{A}, \mathbb{P})$}

\phantom{aaaaaaa} — \textit{On note} $L^p(\Omega, \mathcal{A}, \mathbb{P})$, \textit{l'ensemble :}

\begin{displaymath}
\{ \textbf{X} \text{variable aléatoire sur } (\Omega, \mathcal{A}, \mathbb{P}) | \textbf{E[}|\textbf{X}|^p\textbf{]} < + \infty \}
\end{displaymath}


\item[\bsc{* Moment d'ordre $p$ $m_p$\textbf{[X]}, de la variable aléatoire \textbf{X} : }]

\textit{$\forall$ \textbf{X}, $\in L^p(\Omega, \mathcal{A}, \mathbb{P})$}

\phantom{aaaaaaa} — \textit{On note} $m_p$\textbf{[X]} = $\textbf{E[}\textbf{X}^p\textbf{]}$


\item[\bsc{* Moment centré d'ordre $p$ $\mu_p$\textbf{[X]}, de la variable aléatoire \textbf{X} : }]

\textit{$\forall$ \textbf{X}, $\in L^p(\Omega, \mathcal{A}, \mathbb{P})$}

\phantom{aaaaaaa} — \textit{On note} $\mu_p$\textbf{[X]} = $\textbf{E[}(\textbf{X} - \textbf{E[X]})^p\textbf{]}$


\item[\bsc{* Variantes du moment centré d'ordre $2$, de la variable aléatoire \textbf{X} : }]

\textit{$\forall$ \textbf{X}, $\in L^2(\Omega, \mathcal{A}, \mathbb{P})$}

\phantom{aaaaaaa} — \textit{On note} \textbf{V}$(X)$ = $\mu_2$\textbf{[X]}, \textit{la : « variance de \textbf{X} »} 

\phantom{aaaaaaa} — \textit{On note $\sigma_{X}$ = $\sqrt{V(X)}$, « l'écart-type de \textbf{X} »} 





\item[\bsc{* Covariance, entre les variables aléatoires \textbf{X} et \textbf{Y} : }]

\textit{$\forall ($\textbf{X}, \textbf{Y}$)$ $\in L^2(\Omega, \mathcal{A}, \mathbb{P})^2$}


\phantom{aaaaaaa} — \textit{On note} \textbf{Cov}$(X,Y)$ = $\textbf{E[} (\textbf{X} - \textbf{E[X]})(\textbf{Y} - \textbf{E[Y]}) \textbf{]} $, \textit{la : « covariance entre \textbf{X} et \textbf{Y} »} 

\phantom{aaaaaaaaaaaaaaa} — \textit{$(L^2(\Omega, \mathcal{A}, \mathbb{P})$, \textbf{Cov}$)$, forme un « espace euclidien »} 



\item[\bsc{* Coefficient de corrélation linéaire, entre les variables aléatoires \textbf{X} et \textbf{Y} : }]

\textit{$\forall ($\textbf{X}, \textbf{Y}$)$ $\in L^2(\Omega, \mathcal{A}, \mathbb{P})^2$}


\phantom{aaaaaaa} — \textit{On note} $\rho_{X,Y}$ = $\dfrac{\textbf{Cov(X,Y)}}{\sigma_{X} \sigma_{Y}}$, \textit{la : « le coefficient de corrélation linéaire entre \textbf{X} et \textbf{Y} »}



\end{description}

\footnotetext[1]{$\mathbb{P}_{X}$ << $\mu$, ou $\mu$ est : la « mesure de comptage ».}



\newpage
\subsection{Objets du Problème}
\begin{center}
\begin{minipage}[r]{0.1\textwidth}

\end{minipage}
\begin{minipage}[r]{0.8\textwidth}

On cherche à approximer la probabilité de ruine pour un modèle de théorie de la ruine en
assurance moto. On étudie deux cas : un cas où les assurés sont indépendants, et un cas où ils
sont corrélés à travers des conditions météo communes.

\end{minipage}
\end{center}



\begin{description}

\item[\bsc{* La variable aléatoire $X_{norm}$ sur $(\mathbb{R},\mathbb{B}(\mathbb{R}))$ : }]

\textit{$\forall (x_0,b,\sigma,\delta) \in \mathbb{R} \times (\mathbb{R}_{+}^{*})^3$}

\phantom{aaaaaaa} — \textit{On note} $X_{norm}$,

\phantom{aaaaaaaaaaaaaaa} — \textit{la variable aléatoire continue de densité : $f_{norm}$ :}

\[ \forall x \in \mathbb{R}, \text{  } f_{norm}(x) = \mathds{1}_{[0,b]}(x) \text{ } exp(-\dfrac{(x-x_0)^2}{2\sigma^2}) \text{ } (1 + cos(2 \pi \dfrac{x - x_0}{\delta} )^2) \]



\item[\bsc{* La variable aléatoire $X_{puissance}$ sur $(\mathbb{R},\mathbb{B}(\mathbb{R}))$ : }]

\textit{$\forall (a, \alpha) \in \mathbb{R}_{+}^{*} \times ]1 : + \infty [$}

\phantom{aaaaaaa} — \textit{On note} $X_{puissance}$,

\phantom{aaaaaaaaaaaaaaa} — \textit{la variable aléatoire continue de densité : $f_{puissance}$\footnotemark[1] :}

\[ \forall x \in \mathbb{R}, \text{  } f_{puissance}(x) = \mathds{1}_{[a,+\infty [}(x) \text{ } x^{-\alpha} \times \dfrac{\alpha - 1}{a^{1-\alpha}} \]



\item[\bsc{* La variable aléatoire $Z$ sur $(\Omega, \mathcal{A}, \mathbb{P})$ : }]

\textit{Soit $Z(\Omega)$ = $\mathbb{N}$ et $(p_n)_{n \in \mathbb{N}} \in [0,1]^{\mathbb{N}}$ et tel que : $\sum_{n \in \mathbb{N}} p_n$ = 1}

\phantom{aaaaaaa} — \textit{On note} $Z$,

\phantom{aaaaaaaaaaaaaaa} — \textit{la variable aléatoire discrète, dont les probabilités \phantom{aaaaaaaaaaaaaaaaaaa} respectives sont ainsi notées :}

\[ \forall n \in \mathbb{N}, \text{  } p_n = \mathbb{P}(Z = n) \]


\phantom{aaaaaaaaaaaaaaaaaa} — \textit{On désignera par la suite sa probabilité de la sorte : $\mathbb{P}_Z$}



\item[\bsc{* La variable aléatoire \textbf{X} sur $(\Omega, \mathcal{A}, \mathbb{P})$ : }]

\textit{Soit : $X_{norm}$, $X_{puissance}$, $Z$, des variables aléatoires mutuellement indépendantes, de lois (et ou de densités) respectives : $f_{norm}$, $f_{puissance}$ et $\mathbb{P}_Z$.}

\phantom{aaaaaaa} — \textit{On note} \textbf{X},

\phantom{aaaaaaaaaaaaaaa} — \textit{la variable aléatoire, définie de la sorte :}

\begin{displaymath}
\textbf{X} = 
\begin{cases}
	X_{norm} \text{ si Z = } 0 \\
	X_{puissance} \text{ si Z = } 1 \\
	Z \text{ sinon}
\end{cases}
\end{displaymath}





\end{description}




\footnotetext[1]{\href{run:./Annexe01.pdf}{This is my link}}


\href{file:ax01.pdf}{File keyword}

\href{run:./Annexe01.pdf}{Run keyword}

\href{run:foo.pdf}{Ouvrir l'annexe}

\href{run:./foo.tex}{test}

\href{run:./file.txt}{File.txt}



\section{Organisation du travail}
\begin{center}
\begin{minipage}[r]{0.1\textwidth}

\end{minipage}
\begin{minipage}[r]{0.8\textwidth}

Concernant l'organisation du travail, nous avons jugé nécessaire de mettre en place un
environnement permettant de partager facilement nos ébauches de code, l'avancée du rendu ainsi
que tout document utile au bon déroulement du projet. Pour cela, nous avons créé une page \href{https://github.com/LaboiteNoire/techniques-de-simulations-}{\textit{GitHub}}
dédiée.

\phantom{aaaaaaa}

La communication s'est faite principalement via un groupe de discussion sur les réseaux sociaux,
mais aussi lors d'échanges directs en classe ou au cours de réunions informelles consacrées à
l'avancement du projet.

\phantom{aaaaaaa}

Sur le plan technique, la première séance en classe a été consacrée à l'analyse de chaque question
afin de déterminer les méthodes de simulation à utiliser et les optimisations possibles. Suite à cela,
le rôle de \href{https://github.com/priscilla1269}{\textit{Priscilla}} a été plutôt dirigé vers les implémentations de techniques de simulations
« classiques » tandis que \href{https://github.com/LaboiteNoire}{\textit{Mahlî}} a lui été plutôt chargé du côté optimisation du code notamment :
\textit{table de Walker}, classes...

\phantom{aaaaaaa}

Cela dit, de nombreuses parties du code ont été développées conjointement : chacun ayant parfois
besoin des conseils, des idées ou de l'expertise de l'autre pour la mise en place de structures de
données adaptées et pour garantir la cohérence globale de l'implémentation.

\phantom{aaaaaaa}


Enfin, nous avons choisi de travailler sur un \textit{Notebook Python}, un format qui nous a semblé plus
pratique pour organiser notre code, structurer nos sections et ajouter facilement titres et
commentaires. Par souci de clarté et de rigueur, nous avons rédigé les démonstrations
mathématiques associées aux différentes étapes de nos algorithmes. Conscients que ces éléments ne
constituent pas le cœur de la matière, nous avons choisi de les regrouper dans une annexe, où elles
restent consultables si nécessaire.

\end{minipage}
\end{center}


\subsection{Notes d'updates}
\begin{center}
\begin{minipage}[r]{0.1\textwidth}

\end{minipage}
\begin{minipage}[r]{0.8\textwidth}

Une section que l'on supprimera lors du projet final, mais qui me permet de laisser quelques petits commentaires.

Autant je peux concevoir l'utilité de faire une section optimisée et non optimisée pour $X_{norm}$, autant (comme tu l'as très justement fait remarquer) je ne pense pas que cela soit pertinent pour $X_{puissance}$.

\textbf{Note a moi même : enlevé les tests en fin de page 5.}

\textbf{Note a moi même : italique sur les commentaires.}

\textbf{Note a moi même : enlevé les \_ de x\_0 dans les codeblock}

\textbf{Tenter la réduction de variance sur le modèle A}



\end{minipage}
\end{center}


\part{Aspects théoriques}
\section{modélisation}
\subsection{simulation de $X_{norm}$}
\subsection{Simulation de $X_{puissance}$}
\begin{displaymath}
\forall (a, \alpha) \in \mathbb{R}_{+}^{*} \times ]1 : + \infty [,
\end{displaymath}

\begin{center}
\begin{minipage}[r]{0.1\textwidth}

\end{minipage}
\begin{minipage}[r]{0.8\textwidth}
$X_{puissance}$ est une variable aléatoire continue, de densité $f_{puissance}$, tel que $\forall x \in \mathbb{R}$ :
\end{minipage}
\end{center}

\begin{displaymath}
f_{puissance}(x) = \mathds{1}_{[a,+\infty [}(x) \text{ } x^{-\alpha} \times \dfrac{\alpha - 1}{a^{1-\alpha}}
\end{displaymath}

\begin{center}
$\Updownarrow$
\end{center}

\begin{displaymath}
\forall t \in \mathbb{R}, F_{X_{puissance}}(t) = \mathbb{P}_{X_{puissance}}(]-\infty: t]) = \int_{-\infty}^{t} f_{puissance}(x) dx
\end{displaymath}

\begin{displaymath}
= \int_{-\infty}^{t} \mathds{1}_{[a,+\infty [}(x) \text{ } x^{-\alpha} \times \dfrac{\alpha - 1}{a^{1-\alpha}} dx
\end{displaymath}

\begin{displaymath}
= \mathds{1}_{[a,+\infty [}(t) \int_{a}^{t} \text{ } x^{-\alpha} \times \dfrac{\alpha - 1}{a^{1-\alpha}} dx = \mathds{1}_{[a,+\infty [}(t) \dfrac{\alpha - 1}{a^{1-\alpha}} \int_{a}^{t} \text{ } x^{-\alpha} dx
\end{displaymath}

\begin{displaymath}
= \mathds{1}_{[a,+\infty [}(t) \times \dfrac{\overbrace{\alpha - 1}^{= -(1 - \alpha)}}{a^{1-\alpha}} \times \left[ \dfrac{x^{1-\alpha}}{1-\alpha}\right]^{t}_{a} = - \mathds{1}_{[a,+\infty [}(t) \times \left[ \dfrac{x^{1-\alpha}}{a^{1-\alpha}}\right]^{t}_{a}
\end{displaymath}


\begin{displaymath}
= \mathds{1}_{[a,+\infty [}(t) \times \left[ \dfrac{x^{1-\alpha}}{a^{1-\alpha}}\right]^{a}_{t} = \mathds{1}_{[a,+\infty [}(t) \times \underbrace{\left[ x^{1-\alpha} \right]^{a}_{t}}_{= a^{1- \alpha} - t^{1- \alpha}} \times a^{\alpha - 1}
\end{displaymath}

\begin{displaymath}
= \mathds{1}_{[a,+\infty [}(t) \times \left(1- \left(\dfrac{t}{a}\right)^{1-\alpha} \right)
\end{displaymath}


\begin{center}
\begin{minipage}[r]{0.1\textwidth}

\end{minipage}
\begin{minipage}[r]{0.8\textwidth}
Posons $F_{X_{puissance}}^{\phantom{aa}-}$, la fonction définit de la sorte : $\forall y \in ]0,1[$ :

$F_{X_{puissance}}^{\phantom{aa}-}(y)$ = inf $\bigl\{ x \in \mathbb{R} \text{ | } y \leq \mathds{1}_{[a,+\infty [}(x) \times \left(1- \left(\dfrac{x}{a}\right)^{1-\alpha} \right) \bigr\}$
\end{minipage}
\end{center}



\begin{center}
\begin{minipage}[r]{0.1\textwidth}

\end{minipage}
\begin{minipage}[r]{0.8\textwidth}
Or $y \in ]0,1[ \iff 0 < y \iff \bigl\{ x \in \mathbb{R} \text{ | } y \leq \mathds{1}_{[a,+\infty [}(x) \times \left(1- \left(\dfrac{x}{a}\right)^{1-\alpha} \right) \bigr\}$ = $\bigl\{ x \in [a,+\infty [ \text{ | } y \leq \left(1- \left(\dfrac{x}{a}\right)^{1-\alpha} \right) \bigr\}$
\end{minipage}
\end{center}


\newpage

\begin{center}
\begin{minipage}[r]{0.1\textwidth}

\end{minipage}
\begin{minipage}[r]{0.8\textwidth}
inf$\bigl\{ x \in [a,+\infty [ \text{ | } y \leq 1- \left(\dfrac{x}{a}\right)^{1-\alpha} \bigr\}$ = inf$\bigl\{ x \in [a,+\infty [ \text{ | } y - 1 \leq - \left(\dfrac{x}{a}\right)^{1-\alpha} \bigr\}$ = sup$\bigl\{ x \in [a,+\infty [ \text{ | } \left(\dfrac{x}{a}\right)^{1-\alpha} \leq 1-y \bigr\}$ = sup$\bigl\{ x \in [a,+\infty [ \text{ | } \left(\dfrac{x}{a}\right) \leq \sqrt[1-\alpha]{1-y} \bigr\}$ = sup$\bigl\{ x \in [a,+\infty [ \text{ | } x \leq a\sqrt[1-\alpha]{1-y} \bigr\}$

\end{minipage}

Or $a\sqrt[1-\alpha]{1-y} = \dfrac{a}{\underbrace{\sqrt[\alpha-1]{1-y}}_{\in ]0,1[}} \in [a,+\infty [ \iff$

$F_{X_{puissance}}^{\phantom{aa}-}(y) = sup\bigl\{ x \in [a,+\infty [ \text{ | } x \leq a\sqrt[1-\alpha]{1-y} \bigr\}$ = $sup[a,a\sqrt[1-\alpha]{1-y} ]$ = \colorbox{black!30}{$a\sqrt[1-\alpha]{1-y}$}
\end{center}


\begin{center}
\begin{minipage}[r]{0.1\textwidth}

\end{minipage}
\begin{minipage}[r]{0.8\textwidth}
\hypertarget{ref1}{A l'aune de cette information nouvelle, nous pouvons établir notre modèle de la sorte} :  
\end{minipage}

\colorbox{black!30}{Soit $U \sim \mathcal{U}(]0,1[)$, $F_{X_{puissance}}^{\phantom{aa}-}(U) \sim X_{puissance}$}
\end{center}


\subsection{Conditions météorologiques et chaines de Markov $(H_k)_{k \in \mathbb{N}^{*}}$}

\begin{center}
\begin{minipage}[r]{0.1\textwidth}

\end{minipage}
\begin{minipage}[r]{0.8\textwidth}
L'on cherche à réaliser un modèle simulant des observations journalières de nos états météorologique.

Pour ce faire (et de façon assez naturelle, nous établirons une \textit{chaine de Markov} $(H_k)_{k \in \mathbb{N}^{*}}$, possédant les propriétés suivantes :

\end{minipage}
\end{center}





\begin{description}

\item[\bsc{* Processus Aléatoire $(H_k)_{k \in \mathbb{N}^{*}}$ : }]

\textit{Soit $(H_k)_{k \in \mathbb{N}^{*}} \in (E, \mathcal{A}, \mathbb{P})^{\mathbb{N}^{*}}$}

\phantom{aaaaaaa} — \textit{On note} $E = \{ \text{beau temps}, \text{temps couvert}, \text{pluie} \}$, dit \textit{« ensemble des états de $(H_k)_{k \in \mathbb{N}^{*}}$ »}.

\phantom{aaaaaaa} — \textit{On note} $\mu_0$, \textit{une mesure de probabilité sur $(E, \mathcal{A})$, dite « loi initiale de $(H_k)_{k \in \mathbb{N}^{*}}$ », tel que $(\mu_0(i))_{i \in [|1,3|]}$, est une permutation quelconque de $(1,0,0)$}.

\phantom{aaaaaaa} — \textit{On note} $Q \in M_3(\mathbb{R})$, \textit{une matrice stochastique, dite « matrice de transition de $(H_k)_{k \in \mathbb{N}^{*}}$ », tel que $\forall k \in \mathbb{N}^{*}$\footnotemark[1]} : 

\begin{displaymath}
\begin{bmatrix}
\mathbb{P}(H_{k+1} = 1 | H_k = 1) & \mathbb{P}(H_{k+1} = 2 | H_k = 1) & \mathbb{P}(H_{k+1} = 3 | H_k = 1)\\
\mathbb{P}(H_{k+1} = 1 | H_k = 2) & \mathbb{P}(H_{k+1} = 2 | H_k = 2) & \mathbb{P}(H_{k+1} = 3 | H_k = 2)\\
\mathbb{P}(H_{k+1} = 1 | H_k = 3) & \mathbb{P}(H_{k+1} = 2 | H_k = 3) & \mathbb{P}(H_{k+1} = 3 | H_k = 3)
\end{bmatrix}
\end{displaymath}


\end{description}




\begin{tcolorbox}[colback=black!30,colbacklower=black!20,colframe=black!20,rightrule=1mm,sidebyside,arc=0mm]


\begin{displaymath}
\begin{bmatrix}
p_{1,1} & p_{1,2} & p_{1,3}\\
p_{2,1} & p_{2,2} & p_{2,3}\\
p_{3,1} & p_{3,2} & p_{3,3}
\end{bmatrix}
\end{displaymath}


\tcblower
\begin{tikzpicture}[->,>=stealth',shorten >=1.4pt,auto,node distance=2cm,
                    thick,main node/.style={circle,draw,font=\sffamily\Large\bfseries}]

\node[main node] (1) {1};
\node[main node] (2) [below left of=1] {2};
\node[main node] (3) [below right of=1] {3};

  \path[every node/.style={font=\sffamily\small}]
    (1) edge node [left] {$p_{1,3}$} (3)
        edge [bend right] node[left] {$p_{1,2}$} (2)
        edge [loop above] node {$p_{1,1}$} (1)
    (2) edge node [right] {$p_{2,1}$} (1)
        edge node {$p_{2,3}$} (3)
        edge [loop left] node {$p_{2,2}$} (2)
        %edge [bend right] node[left] {$p_{2,1}$} (1)
    (3) edge node [bend right] {$p_{3,2}$} (2)
        edge [bend right] node[right] {$p_{3,1}$} (1)
        edge [loop right] node[right] {$p_{3,3}$} (3);
\end{tikzpicture}

\end{tcolorbox}



\footnotetext[1]{Pour des raisons évidentes de lisibilité nous confondrons les états \textit{« beau temps »}, \textit{« temps couvert »} et \textit{« pluie »} avec les états respectifs : $1$, $2$, et $3$.}



\begin{center}
\begin{minipage}[r]{0.1\textwidth}

\end{minipage}
\begin{minipage}[r]{0.8\textwidth}

\textbf{\textit{Commentaires sur l'implémentation de la chaine de markov}}

\phantom{aaaaaaa}

Une première approche a été de partitionner notre intervalle : $[0,1]$, de telle sorte à pouvoir simuler n'importe qu'elle variable aléatoire à support fini, à l'aide d'une loi uniforme.

Cette approche a le malheureux inconvénient d'avoir (parmi ses implémentations les moins naïves), une complexité de l'ordre de $o(nln(n))$\footnotemark[1].

\phantom{aaaaaaa}

Comparativement, une autre approche dite de \textit{« Table de Walker\footnotemark[2] »} (certes plus couteuse en temps d'initialisation), a le bon gout d'avoir une complexité de l'ordre : $o(1)$.

\phantom{aaaaaaa}

« La \textit{méthode optimale} serait-elle fonction des conditions initiales? ». La question ne manque pas pertinence, après tout notre loi a support fini ne possède que 3 états. En ce sens une \textit{« Table de Walker »} est-elle réellement une méthode plus optimale que notre \textit{approche naïve}?

\phantom{aaaaaaa}

A cela nous avons deux objections :

\phantom{aaaaaaa}

 — Pour $k \in \mathbb{N}$, la simulation d'un trajectoire a $k$ étapes, d'une \textit{chaine de Markov} à $n$ états serait de l'ordre de $o(knln(n))$ avec notre approche naïve et de $o(k)$ avec notre \textit{table de walker\footnotemark[3]}.
 
 — Simuler convenablement des conditions météorologique à l'aide d'une unique \textit{chaine de Markov} a 3 états, nous apparait fort improbable. Il est fort à parier que l'utilisateur sera amené à faire varier le nombre d'états : $n$. En ce sens, notre \textit{« modèle à Table de Walker »}, se montre beaucoup plus robuste que le précédent.
 
\phantom{aaaaaaa}

Ainsi, nous faisons donc le pari de la \textit{robustesse} et de \textit{l'adaptabilité} de notre modèle. 


\begin{center}
\begin{tikzpicture}[->,>=stealth',shorten >=1.4pt,auto,node distance=2cm,
                    thick,main node/.style={circle,draw,font=\sffamily\Large\bfseries}]

\node[main node] (1) {1};
\node[main node] (2) [below left of=1] {2};
\node[main node] (3) [below right of=1] {3};

  \path[every node/.style={font=\sffamily\small}]
    (1) edge node [left] {$p_{1,3}$} (3)
        edge [bend right] node[left] {$p_{1,2}$} (2)
        edge [loop above] node {$p_{1,1}$} (1)
    (2) edge node [right] {$p_{2,1}$} (1)
        edge node {$p_{2,3}$} (3)
        edge [loop left] node {$p_{2,2}$} (2)
        %edge [bend right] node[left] {$p_{2,1}$} (1)
    (3) edge node [bend right] {$p_{3,2}$} (2)
        edge [bend right] node[right] {$p_{3,1}$} (1)
        edge [loop right] node[right] {$p_{3,3}$} (3);
\end{tikzpicture}
\end{center}
 


\footnotetext[1]{$n = |E|$ et $E$, l'ensemble des états de la variable aléatoire a support fini.}

\footnotetext[2]{Vous trouverez en annexe la construction de notre \textit{« Table de Walker »}.}

\footnotetext[3]{Nous ne comptons pas l'étape d'initialisation, qui est dans le pire des cas d'ordre $o(n^2)$.}
\end{minipage}
\end{center}


\newpage
\subsection{Occurrences des sinistres (modèle A)}
\begin{center}
\begin{minipage}[r]{0.1\textwidth}

\end{minipage}
\begin{minipage}[r]{0.8\textwidth}
À chaque état de notre \textit{chaine de Markov} ($(1,2,3)$) est associé une valeur $\lambda_k \in \mathbb{R}_{+}^{*}$ (respectivement $(\lambda_1,\lambda_2,\lambda_3)$.

Notons $N \in \mathbb{N}$, la taille de notre portefeuille.

\textit{« On suppose que, pour chaque jour $k \in \mathbb{N}$, les dates des sinistres déclarés par l'assuré le jour $k$ suivent, conditionnellement à la valeur de $H_k$, un processus de Poisson d'intensité $\lambda_{H_k}$ »}.

\phantom{aaaaaaa}

Ainsi, nous définissons : 

\end{minipage}
\end{center}


\begin{description}

\item[\bsc{* Fonction}]

\textit{$\Delta(\omega) : $ : $\mathbb{R}_{+} \to \mathbb{R}_{+}$}

\begin{displaymath}
	\Delta : 
	\begin{cases}
		\text{$\mathbb{R}_{+} \to \mathbb{R}_{+}$}\\
		t \longmapsto \mathds{1}_{[0,365]}(t) \lambda_{H_{\lfloor t \rfloor}}
	\end{cases}
	.
\end{displaymath}


\item[\bsc{* Fonction}]

\textit{$\mu(\omega) : $ : $\mathbb{R}_{+} \to \mathbb{R}_{+}$}

\begin{displaymath}
\mu(t) = \int_{0}^{t} \Delta(x) dx = \int_{0}^{t} \mathds{1}_{[0,365]}(x) \lambda_{H_{\lfloor x \rfloor}} dx
\end{displaymath}


\item[\bsc{* Suite de processus de poisson in-homogène mélange : }]

\textit{$(R_t^{(k)})_{k \in [|1,N|]}$}

\phantom{aaaaaaa} — \textit{$(R_t^{(k)})_{k \in [|1,N|]}$, une suite de processus de poisson in-homogène mélange indépendant.}

\phantom{aaaaaaa} — \textit{$\forall (k,t) \in [|1,N|] \times \mathbb{R}_{+}$,  $R_t^{(k)} \sim P(\mu(t))$, le  processus de poisson in-homogène mélange indépendants représentant les temps d'occurrence des sinistres du contrat $k$.}

\begin{displaymath}
\forall t \in \mathbb{R}_{+} \text{, } R_t = \sum_{i=1}^{N} R_t^{(i)}
\end{displaymath}

\end{description}


\begin{displaymath}
\forall t \in [0,365] \text{, } \mu(t) = \int_{0}^{t} \Delta(x) dx = \int_{0}^{t} \mathds{1}_{[0,365]}(x) \lambda_{H_{\lfloor x \rfloor}} dx = \int_{0}^{t} \lambda_{H_{\lfloor x \rfloor}} dx
\end{displaymath}

\begin{displaymath}
= \int_{0}^{1} \lambda_{H_{\lfloor x \rfloor}} dx + \int_{1}^{2} \lambda_{H_{\lfloor x \rfloor}} dx + ... + \int_{\lfloor t \rfloor - 1}^{\lfloor t \rfloor} \lambda_{H_{\lfloor x \rfloor}} dx + \int_{\lfloor t \rfloor}^{t} \lambda_{H_{\lfloor x \rfloor}} dx
\end{displaymath}

\begin{displaymath}
= \int_{0}^{1} \lambda_{H_{0}} dx + \int_{1}^{2} \lambda_{H_{1}} dx + ... + \int_{\lfloor t \rfloor - 1}^{\lfloor t \rfloor} \lambda_{H_{\lfloor t \rfloor - 1}} dx + \int_{\lfloor t \rfloor}^{t} \lambda_{H_{\lfloor t \rfloor}} dx
\end{displaymath}

\begin{displaymath}
= \lambda_{H_{0}} + \lambda_{H_{1}} + ... + \lambda_{H_{\lfloor t \rfloor - 1}} + \int_{\lfloor t \rfloor}^{t} \lambda_{H_{\lfloor t \rfloor}} dx
\end{displaymath}


\begin{displaymath}
= \sum_{i=0}^{\lfloor t \rfloor - 1} \lambda_{H_{i}} + \lambda_{H_{\lfloor t \rfloor}} \times (t - \lfloor t \rfloor)
\end{displaymath}


\newpage
\begin{displaymath}
\forall t \in \mathbb{R}_{+} \text{, } R_t = \sum_{i=1}^{N} \underbrace{R_t^{(i)}}_{\sim P(\mu(t))} \sim P(N\times \mu(t)) \iff
\end{displaymath}

\begin{displaymath}
R_t \text{est un processus de poisson in-homogène mélange d'intensité : } \Delta^{*} = N \Delta
\end{displaymath}


\begin{center}
\begin{minipage}[r]{0.1\textwidth}

\end{minipage}
\begin{minipage}[r]{0.8\textwidth}
Il nous suffit donc de simuler une seule loi de poisson pour nos $N$ contrats.
\end{minipage}

Posons donc : $\forall t \in \mathbb{R}$, \colorbox{black!30}{$\Delta^{*}(t) = N \mathds{1}_{[0,365]}(t) \lambda_{H_{\lfloor t \rfloor}}$.}
\end{center}


\begin{center}
\begin{minipage}[r]{0.1\textwidth}

\end{minipage}
\begin{minipage}[r]{0.8\textwidth}
Cette définition a le bon gout d'être aisément majorable par une formule simple : $\theta = N \times max(\lambda_1,\lambda_2,\lambda_3)$.
\end{minipage}
\end{center}




\begin{tcolorbox}[colback=black!30,colbacklower=black!20,colframe=black!20,rightrule=1mm,arc=0mm]


\begin{center}
Montrons nous toutefois sceptiques vis a vis de notre modèle.

Partir du postulat que nos assurés partage une météo commune, n'est pas une idée totalement absurde dans l'absolue, mais reste néanmoins extrêmement discutable dans les faits. Il faudrait pour cela faire l'hypothèse que nos assurés vivent sur un même territoire et que ce territoire est assez restreint pour que sa météo reste uniforme et uni-variée.

Le modèle B, fait l'hypothèse inverse (qui est tout aussi discutable).

Notre modèle A repose sur une autre hypothèse : que l'état de la météo au jour $n$, dépends uniquement de l'état de la météo au jours $n-1$.

Nous n'expliqueront pas a quel point cette hypothèse est absurde, néanmoins la valeur d'un modèle ne se limite pas a la somme de la valeur de ses axiomes (ex : les modèles de base de la micro-économie).
\end{center}

\end{tcolorbox}


\begin{center}
\includegraphics[width=12cm,height=3.4cm]{img6}
\end{center}









\newpage
\subsection{Probabilité de Ruine Annuelle (modèle A)}

\begin{description}

\item[\bsc{* Modèle de Réserves : }]

\textit{$\forall (N, u, c) \in \mathbb{N} \times \mathbb{R}^2$, $(T_i)_{i \in \mathbb{N}^{*}}$, une suite de variables aléatoires identiquement distribuées et croissantes.}

\phantom{aaaaaaa} — \textit{On note $N$, la taille de notre portefeuille.}

\phantom{aaaaaaa} — \textit{On note $u$, l'investissement initial et individuel par assurés.}

\phantom{aaaaaaa} — \textit{On note $c$, le taux de prime par assuré et par unité de temps.}

\phantom{aaaaaaa} — \textit{On note $(T_i)_{i \in \mathbb{N}^{*}}$, la suite des dates de sinistres déclarés (de tous les assurés). La suite est par ailleurs ordonnée.}

\phantom{aaaaaaaaaaaaaaa} — \textit{$\forall t \in \mathbb{R}^{+} :$}

\[ R_t = Nu + Nct - \sum_{i=1}^{+ \infty} \mathds{1}_{[0,t]}(T_i) \text{ } X_i \]


\item[\bsc{* Partition $A$ de $[0,365]$ : }]

\textit{$\forall k \in \mathbb{N}$.}

\phantom{aaaaaaa} — \textit{$n = inf \bigl\{ k \in \mathbb{N}^{*} | T_k \in [0,365] \bigr\}$}

\begin{displaymath}
A_k =
\begin{cases}
	[0,T_1[ \text{ , si k = } 0 \\
	[T_k, T_{k+1}[ \text{ , si } k \in [|1, n-1 |] \\
	[T_n,365] \text{ , si } k = n \\
	\emptyset \text{ , sinon }
\end{cases}
\end{displaymath}


\phantom{aaaaaaaaaaaaaaa} — \textit{$(A_k)_{k \in \mathbb{N}}$ forme une partition de $[0,365]$.}
\end{description}



\begin{center}
\begin{minipage}[r]{0.1\textwidth}

\end{minipage}
\begin{minipage}[r]{0.8\textwidth}
Soit : $\forall \omega \in \Omega$, $R_t(\omega)$, est bien définie sur $[0,365]$.
On a donc : 
\end{minipage}
\end{center}

\[ \min_{t \in [0,365]} R_t(\omega) = \min_{k \in [|0,n|]} (\min_{t \in A_k} R_t(\omega)) \]


\begin{center}
\begin{minipage}[r]{0.1\textwidth}

\end{minipage}
\begin{minipage}[r]{0.8\textwidth}
Cette partition ($(A_k)_{k \in \mathbb{N}}$), nous permet d'exprimer tout minimum local ($\min_{t \in A_k} R_t(\omega)$), sous une forme explicite (plus ou moins simple) : 
\end{minipage}
\end{center}

\[ \forall (k,t) \in \mathbb{N} \times A_k, \text{ } R_t(\omega) = Nu + Nct - \sum_{i=1}^{+ \infty} \mathds{1}_{[0,t]}(T_i(\omega)) \text{ } X_i(\omega) \]

\[ = Nu + Nct - \sum_{i=1}^{k} X_i(\omega) \iff \]

\begin{displaymath}
\min_{t \in A_k} R_t(\omega) =
\begin{cases}
	Nu \text{ , si k = } 0 \\
	Nu + NcT_k(\omega) - \sum_{i=1}^{k} X_i(\omega) \text{ , si } k \in [|1, n |]
\end{cases}
\end{displaymath}



\begin{center}
\begin{minipage}[r]{0.1\textwidth}

\end{minipage}
\begin{minipage}[r]{0.8\textwidth}
, car par soucis de réalisme l'on considère que $c \in \mathbb{R}_{+}^{*}.$
\end{minipage}
\end{center}




\begin{center}
\begin{minipage}[r]{0.1\textwidth}

\end{minipage}
\begin{minipage}[r]{0.8\textwidth}
Nous avons donc le résultat suivant : 
\end{minipage}
\end{center}

\[ \min_{t \in [0,365]} R_t(\omega) = Nu + \min_{k \in [|1,n|]} (NcT_k(\omega) - \sum_{i=1}^{k} X_i(\omega)) \]

\[ = Nu + \min_{k \in [|1,n|]} (\sum_{i=1}^{k} (\dfrac{NcT_k(\omega)}{k} - X_i(\omega))) \]


\begin{center}
\begin{minipage}[r]{0.1\textwidth}

\end{minipage}
\begin{minipage}[r]{0.8\textwidth}
Ce résultat nous permet de caractériser l'événement suivant :
\end{minipage}
\end{center}


\[ \left( \min_{t \in [0,365]} R_t < 0 \right) = \left( \exists k \in [|1,n|] \text{ , tel que : } \sum_{i=1}^{k} (\dfrac{NcT_k}{k} - X_i) < -Nu \right) \]

\begin{center}
\begin{minipage}[r]{0.1\textwidth}

\end{minipage}
\begin{minipage}[r]{0.8\textwidth}
Il nous suffirait donc de procédé pas à pas.
\end{minipage}
\end{center}

\[ \text{Soit } (V_j)_{j \in \mathbb{N}} \text{, une suite de v.a.i.i.d., tel que } \forall j \in \mathbb{N}, \]


\hypertarget{ref2}{\[ V_j \sim \mathbb{B}(\mathbb{P} \left( \exists k \in [|1,n|] \text{ , tel que : } \sum_{i=1}^{k} (\dfrac{NcT_k}{k} - X_i) < -Nu \right) )\]}



\begin{center}
\begin{minipage}[r]{0.1\textwidth}

\end{minipage}
\begin{minipage}[r]{0.8\textwidth}
Par loi des grands nombres nous avons :
\end{minipage}
\end{center}



\[ \dfrac{1}{p} \sum_{j=1}^{p} V_j \underset{p \to +\infty}{\overset{p.s.}{\longrightarrow}} \mathbb{P}\left( \min_{t \in [0,365]} R_t < 0 \right) \]



\begin{center}
\begin{minipage}[r]{0.1\textwidth}

\end{minipage}
\begin{minipage}[r]{0.8\textwidth}
Le fait que nous ayons deux sommes (d'une part $\sum_{i=1}^{k} (\dfrac{NcT_k}{k} - X_i)$ et d'une autre $\sum_{j=1}^{p} V_j$ ), rend le problème parallélisable.
\end{minipage}
\end{center}


\begin{center}
\includegraphics[width=12cm,height=3.4cm]{img7}
\end{center}


\phantom{aaaaaaa}

\phantom{aaaaaaa}


\begin{center}
\begin{minipage}[r]{0.1\textwidth}

\end{minipage}
\begin{minipage}[r]{0.8\textwidth}

\textbf{\textit{Réduction de variance}}

\phantom{aaaaaaa}

\end{minipage}
\end{center}









\subsection{Occurrences des sinistres (modèle B)}
\subsection{Probabilité de Ruine Annuelle (modèle B)}





\newpage
\part{Aspects Programmation}
\section{Commentaires sur les techniques de programmation}
%\pagecolor{blue!20}
\pagecolor{black!30}



\subsection{Dépendances}
\begin{center}
\begin{minipage}[r]{0.1\textwidth}
\textcolor{black!60}{1}

\textcolor{black!60}{2}

\textcolor{black!60}{3}

\textcolor{black!60}{4}

\textcolor{black!60}{5}

\textcolor{black!60}{6}
\end{minipage}
\begin{minipage}[r]{0.82\textwidth}

\textcolor{teal}{import} random as rd

\textcolor{teal}{import} numpy as np

\textcolor{teal}{import} matplotlib.pyplot as plt \textcolor{mymauve}{\# graphics}

\textcolor{teal}{import} plotly.express as px \textcolor{mymauve}{\# graphics}

\textcolor{teal}{import} threading \textcolor{mymauve}{\# parallélisation}

\textcolor{teal}{import} bisect \textcolor{mymauve}{\# insertion dans une liste triée}

\end{minipage}
\end{center}



\subsection{$X_{norm}$}
\begin{center}
\begin{minipage}[r]{0.1\textwidth}

\end{minipage}
\begin{minipage}[r]{0.8\textwidth}
$f_{norm}$, est une fonction complexe et au vue de sa forme, il parait fort peu probable de trouver une forme explicite à son intégrale (sur un intervalle quelconque).

\phantom{aaaaaaa}

Une méthode similaire à celle de \textit{Box-Muller}, a brièvement été évoquée, sans succès.

\phantom{aaaaaaa}

« La méthode du rejet semble donc s'imposer d'elle même ? ». Il s'agit encore d'une question d'arbitrage.
Faut-il faire le choix de la meilleure des complexités, en approchant la fonction de répartition de  $X_{norm}$, par des formules explicites incorrectes, ou préférer à la complexité une juste représentation de sa loi?

\phantom{aaaaaaa}

Nous avons de prime abord opté pour l'implémentation d'une méthode de rejet dont le support serait la loi uniforme $U([0,b])$\footnotemark[1].

De plus, la majoration suivante, apparait de façon quasi-immédiate : $f_{norm} \leq 2$.



\footnotetext[1]{La densité $f_{norm}$ étant nulle en dehors de l'intervalle $[0,b]$, il est naturel d'utiliser comme loi de proposition une uniforme sur ce même intervalle.}
\end{minipage}
\end{center}


\begin{algorithm}
\caption{Algorithme de rejet}
\begin{algorithmic}[1]
\State $i \gets True$
\While{$i$}
\State $U \gets \sim U([0,b])$
\State $Y \gets \sim U([0,2])$
\If {$Y \leq f_{norm}(U)$}
\textbf{return } $U$
\EndIf
\EndWhile
\end{algorithmic}
\end{algorithm}

\newpage
\textbf{Première approche :}




\begin{center}
\begin{minipage}[r]{0.1\textwidth}
\textcolor{black!60}{1}

\textcolor{black!60}{2}

\textcolor{black!60}{3}

\end{minipage}
\begin{minipage}[r]{0.88\textwidth}

\textcolor{teal}{def} \textcolor{blue}{f\_norm}(x : \textcolor{codegreen}{float}, x\_0 : \textcolor{codegreen}{float}, b : \textcolor{codegreen}{float}, sigma : \textcolor{codegreen}{float}, delta : \textcolor{codegreen}{float}):

\phantom{aaaa}ind = (x \textcolor{mymauve}{>=} \textcolor{codegreen}{0}) \textcolor{mymauve}{\&} (x \textcolor{mymauve}{<=} b)

\phantom{aaaa}\textcolor{teal}{return} ind\textcolor{mymauve}{*}(np.\textcolor{teal}{exp}(-((x - x0)\textcolor{mymauve}{**}\textcolor{codegreen}{2}) \textcolor{mymauve}{/} (\textcolor{codegreen}{2} \textcolor{mymauve}{*} sigma\textcolor{mymauve}{**}\textcolor{codegreen}{2})) * (\textcolor{codegreen}{1} + np.\textcolor{teal}{cos}(\textcolor{codegreen}{2}\textcolor{mymauve}{*}np.\textcolor{teal}{pi}\textcolor{mymauve}{*}(x - x0)\textcolor{mymauve}{/}delta)\textcolor{mymauve}{**}\textcolor{codegreen}{2}))

\end{minipage}
\end{center}







\begin{center}
\begin{minipage}[r]{0.1\textwidth}
\textcolor{black!60}{1}

\phantom{aa}

\textcolor{black!60}{2}

\textcolor{black!60}{3}

\textcolor{black!60}{4}

\textcolor{black!60}{5}

\textcolor{black!60}{6}

\textcolor{black!60}{7}

\textcolor{black!60}{8}

\end{minipage}
\begin{minipage}[r]{0.88\textwidth}

\textcolor{teal}{def} \textcolor{blue}{echantillon\_f\_norm}(x\_0 : \textcolor{codegreen}{float}, b : \textcolor{codegreen}{float}, sigma : \textcolor{codegreen}{float}, delta : \textcolor{codegreen}{float}, n : \textcolor{codegreen}{int}):

\phantom{aaaa}res \textcolor{mymauve}{=} $[]$

\phantom{aaaa}\textcolor{teal}{while len}(res) \textcolor{mymauve}{<} n:

\phantom{aaaaaaaa}X \textcolor{mymauve}{=} np.\textcolor{teal}{random.uniform}(\textcolor{codegreen}{0}, b) \textcolor{mymauve}{\# \textit{f\_norm est nulle sur [b,inf]}}

\phantom{aaaaaaaa}Y \textcolor{mymauve}{=} np.\textcolor{teal}{random.uniform}(\textcolor{codegreen}{0}, M)

\phantom{aaaaaaaa}\textcolor{teal}{if} Y \textcolor{mymauve}{<=} f\_norm(X,x0,b,sigma,delta):

\phantom{aaaaaaaaaaaa}res.\textcolor{teal}{append}(X) \textcolor{mymauve}{\# \textit{condition d'acceptation}}

\phantom{aaaa}\textcolor{teal}{return} res
\end{minipage}
\end{center}

\phantom{aaaa}

\textbf{Deuxième approche :}
\begin{center}
\begin{minipage}[r]{0.1\textwidth}

\end{minipage}
\begin{minipage}[r]{0.8\textwidth}
Conscients que
cette méthode n'est sans doute pas la plus efficace au vue de la forme de $f_{norm}$ nous avons donc opté pour une seconde méthode.

La loi $\mathbb{P}_{norm}$ étant très proche d'une loi normale, nous avons pensé à faire une méthode de rejet vis à vis de cette dernière.

\phantom{aaaa}

Nous avons donc majoré le rapport $\dfrac{f_{norm}}{g}$, avec $g$ la densité d'une loi normale.

Cela garantit une meilleure efficacité du rejet : la probabilité d'acceptation augmente, et donc le
nombre moyen d'itérations\footnotemark[1] pour accepter un point diminue.

\footnotetext[1]{Qui fut précédemment de l'ordre de $2b$.}
\end{minipage}
\end{center}




\begin{algorithm}
\caption{Algorithme de rejet}
\begin{algorithmic}[1]
\State $i \gets True$
\While{$i$}
\State $U \gets \sim $ loi de densité $g$
\State $Y \gets \sim U([0,M])$
\If {$Y \times g(U) \leq f(U)$}
\textbf{return } $U$
\EndIf
\EndWhile
\end{algorithmic}
\end{algorithm}

\textbf{Nouvelle approche :}



\begin{center}
\begin{minipage}[r]{0.1\textwidth}
\textcolor{black!60}{1}

\textcolor{black!60}{2}

\end{minipage}
\begin{minipage}[r]{0.88\textwidth}

\textcolor{teal}{def} \textcolor{blue}{g}(x : \textcolor{codegreen}{float}, x\_0 : \textcolor{codegreen}{float}, sigma : \textcolor{codegreen}{float}):

\phantom{aaaa}ind = (x \textcolor{mymauve}{>=} \textcolor{codegreen}{0}) \textcolor{mymauve}{\&} (x \textcolor{mymauve}{<=} b)

\phantom{aaaa}\textcolor{teal}{return} (\textcolor{codegreen}{1} \textcolor{mymauve}{/} (np.\textcolor{teal}{sqrt}(\textcolor{codegreen}{2}\textcolor{mymauve}{*}np.\textcolor{teal}{pi})\textcolor{mymauve}{*}sigma)) \textcolor{mymauve}{*} np.\textcolor{teal}{exp}(-((x - x0)\textcolor{mymauve}{**}\textcolor{codegreen}{2}) \textcolor{mymauve}{/} (\textcolor{codegreen}{2} \textcolor{mymauve}{*} sigma\textcolor{mymauve}{**}\textcolor{codegreen}{2}))

\end{minipage}
\end{center}





\begin{center}
\begin{minipage}[r]{0.1\textwidth}
\textcolor{black!60}{1}

\phantom{aa}

\textcolor{black!60}{2}

\textcolor{black!60}{3}

\textcolor{black!60}{4}

\textcolor{black!60}{5}

\textcolor{black!60}{6}

\textcolor{black!60}{7}

\textcolor{black!60}{8}

\textcolor{black!60}{9}

\end{minipage}
\begin{minipage}[r]{0.88\textwidth}

\textcolor{teal}{def} \textcolor{blue}{echantillon\_f\_norm\_opt}(x\_0 : \textcolor{codegreen}{float}, b : \textcolor{codegreen}{float}, sigma : \textcolor{codegreen}{float}, delta : \textcolor{codegreen}{float}, n : \textcolor{codegreen}{int}):

\phantom{aaaa}M \textcolor{mymauve}{=} \textcolor{codegreen}{2}\textcolor{mymauve}{*}np.\textcolor{teal}{sqrt}(\textcolor{codegreen}{2}\textcolor{mymauve}{*}np.\textcolor{teal}{pi})\textcolor{mymauve}{*}sigma

\phantom{aaaa}res \textcolor{mymauve}{=} $[]$

\phantom{aaaa}\textcolor{teal}{while len}(res) \textcolor{mymauve}{<} n:

\phantom{aaaaaaaa}X \textcolor{mymauve}{=} np.\textcolor{teal}{random.normal}(\textcolor{codegreen}{x0}, sigma)

\phantom{aaaaaaaa}Y \textcolor{mymauve}{=} np.\textcolor{teal}{random.uniform}(\textcolor{codegreen}{0}, M)

\phantom{aaaaaaaa}\textcolor{teal}{if} Y\textcolor{mymauve}{*}g(X,x0,sigma) <= f\_norm(X,x0,b,sigma,delta):

\phantom{aaaaaaaaaaaa}res.\textcolor{teal}{append}(X) \textcolor{mymauve}{\# \textit{condition d'acceptation}}

\phantom{aaaa}\textcolor{teal}{return} res
\end{minipage}
\end{center}





\subsection{$X_{puissance}$}
\begin{center}
\begin{minipage}[r]{0.1\textwidth}

\end{minipage}
\begin{minipage}[r]{0.8\textwidth}
Cette partie sera relativement succincte. Les causes de cette concision sont doubles : 

\phantom{aaaa}— Premièrement car tous les calculs ont déjà été traités dans la partie \hyperlink{ref1}{\textcolor{blue}{\textbf{\textit{Modélisation}}}}.
 
\phantom{aaaa}— Deuxièmement car le code qui y est associé est lui même relativement succint.

La complexité est ici en temps constant et nous voyons mal comment optimiser ce code sans passer par un \textit{interfacage c++}.
\end{minipage}
\end{center}



\textbf{Le code dans toute sa beauté fonctionnelle :}

\begin{center}
\begin{minipage}[r]{0.1\textwidth}
\textcolor{black!60}{1}

\textcolor{black!60}{2}

\end{minipage}
\begin{minipage}[r]{0.88\textwidth}

\textcolor{teal}{def} \textcolor{blue}{run\_loi\_de\_puissance}(a : \textcolor{codegreen}{float}, alpha : \textcolor{codegreen}{float}):

\phantom{aaaa}\textcolor{teal}{return} a\textcolor{mymauve}{*}(\textcolor{codegreen}{1} \textcolor{mymauve}{-} rd.\textcolor{teal}{random}())\textcolor{mymauve}{**}(\textcolor{codegreen}{1}\textcolor{mymauve}{/}(\textcolor{codegreen}{1}\textcolor{mymauve}{-}alpha))
\end{minipage}
\end{center}



\subsection{$Z$}
\begin{center}
\begin{minipage}[r]{0.1\textwidth}

\end{minipage}
\begin{minipage}[r]{0.8\textwidth}
$Z$ suit une loi de probabilité qui nous est inconnue, il n'existe donc aucune \textit{implémentation optimale} de cette dernière (que ce soit en terme de code et ou de complexité).

Il parait assez évident, qu'une approche par \textit{« inversion de la fonction de répartition »}, serait complètement hors propos.

A terme, nous avons finalement opter pour une méthode de rejet (bien que la \textit{« table de walker »} nous ait un instant effleurer l'esprit).

\phantom{aa}

Par la suite nous restructurons notre code pour le rendre moins sensible a la casse.

\phantom{aa}

La programmation orientée objet nous offre un paradigme bien plus adaptable et robuste au changement de paramètres.

Elle structure notre code et lui offre une architecture bien plus \textit{arborescente}.
\end{minipage}
\end{center}



\subsection{$X$}



\begin{center}
\begin{minipage}[r]{0.1\textwidth}
\textcolor{black!60}{1}

\textcolor{black!60}{2}

\phantom{aa}

\phantom{aa}

\phantom{aa}

\phantom{aa}

\phantom{aa}

\phantom{aa}

\textcolor{black!60}{3}

\textcolor{black!60}{4}

\textcolor{black!60}{5}

\textcolor{black!60}{6}

\textcolor{black!60}{7}

\textcolor{black!60}{8}

\textcolor{black!60}{9}

\textcolor{black!60}{10}

\textcolor{black!60}{11}

\textcolor{black!60}{12}

\textcolor{black!60}{13}

\textcolor{black!60}{14}

\textcolor{black!60}{15}

\textcolor{black!60}{16}

\phantom{aa}

\textcolor{black!60}{17}

\textcolor{black!60}{18}

\textcolor{black!60}{19}

\textcolor{black!60}{20}

\textcolor{black!60}{21}

\phantom{aa}

\phantom{aa}

\textcolor{black!60}{22}

\textcolor{black!60}{23}

\phantom{aa}

\phantom{aa}

\end{minipage}
\begin{minipage}[r]{0.88\textwidth}

\textcolor{teal}{class} \textcolor{blue}{Settings}():

\phantom{aaaa}\textcolor{teal}{def} \textcolor{blue}{\_\_init\_\_}(self, x\_0\textcolor{mymauve}{=}np.\textcolor{blue}{random.uniform}(\textcolor{codegreen}{0},\textcolor{codegreen}{1}), b\textcolor{mymauve}{=}np.\textcolor{blue}{random.uniform}(\textcolor{codegreen}{0.1},\textcolor{codegreen}{1}), sigma\textcolor{mymauve}{=}np.\textcolor{blue}{random.uniform}(\textcolor{codegreen}{0.1},\textcolor{codegreen}{1}), delta\textcolor{mymauve}{=}np.\textcolor{blue}{random.uniform}(\textcolor{codegreen}{0.1},\textcolor{codegreen}{1}), a\textcolor{mymauve}{=}np.\textcolor{blue}{random.uniform}(\textcolor{codegreen}{0.1},\textcolor{codegreen}{1}), alpha\textcolor{mymauve}{=}np.\textcolor{blue}{random.uniform}(\textcolor{codegreen}{1},\textcolor{codegreen}{10}), u\textcolor{mymauve}{=}np.\textcolor{blue}{random.uniform}(\textcolor{codegreen}{100},\textcolor{codegreen}{200}), c\textcolor{mymauve}{=}np.\textcolor{blue}{random.uniform}(\textcolor{codegreen}{0.1},\textcolor{codegreen}{1}), N\textcolor{mymauve}{=}rd.\textcolor{blue}{randint}(\textcolor{codegreen}{1},\textcolor{codegreen}{10000}), monte\_carlo\_limit\textcolor{mymauve}{=}\textcolor{codegreen}{10000}, lambda\_01\textcolor{mymauve}{=}np.\textcolor{blue}{random.uniform}(\textcolor{codegreen}{0.1},\textcolor{codegreen}{1}), lambda\_02\textcolor{mymauve}{=}np.\textcolor{blue}{random.uniform}(\textcolor{codegreen}{0.1},\textcolor{codegreen}{1}), lambda\_03\textcolor{mymauve}{=}np.\textcolor{blue}{random.uniform}(\textcolor{codegreen}{0.1},\textcolor{codegreen}{1})):

\phantom{aaaaaaaa}\textcolor{red}{"""}

\phantom{aaaaaaaa}\textcolor{red}{Contient toutes les variables initiales de nos modeles}

\phantom{aaaaaaaa}\textcolor{red}{"""}

\phantom{aaaaaaaa}self.\textcolor{blue}{colors} \textcolor{mymauve}{=} {\textcolor{red}{"bg"} : \textcolor{codegreen}{0}}

\phantom{aaaaaaaa}self.\textcolor{blue}{parameters} = \{ \textcolor{red}{"x 0"} : x\_0,

\phantom{aaaaaaaaaaaaaaaa}\textcolor{red}{"b"} : b,

\phantom{aaaaaaaaaaaaaaaa}\textcolor{red}{"sigma"} : sigma,

\phantom{aaaaaaaaaaaaaaaa}\textcolor{red}{"delta"} : delta,

\phantom{aaaaaaaaaaaaaaaa}\textcolor{red}{"a"} : a,

\phantom{aaaaaaaaaaaaaaaa}\textcolor{red}{"alpha"} : alpha,

\phantom{aaaaaaaaaaaaaaaa}\textcolor{red}{"u"} : u,

\phantom{aaaaaaaaaaaaaaaa}\textcolor{red}{"c"} : c,

\phantom{aaaaaaaaaaaaaaaa}\textcolor{red}{"N"} : N,

\phantom{aaaaaaaaaaaaaaaa}\textcolor{red}{"limite machine de monte carlo limit"} : monte\_carlo\_limit,

\phantom{aaaaaaaaaaaaaaaa}\textcolor{red}{"lambda 01"} : lambda\_01,

\phantom{aaaaaaaaaaaaaaaa}\textcolor{red}{"lambda 02"} : lambda\_02,

\phantom{aaaaaaaaaaaaaaaa}\textcolor{red}{"lambda 03"} : lambda\_03 \}

\phantom{aaaa}\textcolor{teal}{def} \textcolor{blue}{\_\_repr\_\_}(self):

\phantom{aaaaaaaa}\textcolor{teal}{return} \textcolor{red}{"Parametres du modèle : "} \textcolor{mymauve}{+} \textcolor{red}{"$\backslash$n"} \textcolor{mymauve}{+} \textcolor{red}{"$\backslash$n"}.\textcolor{blue}{join}([\textcolor{red}{" - "} \textcolor{mymauve}{+} \textcolor{codegreen}{str}(elt) \textcolor{mymauve}{+} \textcolor{red}{" : "} \textcolor{mymauve}{+} \textcolor{codegreen}{str}(self.\textcolor{blue}{parameters}[elt]) \textcolor{codegreen}{for} elt \textcolor{codegreen}{in} self.\textcolor{blue}{parameters}.\textcolor{blue}{keys}()])
        
\phantom{aaaa}\textcolor{teal}{def} \textcolor{blue}{\_\_str\_\_}(self):

\phantom{aaaaaaaa}\textcolor{teal}{return} \textcolor{red}{"Parametres du modèle : "} \textcolor{mymauve}{+} \textcolor{red}{"$\backslash$n"} \textcolor{mymauve}{+} \textcolor{red}{"$\backslash$n"}.\textcolor{blue}{join}([\textcolor{red}{" - "} \textcolor{mymauve}{+} \textcolor{codegreen}{str}(elt) \textcolor{mymauve}{+} \textcolor{red}{" : "} \textcolor{mymauve}{+} \textcolor{codegreen}{str}(self.\textcolor{blue}{parameters}[elt]) \textcolor{codegreen}{for} elt \textcolor{codegreen}{in} self.\textcolor{blue}{parameters}.\textcolor{blue}{keys}()])
\end{minipage}
\end{center}


\phantom{aaaa}


\phantom{aaaa}


\begin{center}
\begin{minipage}[r]{0.1\textwidth}

\end{minipage}
\begin{minipage}[r]{0.8\textwidth}
\begin{center}
Bien que le choix de stocker nos paramètres ait brièvement été aborder, les nombreuses ouvertures et fermetures de fichiers successives auraient un impact néfaste et difficilement quantifiable sur la qualité de notre code.
\end{center}
\end{minipage}
\end{center}






\begin{center}
\begin{minipage}[r]{0.1\textwidth}
\textcolor{black!60}{1}

\textcolor{black!60}{2}

\phantom{aa}

\textcolor{black!60}{3}

\textcolor{black!60}{4}

\textcolor{black!60}{5}

\textcolor{black!60}{6}

\phantom{aa}

\textcolor{black!60}{7}

\textcolor{black!60}{8}

\phantom{aa}

\phantom{aa}

\phantom{aa}

\textcolor{black!60}{9}

\textcolor{black!60}{10}

\phantom{aa}

\phantom{aa}

\textcolor{black!60}{11}

\textcolor{black!60}{12}

\textcolor{black!60}{13}

\phantom{aa}

\textcolor{black!60}{14}

\phantom{aa}

\textcolor{black!60}{15}

\textcolor{black!60}{16}

\textcolor{black!60}{17}

\textcolor{black!60}{18}

\phantom{aa}

\textcolor{black!60}{19}

\textcolor{black!60}{20}

\textcolor{black!60}{21}

\textcolor{black!60}{22}

\textcolor{black!60}{23}

\textcolor{black!60}{24}

\textcolor{black!60}{25}

\textcolor{black!60}{26}

\textcolor{black!60}{27}

\textcolor{black!60}{28}

\textcolor{black!60}{29}

\phantom{aa}

\textcolor{black!60}{30}

\textcolor{black!60}{31}

\phantom{aa}

\phantom{aa}

\phantom{aa}

\textcolor{black!60}{32}

\textcolor{black!60}{33}

\phantom{aa}

\textcolor{black!60}{34}


\end{minipage}
\begin{minipage}[r]{0.88\textwidth}

\textcolor{teal}{class} \textcolor{blue}{Sinistre}():

\phantom{aaaa}\textcolor{teal}{def} \textcolor{blue}{\_\_init\_\_}(self, settings\textcolor{mymauve}{=}ProjectSettings, p\textcolor{mymauve}{=}get\_a\_random\_distribution(n\textcolor{mymauve}{=}\textcolor{codegreen}{10})):

\phantom{aaaaaaaa}self.\textcolor{blue}{settings} \textcolor{mymauve}{=} settings

\phantom{aaaaaaaa}self.\textcolor{blue}{p} \textcolor{mymauve}{=} p

\phantom{aaaa}\textcolor{teal}{def} \textcolor{blue}{f\_norm}(self, x : \textcolor{codegreen}{float}):

\phantom{aaaaaaaa}\textcolor{red}{"""f\_norm est la loi selon  laquelle on doit simuler pour obtenir Pnorm"""}

\phantom{aaaaaaaa}ind \textcolor{mymauve}{=} (x \textcolor{mymauve}{>=} \textcolor{codegreen}{0}) \& (x \textcolor{mymauve}{<=} self.\textcolor{blue}{settings.parameters}[\textcolor{red}{"b"}])

\phantom{aaaaaaaa}\textcolor{teal}{return} ind\textcolor{mymauve}{*}(np.\textcolor{blue}{exp}(\textcolor{mymauve}{-}((x \textcolor{mymauve}{-} self.\textcolor{blue}{settings.parameters}[\textcolor{red}{"x 0"}])\textcolor{mymauve}{**}\textcolor{codegreen}{2}) \textcolor{mymauve}{/} (\textcolor{codegreen}{2} \textcolor{mymauve}{*} self.\textcolor{blue}{settings.parameters}[\textcolor{red}{"sigma"}]\textcolor{mymauve}{**}\textcolor{codegreen}{2})) \textcolor{mymauve}{*} (\textcolor{codegreen}{1}\textcolor{mymauve}{+} np.\textcolor{blue}{cos}(\textcolor{codegreen}{2}\textcolor{mymauve}{*}np.\textcolor{blue}{pi}\textcolor{mymauve}{*}(x \textcolor{mymauve}{-} self.\textcolor{blue}{settings.parameters}[\textcolor{red}{"x 0"}])\textcolor{mymauve}{/}self.\textcolor{blue}{settings.parameters}[\textcolor{red}{"delta"}])\textcolor{mymauve}{**}\textcolor{codegreen}{2}))

\phantom{aaaa}\textcolor{teal}{def} \textcolor{blue}{g}(self, x : \textcolor{codegreen}{float}):

\phantom{aaaaaaaa}\textcolor{teal}{return} (\textcolor{codegreen}{1} \textcolor{mymauve}{/} (np.\textcolor{blue}{sqrt}(\textcolor{codegreen}{2}\textcolor{mymauve}{*}np.\textcolor{blue}{pi})\textcolor{mymauve}{*}self.\textcolor{blue}{settings.parameters}[\textcolor{red}{"sigma"}])) \textcolor{mymauve}{*} np.\textcolor{blue}{exp}(\textcolor{mymauve}{-}((x \textcolor{mymauve}{-} self.\textcolor{blue}{settings.parameters}[\textcolor{red}{"x 0"}])\textcolor{mymauve}{**}\textcolor{codegreen}{2}) \textcolor{mymauve}{/} (\textcolor{codegreen}{2} \textcolor{mymauve}{*} self.\textcolor{blue}{settings.parameters}[\textcolor{red}{"sigma"}]\textcolor{mymauve}{**}\textcolor{codegreen}{2}))

\phantom{aaaa}\textcolor{teal}{def} f\_norm\_run(self):

\phantom{aaaaaaaa}\textcolor{codegreen}{while} \textcolor{orange!80}{True}:

\phantom{aaaaaaaaaaaa}X = np.\textcolor{blue}{random.normal}(self.\textcolor{blue}{settings.parameters}[\textcolor{red}{"x 0"}], self.\textcolor{blue}{settings.parameters}[\textcolor{red}{"sigma"}])   
            
\phantom{aaaaaaaaaaaa}Y = np.\textcolor{blue}{random.uniform}(\textcolor{codegreen}{0}, \textcolor{codegreen}{2}\textcolor{mymauve}{*}np.\textcolor{blue}{sqrt}(\textcolor{codegreen}{2}\textcolor{mymauve}{*}np.\textcolor{blue}{pi})\textcolor{mymauve}{*}self.\textcolor{blue}{settings.parameters}[\textcolor{red}{"sigma"}])

\phantom{aaaaaaaaaaaa}\textcolor{codegreen}{if} Y\textcolor{mymauve}{*}self.\textcolor{blue}{g}(x\textcolor{mymauve}{=}X) \textcolor{mymauve}{<=} self.\textcolor{blue}{f\_norm}(x\textcolor{mymauve}{=}X):

\phantom{aaaaaaaaaaaaaaaa}\textcolor{teal}{return} X \textcolor{mymauve}{\#condition \textit{d'acceptation, boucle brisée}}

\phantom{aaaa}\textcolor{teal}{def} \textcolor{blue}{loi\_de\_puissance\_run}(self):

\phantom{aaaaaaaa}\textcolor{teal}{return} self.\textcolor{blue}{settings.parameters}[\textcolor{red}{"a"}]\textcolor{mymauve}{*}(\textcolor{codegreen}{1} \textcolor{mymauve}{-} rd.\textcolor{blue}{random}())\textcolor{mymauve}{**}(\textcolor{codegreen}{1}\textcolor{mymauve}{/}(\textcolor{codegreen}{1}\textcolor{mymauve}{-}self.\textcolor{blue}{settings.parameters}[\textcolor{red}{"alpha"}]))

\phantom{aaaa}\textcolor{teal}{def} \textcolor{blue}{loi\_z\_run}(self):

\phantom{aaaaaaaa}M \textcolor{mymauve}{=} np.\textcolor{blue}{max}(self.\textcolor{blue}{p})

\phantom{aaaaaaaa}k \textcolor{mymauve}{=} \textcolor{codegreen}{len}(self.\textcolor{blue}{p})

\phantom{aaaaaaaa}\textcolor{codegreen}{while} \textcolor{orange!80}{True}:

\phantom{aaaaaaaaaaaa}I \textcolor{mymauve}{=} np.\textcolor{blue}{random.randint}(\textcolor{codegreen}{0}, k) 

\phantom{aaaaaaaaaaaa}U \textcolor{mymauve}{=} np.\textcolor{blue}{random.uniform}(\textcolor{codegreen}{0}, M)

\phantom{aaaaaaaaaaaa}\textcolor{codegreen}{if} U \textcolor{mymauve}{<=} self.\textcolor{blue}{p}[I]:

\phantom{aaaaaaaaaaaaaaaa}\textcolor{teal}{return} I \textcolor{mymauve}{\# \textit{condition d'acceptation}}

\phantom{aaaa}\textcolor{teal}{def} \textcolor{blue}{loi\_X\_run}(self):

\phantom{aaaaaaaa}z \textcolor{mymauve}{=} self.\textcolor{blue}{loi\_z\_run}()

\phantom{aaaaaaaaaaaa}return (z \textcolor{mymauve}{==} \textcolor{codegreen}{0})\textcolor{mymauve}{*}self.\textcolor{blue}{f\_norm\_run}() + (z \textcolor{mymauve}{==} \textcolor{codegreen}{1})\textcolor{mymauve}{*}self.\textcolor{blue}{loi\_de\_puissance\_run}() + (z \textcolor{mymauve}{>} \textcolor{codegreen}{1})\textcolor{mymauve}{*}z

\phantom{aaaa}\textcolor{teal}{def} \textcolor{blue}{empiricLikelihood}(self, n\textcolor{mymauve}{=}\textcolor{codegreen}{4000}):

\phantom{aaaaaaaa}hist\_data \textcolor{mymauve}{=} [[self.\textcolor{blue}{f\_norm\_run}() \textcolor{codegreen}{for} i \textcolor{codegreen}{in} \textcolor{codegreen}{range}(n)],[self.loi\_de\_puissance\_run() \textcolor{codegreen}{for} i \textcolor{codegreen}{in} \textcolor{codegreen}{range}(n)],[self.\textcolor{blue}{loi\_z\_run}() \textcolor{codegreen}{for} i \textcolor{codegreen}{in} \textcolor{codegreen}{range}(n)],[self.\textcolor{blue}{loi\_X\_run}() \textcolor{codegreen}{for} i \textcolor{codegreen}{in} \textcolor{codegreen}{range}(n)]]

\phantom{aaaaaaaa}group\_labels \textcolor{mymauve}{=} [\textcolor{red}{"X\_norm"}, \textcolor{red}{"X\_puissance"},\textcolor{red}{"Z"},\textcolor{red}{"X"}]

\phantom{aaaaaaaa}fig \textcolor{mymauve}{=} ff.\textcolor{blue}{create\_distplot}(hist\_data, group\_labels, show\_hist=\textcolor{orange!80}{False})

\phantom{aaaaaaaa}fig.\textcolor{blue}{show}()
\end{minipage}
\end{center}





















\subsection{Vérifications d'usage}

\begin{center}
\begin{minipage}[r]{0.1\textwidth}

\end{minipage}
\begin{minipage}[r]{0.8\textwidth}
Nos \textit{densités empiriques}, sont visiblement conformes (ou du moins vraisemblables) aux densités $f_{norm}$, $f_{puissance}$ et $f_{Z}$ (ou $\mathbb{P}_{Z}$ conditionnellement a la nature de $Z$).
\end{minipage}
\end{center}

\begin{center}
\includegraphics[width=12cm,height=3.4cm]{img5}
\end{center}



\begin{center}
\begin{minipage}[r]{0.1\textwidth}

\end{minipage}
\begin{minipage}[r]{0.8\textwidth}
Qui plus est, nous tenons (dans un soucis de concision) a notifier que les vérifications d'usage pour nos \textit{« tables de walker »} et autres \textit{chaines de markov} (dont les codes ne seront pas détaillés ci-dessous au vu de leurs complexités) sont libre access sur le \href{https://github.com/LaboiteNoire/techniques-de-simulations-}{\textcolor{blue}{\textbf{\textit{notebook}}}}.

\end{minipage}
\end{center}


\section{Les différents modèles}
\subsection{Modèle A}
\begin{center}
\begin{minipage}[r]{0.1\textwidth}

\end{minipage}
\begin{minipage}[r]{0.8\textwidth}
Cette partie bénéficiera grandement des formules exposés en \hyperlink{ref2}{\textcolor{blue}{\textbf{\textit{$3^e$ partie}}}}, sur notre capacité a procéder étapes par étapes, afin d'optimiser notre code.

En premier lieux, nous générons nos possibles dates d'occurrences par une \textit{simili} méthode de rejet, puis nous générons la trajectoire de la \textit{chaine de markov} portant en elle l'information nécessaire a la bonne formation de nos critères de rejet.

Il n'est ainsi pas nécessaire de générer toute la trajectoire de la météo journalière, si l'information que celle-ci nous apporte ne nous est pas indispensable.
\end{minipage}
\end{center}


\begin{center}
\begin{minipage}[r]{0.1\textwidth}
\textcolor{black!60}{1}

\textcolor{black!60}{2}

\end{minipage}
\begin{minipage}[r]{0.88\textwidth}

    def run\_ruine(self, rounds=365, draw=True):
        N\_sim = np.random.poisson(lam=self.theta*rounds)
        \# Nous essayer d'optimiser le code de facon a que l'on ait besoin de simmuler toute la trajectoire de la chaine de markov, si et seulement si l'information qu'elle apport nous ait nécéssaire.
        for k in range(N\_sim):
            va\_transitoire = np.random.uniform(0,rounds)
            va\_transitoire\_aux = int(va\_transitoire)
            if (va\_transitoire\_aux in self.trajectory): \# recherche en temps constant
                if (np.random.uniform(0,self.theta) <= self.settings.parameters["N"]*self.trajectory[va\_transitoire\_aux]):
                    bisect.insort(self.T,va\_transitoire) \# o(lnn)
            else:
                for i in range(va\_transitoire\_aux - self.round + 2): \# Nombre de tours qu'il nous reste pour que va\_transitioire\_aux soit dans le dictionnaire
                    self.state, self.round, self.trajectory[self.round] = self.transitions\_walker\_table[self.indexa[self.state]].run(), self.round + 1, self.state
                if (np.random.uniform(0,self.theta) <= self.settings.parameters["N"]*self.trajectory[va\_transitoire\_aux]):
                    bisect.insort(self.T,va\_transitoire) \# o(lnn)
        if draw:
            X = [self.sinister.loi\_X\_run() for k in range(len(self.T))]
            X[0] = 0
            drawP(T=self.T, X=X)
            drawRt(T=self.T, X=X, N=self.settings.parameters["N"], u=self.settings.parameters["u"], c=self.settings.parameters["c"])
\end{minipage}
\end{center}





\subsection{Modèle B}
\subsection{Complexité algorithmique}


\part{Conclusion}
\section{Commentaires sur la pertinence du modèle}
\section{Évolutions possibles du modèle}
\begin{center}
\begin{minipage}[r]{0.1\textwidth}

\end{minipage}
\begin{minipage}[r]{0.8\textwidth}

Interfaçage avec d'autres langages peut-être plus performants : R, C++

NB : vérifier que R soit plus performant que python.

\end{minipage}
\end{center}
\section{Commentaires}
\section{Annexes et contacts}

\subsection*{Annexes et contacts}



\begin{center}
\begin{minipage}[r]{0.4\textwidth}

\end{minipage}
\begin{minipage}[r]{0.4\textwidth}


\end{minipage}
\end{center}






\end{document}