\documentclass[10pt,a4paper]{article}
\title{Techniques de Simulations}
\author{
  PRISCILLA, GOGUY\\
  \texttt{priscilla.goguy@etu.univ-lyon1.fr}
  \and
  MAHLÎ, REINETTE\\
  \texttt{mahli.reinette@etu.univ-lyon1.fr}
}
\date{13/10/2025}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[french]{babel}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{caption}

\usepackage{listings}
\usepackage{xcolor}


\usepackage[many]{tcolorbox}
\usepackage{lipsum}
\usepackage{tikz}
\usetikzlibrary{automata, positioning, arrows}
\usepackage{pgfplots}
\usepackage{xcolor}
\usepackage{amsfonts}
\usepackage{dsfont}
\usepackage{xr-hyper} 
\usepackage{hyperref} 
\usepackage{algpseudocode}
\usepackage{algorithm}
\externaldocument[B-]{docB}[Annexe01.pdf]% <- full or relative path


% le préambule











% initialisation des couleurs
\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}
\definecolor{mymauve}{rgb}{0.58,0,0.82}






%block de code 
\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},   
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,         
    breaklines=true,                 
    captionpos=b,                    
    keepspaces=true,                 
    numbers=left,                    
    numbersep=5pt,                  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    tabsize=2
}

\lstset{style=mystyle}






%initialisation graphics
\tikzset{
->,
node distance = 2cm}



















% le corps du document






% le préambule
\begin{document}
%titre
\pagecolor{black!20}
\maketitle


\begin{center}
\textbf{\textit{M1 Actuariat}}

\textbf{\textit{ISFA}}

\includegraphics[width=4cm,height=2cm]{img1}

\href{https://github.com/LaboiteNoire/techniques-de-simulations-}{\includegraphics[width=1cm,height=1cm]{img2}}

\end{center}


\newpage

\phantom{aaaaaa}

\tableofcontents

\newpage

\part{Préambule}

\subsection{Avant-propos}
\begin{center}
\begin{minipage}[r]{0.1\textwidth}

\end{minipage}
\begin{minipage}[r]{0.8\textwidth}

Toutes les ressources utilisées seront présentes en annexes et sur le \href{https://github.com/LaboiteNoire/techniques-de-simulations-}{\textit{\textbf{repository}}} github ci-dessus.
Dans une optique de rigueur absolue, nous tenterons de commenter chaque partie de notre code et essaierons de justifier nos méthodes de simulation.

\end{minipage}
\end{center}


\subsection{Notations}

\begin{description}

\item[\bsc{* $\mathcal{P}(\textbf{X})$ : }]

\textit{Soit \textbf{$\Omega$}, un ensemble quelconque.}

\phantom{aaaaaaa} — \textit{On note $\mathcal{P}(\Omega)$, l'ensemble des parties de $\Omega$.}

\item[\bsc{* $\sigma$-Algèbre de $\Omega$ : }]

\textit{Soit $\Omega$, un ensemble quelconque. $\mathcal{A} \subseteq \mathcal{P}(\Omega)$ est dite $\sigma$-Algèbre de $\Omega$ si :}

\phantom{aaaaaaa} — \textit{$\Omega$ $\in \mathcal{A}$}

\phantom{aaaaaaa} — \textit{$\forall A \in \mathcal{A}$, $\bar{A} \in \mathcal{A}$}

\phantom{aaaaaaa} — \textit{$\forall (A_n)_{n \in \mathbb{N}} \in \mathcal{A}^{\mathbb{N}}$, $\bigcup_{n \in \mathbb{N}} A_n \in \mathcal{A}$}

\phantom{aaaaaaaaaaaaaaa} — \textit{On notera la « tribu borélienne » : $\mathbb{B}(\mathbb{R}^n)$ et \phantom{aaaaaaaaaaaaaa} $\lambda$ : « mesure de Lebesgue ».}


\item[\bsc{* $\mu$ Mesure de probabilité sur $(\Omega, \mathcal{A})$ : }]

\textit{Soit $(\Omega, \mathcal{A})$, un couple dit « espace probabilisable »}

\phantom{aaaaaaa} — \textit{$\mu : \mathcal{A} \longrightarrow [0,1]$}

\phantom{aaaaaaa} — \textit{$\mu(\emptyset) = 0$}

\phantom{aaaaaaa} — \textit{$\forall (A_n)_{n \in \mathbb{N}} \in \mathcal{A}^{\mathbb{N}}$, une famille disjointe, $\mu(\bigsqcup_{n \in \mathbb{N}} A_n)$ = \phantom{aaaaaaaaaaaaaa} $\sum_{n \in \mathbb{N}} \mu(A_n)$}

\phantom{aaaaaaaaaaaaaaa} — \textit{On notera la « probabilité historique » : $\mathbb{P}$.}

\phantom{aaaaaaaaaaaaaaa} — \textit{On notera $(\Omega, \mathcal{A}, \mu)$ : « espace probabilisé ».}


\item[\bsc{* \textbf{X}, une variable aléatoire sur $(\Omega, \mathcal{A}, \mathbb{P})$ : }]

\textit{Soit $(\Omega, \mathcal{A}, \mathbb{P})$ : « espace probabilisé »}

\phantom{aaaaaaa} — \textit{$(\textbf{E}, \mathcal{E})$ : « espace mesurable »}

\phantom{aaaaaaa} — \textit{\textbf{X : } $(\Omega, \mathcal{A}, \mathbb{P})$ $\longrightarrow$ $(\textbf{E}, \mathcal{E})$}

\phantom{aaaaaaaaaaaaaaa} — \textit{$\forall B \in \mathcal{E}$, $\mathbb{P}_{X}(B)$ = $\mathbb{P}(\{ \omega \in \Omega | X(\omega) \in \mathcal{B} \})$}


\item[\bsc{* \textbf{X}, une variable aléatoire continue sur $(\Omega, \mathcal{A}, \mathbb{P})$ : }]

\textit{Soit $(\Omega, \mathcal{A}, \mathbb{P})$ : « espace probabilisé »}

\phantom{aaaaaaa} — \textit{$(\mathbb{R}^n, \mathbb{B}(\mathbb{R}^n), \lambda)$ : « espace mesuré »}

\phantom{aaaaaaa} — \textit{\textbf{X : } $(\Omega, \mathcal{A}, \mathbb{P})$ $\longrightarrow$ $(\mathbb{R}^n, \mathbb{B}(\mathbb{R}^n), \lambda)$}

\phantom{aaaaaaa} — \textit{$\mathbb{P}_{X}$ << $\lambda$\footnotemark[1]}

\phantom{aaaaaaaaaaaaaaa} — \textit{$\exists ! \rho : (\mathbb{R}^n, \mathbb{B}(\mathbb{R}^n), \lambda) \longrightarrow \mathbb{R}^{+}$\footnotemark[2], mesurable, tel que :}

\[ \mathbb{P}_{X}(A) = \int_{A} \rho(x) \,dx \]

\end{description}


\footnotetext[1]{$\forall A \in \mathbb{B}(\mathbb{R}^n)$, tel que $\lambda(A) = 0 \Longrightarrow \mathbb{P}_{X}(A) = 0$.}

\footnotetext[2]{Dite : \textit{« densité de \textbf{X} ».}}








\begin{description}

\item[\bsc{* Espérance \textbf{E[X]}, de la variable aléatoire \textbf{X} : }]

\textit{Soit \textbf{X}, une variable aléatoire sur $(\Omega, \mathcal{A}, \mathbb{P})$}

\phantom{aaaaaaa} — \textit{On note} \textbf{E[X]}, \textit{« l'espérance de \textbf{X} ».}

\phantom{aaaaaaaaaaaaaaa} — \textit{Si \textbf{X}, est discrète\footnotemark[1], alors :}

\[ \textbf{E[X]} = \sum_{k \in X(\Omega)} k \mathbb{P}_{X}(\{ k \}) \]

\phantom{aaaaaaaaaaaaaaa} — \textit{Si \textbf{X}, est continue de densité $\rho$, alors :}

\[  \textbf{E[X]} = \int x\rho(x) \,dx \]



\item[\bsc{* Fonction de Répartition $F_X$, de la variable aléatoire \textbf{X} : }]

\textit{Soit \textbf{X}, une variable aléatoire sur $(\Omega, \mathcal{A}, \mathbb{P})$}

\phantom{aaaaaaa} — \textit{On note} $\forall x \in \mathbb{R}$, $F_X(x) = \mathbb{P}_{X}(]-\infty, x])$ \textit{« la fonction de \phantom{aaaaaaaaaaaaaaa} répartition de \textbf{X} ».}



\item[\bsc{* Espace $L^p(\Omega, \mathcal{A}, \mathbb{P})$ : }]

\textit{Soit $(\Omega, \mathcal{A}, \mathbb{P})$}

\phantom{aaaaaaa} — \textit{On note} $L^p(\Omega, \mathcal{A}, \mathbb{P})$, \textit{l'ensemble :}

\begin{displaymath}
\{ \textbf{X} \text{variable aléatoire sur } (\Omega, \mathcal{A}, \mathbb{P}) | \textbf{E[}|\textbf{X}|^p\textbf{]} < + \infty \}
\end{displaymath}


\item[\bsc{* Moment d'ordre $p$ $m_p$\textbf{[X]}, de la variable aléatoire \textbf{X} : }]

\textit{$\forall$ \textbf{X}, $\in L^p(\Omega, \mathcal{A}, \mathbb{P})$}

\phantom{aaaaaaa} — \textit{On note} $m_p$\textbf{[X]} = $\textbf{E[}\textbf{X}^p\textbf{]}$


\item[\bsc{* Moment centré d'ordre $p$ $\mu_p$\textbf{[X]}, de la variable aléatoire \textbf{X} : }]

\textit{$\forall$ \textbf{X}, $\in L^p(\Omega, \mathcal{A}, \mathbb{P})$}

\phantom{aaaaaaa} — \textit{On note} $\mu_p$\textbf{[X]} = $\textbf{E[}(\textbf{X} - \textbf{E[X]})^p\textbf{]}$


\item[\bsc{* Variantes du moment centré d'ordre $2$, de la variable aléatoire \textbf{X} : }]

\textit{$\forall$ \textbf{X}, $\in L^2(\Omega, \mathcal{A}, \mathbb{P})$}

\phantom{aaaaaaa} — \textit{On note} \textbf{V}$(X)$ = $\mu_2$\textbf{[X]}, \textit{la : « variance de \textbf{X} »} 

\phantom{aaaaaaa} — \textit{On note $\sigma_{X}$ = $\sqrt{V(X)}$, « l'écart-type de \textbf{X} »} 





\item[\bsc{* Covariance, entre les variables aléatoires \textbf{X} et \textbf{Y} : }]

\textit{$\forall ($\textbf{X}, \textbf{Y}$)$ $\in L^2(\Omega, \mathcal{A}, \mathbb{P})^2$}


\phantom{aaaaaaa} — \textit{On note} \textbf{Cov}$(X,Y)$ = $\textbf{E[} (\textbf{X} - \textbf{E[X]})(\textbf{Y} - \textbf{E[Y]}) \textbf{]} $, \textit{la : « covariance entre \textbf{X} et \textbf{Y} »} 

\phantom{aaaaaaaaaaaaaaa} — \textit{$(L^2(\Omega, \mathcal{A}, \mathbb{P})$, \textbf{Cov}$)$, forme un « espace euclidien »} 



\item[\bsc{* Coefficient de corrélation linéaire, entre les variables aléatoires \textbf{X} et \textbf{Y} : }]

\textit{$\forall ($\textbf{X}, \textbf{Y}$)$ $\in L^2(\Omega, \mathcal{A}, \mathbb{P})^2$}


\phantom{aaaaaaa} — \textit{On note} $\rho_{X,Y}$ = $\dfrac{\textbf{Cov(X,Y)}}{\sigma_{X} \sigma_{Y}}$, \textit{la : « le coefficient de corrélation linéaire entre \textbf{X} et \textbf{Y} »}



\end{description}

\footnotetext[1]{$\mathbb{P}_{X}$ << $\mu$, ou $\mu$ est : la « mesure de comptage ».}



\newpage
\subsection{Objets du Problème}
\begin{center}
\begin{minipage}[r]{0.1\textwidth}

\end{minipage}
\begin{minipage}[r]{0.8\textwidth}

On cherche à approximer la probabilité de ruine pour un modèle de théorie de la ruine en
assurance moto. On étudie deux cas : un cas où les assurés sont indépendants, et un cas où ils
sont corrélés à travers des conditions météo communes.

\end{minipage}
\end{center}



\begin{description}

\item[\bsc{* La variable aléatoire $X_{norm}$ sur $(\mathbb{R},\mathbb{B}(\mathbb{R}))$ : }]

\textit{$\forall (x_0,b,\sigma,\delta) \in \mathbb{R} \times (\mathbb{R}_{+}^{*})^3$}

\phantom{aaaaaaa} — \textit{On note} $X_{norm}$,

\phantom{aaaaaaaaaaaaaaa} — \textit{la variable aléatoire continue de densité $f_{norm}^{*}$ proportionnelle a $f_{norm}$ :}

\[ \forall x \in \mathbb{R}, \text{  } f_{norm}(x) = \mathds{1}_{[0,b]}(x) \text{ } exp(-\dfrac{(x-x_0)^2}{2\sigma^2}) \text{ } (1 + cos(2 \pi \dfrac{x - x_0}{\delta} )^2) \]



\item[\bsc{* La variable aléatoire $X_{puissance}$ sur $(\mathbb{R},\mathbb{B}(\mathbb{R}))$ : }]

\textit{$\forall (a, \alpha) \in \mathbb{R}_{+}^{*} \times ]1 : + \infty [$}

\phantom{aaaaaaa} — \textit{On note} $X_{puissance}$,

\phantom{aaaaaaaaaaaaaaa} — \textit{la variable aléatoire continue de densité : $f_{puissance}$\footnotemark[1] :}

\[ \forall x \in \mathbb{R}, \text{  } f_{puissance}(x) = \mathds{1}_{[a,+\infty [}(x) \text{ } x^{-\alpha} \times \dfrac{\alpha - 1}{a^{1-\alpha}} \]



\item[\bsc{* La variable aléatoire $Z$ sur $(\Omega, \mathcal{A}, \mathbb{P})$ : }]

\textit{Soit $Z(\Omega)$ = $\mathbb{N}$ et $(p_n)_{n \in \mathbb{N}} \in [0,1]^{\mathbb{N}}$ et tel que : $\sum_{n \in \mathbb{N}} p_n$ = 1}

\phantom{aaaaaaa} — \textit{On note} $Z$,

\phantom{aaaaaaaaaaaaaaa} — \textit{la variable aléatoire discrète, dont les probabilités \phantom{aaaaaaaaaaaaaaaaaaa} respectives sont ainsi notées :}

\[ \forall n \in \mathbb{N}, \text{  } p_n = \mathbb{P}(Z = n) \]


\phantom{aaaaaaaaaaaaaaaaaa} — \textit{On désignera par la suite sa probabilité de la sorte : $\mathbb{P}_Z$}



\item[\bsc{* La variable aléatoire \textbf{X} sur $(\Omega, \mathcal{A}, \mathbb{P})$ : }]

\textit{Soit : $X_{norm}$, $X_{puissance}$, $Z$, des variables aléatoires mutuellement indépendantes, de lois (et ou de densités) respectives : $f_{norm}$, $f_{puissance}$ et $\mathbb{P}_Z$.}

\phantom{aaaaaaa} — \textit{On note} \textbf{X},

\phantom{aaaaaaaaaaaaaaa} — \textit{la variable aléatoire, définie de la sorte :}

\begin{displaymath}
\textbf{X} = 
\begin{cases}
	X_{norm} \text{ si Z = } 0 \\
	X_{puissance} \text{ si Z = } 1 \\
	Z \text{ sinon}
\end{cases}
\end{displaymath}





\end{description}


\section{Organisation du travail}
\begin{center}
\begin{minipage}[r]{0.1\textwidth}

\end{minipage}
\begin{minipage}[r]{0.8\textwidth}

Concernant l'organisation du travail, nous avons jugé nécessaire de mettre en place un
environnement permettant de partager facilement nos ébauches de code, l'avancée du rendu ainsi
que tout document utile au bon déroulement du projet. Pour cela, nous avons créé une page \href{https://github.com/LaboiteNoire/techniques-de-simulations-}{\textit{GitHub}}
dédiée.

\phantom{aaaaaaa}

La communication s'est faite principalement via un groupe de discussion sur les réseaux sociaux,
mais aussi lors d'échanges directs en classe ou au cours de réunions informelles consacrées à
l'avancement du projet.

\phantom{aaaaaaa}

Sur le plan technique, la première séance en classe a été consacrée à l'analyse de chaque question
afin de déterminer les méthodes de simulation à utiliser et les optimisations possibles. Suite à cela,
le rôle de \href{https://github.com/priscilla1269}{\textit{Priscilla}} a été plutôt dirigé vers les implémentations de techniques de simulations
« classiques » tandis que \href{https://github.com/LaboiteNoire}{\textit{Mahlî}} a lui été plutôt chargé du côté optimisation du code notamment :
\textit{table de Walker}, classes...

\phantom{aaaaaaa}

Cela dit, de nombreuses parties du code ont été développées conjointement : chacun ayant parfois
besoin des conseils, des idées ou de l'expertise de l'autre pour la mise en place de structures de
données adaptées et pour garantir la cohérence globale de l'implémentation.

\phantom{aaaaaaa}


Enfin, nous avons choisi de travailler sur un \textit{Notebook Python}, un format qui nous a semblé plus
pratique pour organiser notre code, structurer nos sections et ajouter facilement titres et
commentaires. Par souci de clarté et de rigueur, nous avons rédigé les démonstrations
mathématiques associées aux différentes étapes de nos algorithmes. Conscients que ces éléments ne
constituent pas le cœur de la matière, nous avons choisi de les regrouper dans une annexe, où elles
restent consultables si nécessaire.

\end{minipage}
\end{center}




\subsection{Majoration de $X_{norm}$}

\[ f_{norm}(x) = \mathds{1}_{[0,b]}(x) \text{ } exp(-\dfrac{(x-x_0)^2}{2\sigma^2}) \text{ } (1 + cos(2 \pi \dfrac{x - x_0}{\delta} )^2) \]

\begin{center}
\begin{minipage}[r]{0.1\textwidth}

\end{minipage}
\begin{minipage}[r]{0.8\textwidth}

La loi $\mathbb{P}_{X_{norm}}$, n'étant pas sans rappeler la \textit{loi normale}.

Nous posons donc $g$, la densité de $N(x_0,\sigma^2)$.
\end{minipage}
\end{center}

\begin{displaymath}
\forall x \in [0, b], \dfrac{f(x)}{g(x)} = (\underbrace{1 + \underbrace{cos(2 \pi \dfrac{x - x_0}{\delta} )^2}_{\leq 1}}_{\leq 2}) \times \sqrt{2 \pi}\sigma \leq 2\sigma \sqrt{2 \pi}
\end{displaymath}



\part{Aspects théoriques}
\section{modélisation}

\subsection{Simulation de $X_{puissance}$}
\begin{displaymath}
\forall (a, \alpha) \in \mathbb{R}_{+}^{*} \times ]1 : + \infty [,
\end{displaymath}

\begin{center}
\begin{minipage}[r]{0.1\textwidth}

\end{minipage}
\begin{minipage}[r]{0.8\textwidth}
$X_{puissance}$ est une variable aléatoire continue, de densité $f_{puissance}$, tel que $\forall x \in \mathbb{R}$ :
\end{minipage}
\end{center}

\begin{displaymath}
f_{puissance}(x) = \mathds{1}_{[a,+\infty [}(x) \text{ } x^{-\alpha} \times \dfrac{\alpha - 1}{a^{1-\alpha}}
\end{displaymath}

\begin{center}
$\Updownarrow$
\end{center}

\begin{displaymath}
\forall t \in \mathbb{R}, F_{X_{puissance}}(t) = \mathbb{P}_{X_{puissance}}(]-\infty: t]) = \int_{-\infty}^{t} f_{puissance}(x) dx
\end{displaymath}

\begin{displaymath}
= \int_{-\infty}^{t} \mathds{1}_{[a,+\infty [}(x) \text{ } x^{-\alpha} \times \dfrac{\alpha - 1}{a^{1-\alpha}} dx
\end{displaymath}

\begin{displaymath}
= \mathds{1}_{[a,+\infty [}(t) \int_{a}^{t} \text{ } x^{-\alpha} \times \dfrac{\alpha - 1}{a^{1-\alpha}} dx = \mathds{1}_{[a,+\infty [}(t) \dfrac{\alpha - 1}{a^{1-\alpha}} \int_{a}^{t} \text{ } x^{-\alpha} dx
\end{displaymath}

\begin{displaymath}
= \mathds{1}_{[a,+\infty [}(t) \times \dfrac{\overbrace{\alpha - 1}^{= -(1 - \alpha)}}{a^{1-\alpha}} \times \left[ \dfrac{x^{1-\alpha}}{1-\alpha}\right]^{t}_{a} = - \mathds{1}_{[a,+\infty [}(t) \times \left[ \dfrac{x^{1-\alpha}}{a^{1-\alpha}}\right]^{t}_{a}
\end{displaymath}


\begin{displaymath}
= \mathds{1}_{[a,+\infty [}(t) \times \left[ \dfrac{x^{1-\alpha}}{a^{1-\alpha}}\right]^{a}_{t} = \mathds{1}_{[a,+\infty [}(t) \times \underbrace{\left[ x^{1-\alpha} \right]^{a}_{t}}_{= a^{1- \alpha} - t^{1- \alpha}} \times a^{\alpha - 1}
\end{displaymath}

\begin{displaymath}
= \mathds{1}_{[a,+\infty [}(t) \times \left(1- \left(\dfrac{t}{a}\right)^{1-\alpha} \right)
\end{displaymath}


\begin{center}
\begin{minipage}[r]{0.1\textwidth}

\end{minipage}
\begin{minipage}[r]{0.8\textwidth}
Posons $F_{X_{puissance}}^{\phantom{aa}-}$, la fonction définit de la sorte : $\forall y \in ]0,1[$ :

$F_{X_{puissance}}^{\phantom{aa}-}(y)$ = inf $\bigl\{ x \in \mathbb{R} \text{ | } y \leq \mathds{1}_{[a,+\infty [}(x) \times \left(1- \left(\dfrac{x}{a}\right)^{1-\alpha} \right) \bigr\}$
\end{minipage}
\end{center}



\begin{center}
\begin{minipage}[r]{0.1\textwidth}

\end{minipage}
\begin{minipage}[r]{0.8\textwidth}
Or $y \in ]0,1[ \iff 0 < y \iff \bigl\{ x \in \mathbb{R} \text{ | } y \leq \mathds{1}_{[a,+\infty [}(x) \times \left(1- \left(\dfrac{x}{a}\right)^{1-\alpha} \right) \bigr\}$ = $\bigl\{ x \in [a,+\infty [ \text{ | } y \leq \left(1- \left(\dfrac{x}{a}\right)^{1-\alpha} \right) \bigr\}$
\end{minipage}
\end{center}


\newpage


\begin{center}
\begin{minipage}[r]{0.1\textwidth}

\end{minipage}
\begin{minipage}[r]{0.8\textwidth}
inf$\bigl\{ x \in [a,+\infty [ \text{ | } y \leq 1- \left(\dfrac{x}{a}\right)^{1-\alpha} \bigr\}$ = inf$\bigl\{ x \in [a,+\infty [ \text{ | } y - 1 \leq - \left(\dfrac{x}{a}\right)^{1-\alpha} \bigr\}$ = sup$\bigl\{ x \in [a,+\infty [ \text{ | } \left(\dfrac{x}{a}\right)^{1-\alpha} \leq 1-y \bigr\}$ = sup$\bigl\{ x \in [a,+\infty [ \text{ | } \left(\dfrac{x}{a}\right) \leq \sqrt[1-\alpha]{1-y} \bigr\}$ = sup$\bigl\{ x \in [a,+\infty [ \text{ | } x \leq a\sqrt[1-\alpha]{1-y} \bigr\}$

\end{minipage}

Or $a\sqrt[1-\alpha]{1-y} = \dfrac{a}{\underbrace{\sqrt[\alpha-1]{1-y}}_{\in ]0,1[}} \in [a,+\infty [ \iff$

$F_{X_{puissance}}^{\phantom{aa}-}(y) = sup\bigl\{ x \in [a,+\infty [ \text{ | } x \leq a\sqrt[1-\alpha]{1-y} \bigr\}$ = $sup[a,a\sqrt[1-\alpha]{1-y} ]$ = \colorbox{black!30}{$a\sqrt[1-\alpha]{1-y}$}
\end{center}


\begin{center}
\begin{minipage}[r]{0.1\textwidth}

\end{minipage}
\begin{minipage}[r]{0.8\textwidth}
\hypertarget{ref1}{A l'aune de cette information nouvelle, nous pouvons établir notre modèle de la sorte} :  
\end{minipage}

\colorbox{black!30}{Soit $U \sim \mathcal{U}(]0,1[)$, $F_{X_{puissance}}^{\phantom{aa}-}(U) \sim X_{puissance}$}
\end{center}



\subsection{Conditions météorologiques et chaines de Markov $(H_k)_{k \in \mathbb{N}^{*}}$}

\begin{center}
\begin{minipage}[r]{0.1\textwidth}

\end{minipage}
\begin{minipage}[r]{0.8\textwidth}
L'on cherche à réaliser un modèle simulant des observations journalières de nos états météorologique.

Pour ce faire (et de façon assez naturelle, nous établirons une \textit{chaine de Markov} $(H_k)_{k \in \mathbb{N}^{*}}$, possédant les propriétés suivantes :

\end{minipage}
\end{center}





\begin{description}

\item[\bsc{* Processus Aléatoire $(H_k)_{k \in \mathbb{N}^{*}}$ : }]

\textit{Soit $(H_k)_{k \in \mathbb{N}^{*}} \in (E, \mathcal{A}, \mathbb{P})^{\mathbb{N}^{*}}$}

\phantom{aaaaaaa} — \textit{On note} $E = \{ \text{beau temps}, \text{temps couvert}, \text{pluie} \}$, dit \textit{« ensemble des états de $(H_k)_{k \in \mathbb{N}^{*}}$ »}.

\phantom{aaaaaaa} — \textit{On note} $\mu_0$, \textit{une mesure de probabilité sur $(E, \mathcal{A})$, dite « loi initiale de $(H_k)_{k \in \mathbb{N}^{*}}$ », tel que $(\mu_0(i))_{i \in [|1,3|]}$, est une permutation quelconque de $(1,0,0)$}.

\phantom{aaaaaaa} — \textit{On note} $Q \in M_3(\mathbb{R})$, \textit{une matrice stochastique, dite « matrice de transition de $(H_k)_{k \in \mathbb{N}^{*}}$ », tel que $\forall k \in \mathbb{N}^{*}$\footnotemark[1]} : 

\begin{displaymath}
\begin{bmatrix}
\mathbb{P}(H_{k+1} = 1 | H_k = 1) & \mathbb{P}(H_{k+1} = 2 | H_k = 1) & \mathbb{P}(H_{k+1} = 3 | H_k = 1)\\
\mathbb{P}(H_{k+1} = 1 | H_k = 2) & \mathbb{P}(H_{k+1} = 2 | H_k = 2) & \mathbb{P}(H_{k+1} = 3 | H_k = 2)\\
\mathbb{P}(H_{k+1} = 1 | H_k = 3) & \mathbb{P}(H_{k+1} = 2 | H_k = 3) & \mathbb{P}(H_{k+1} = 3 | H_k = 3)
\end{bmatrix}
\end{displaymath}


\end{description}




\begin{tcolorbox}[colback=black!30,colbacklower=black!20,colframe=black!20,rightrule=1mm,sidebyside,arc=0mm]


\begin{displaymath}
\begin{bmatrix}
p_{1,1} & p_{1,2} & p_{1,3}\\
p_{2,1} & p_{2,2} & p_{2,3}\\
p_{3,1} & p_{3,2} & p_{3,3}
\end{bmatrix}
\end{displaymath}


\tcblower
\begin{tikzpicture}[->,>=stealth',shorten >=1.4pt,auto,node distance=2cm,
                    thick,main node/.style={circle,draw,font=\sffamily\Large\bfseries}]

\node[main node] (1) {1};
\node[main node] (2) [below left of=1] {2};
\node[main node] (3) [below right of=1] {3};

  \path[every node/.style={font=\sffamily\small}]
    (1) edge node [left] {$p_{1,3}$} (3)
        edge [bend right] node[left] {$p_{1,2}$} (2)
        edge [loop above] node {$p_{1,1}$} (1)
    (2) edge node [right] {$p_{2,1}$} (1)
        edge node {$p_{2,3}$} (3)
        edge [loop left] node {$p_{2,2}$} (2)
        %edge [bend right] node[left] {$p_{2,1}$} (1)
    (3) edge node [bend right] {$p_{3,2}$} (2)
        edge [bend right] node[right] {$p_{3,1}$} (1)
        edge [loop right] node[right] {$p_{3,3}$} (3);
\end{tikzpicture}

\end{tcolorbox}



\footnotetext[1]{Pour des raisons évidentes de lisibilité nous confondrons les états \textit{« beau temps »}, \textit{« temps couvert »} et \textit{« pluie »} avec les états respectifs : $1$, $2$, et $3$.}



\begin{center}
\begin{minipage}[r]{0.1\textwidth}

\end{minipage}
\begin{minipage}[r]{0.8\textwidth}

\textbf{\textit{Commentaires sur l'implémentation de la chaine de markov}}

\phantom{aaaaaaa}

Une première approche a été de partitionner notre intervalle : $[0,1]$, de telle sorte à pouvoir simuler n'importe qu'elle variable aléatoire à support fini, à l'aide d'une loi uniforme.

Cette approche a le malheureux inconvénient d'avoir (parmi ses implémentations les moins naïves), une complexité de l'ordre de $o(nln(n))$\footnotemark[1].

\phantom{aaaaaaa}

Comparativement, une autre approche dite de \textit{« Table de Walker\footnotemark[2] »} (certes plus couteuse en temps d'initialisation), a le bon gout d'avoir une complexité de l'ordre : $o(1)$.

\phantom{aaaaaaa}

« La \textit{méthode optimale} serait-elle fonction des conditions initiales? ». La question ne manque pas pertinence, après tout notre loi a support fini ne possède que 3 états. En ce sens une \textit{« Table de Walker »} est-elle réellement une méthode plus optimale que notre \textit{approche naïve}?

\phantom{aaaaaaa}

A cela nous avons deux objections :

\phantom{aaaaaaa}

 — Pour $k \in \mathbb{N}$, la simulation d'un trajectoire a $k$ étapes, d'une \textit{chaine de Markov} à $n$ états serait de l'ordre de $o(knln(n))$ avec notre approche naïve et de $o(k)$ avec notre \textit{table de walker\footnotemark[3]}.
 
 — Simuler convenablement des conditions météorologique à l'aide d'une unique \textit{chaine de Markov} a 3 états, nous apparait fort improbable. Il est fort à parier que l'utilisateur sera amené à faire varier le nombre d'états : $n$. En ce sens, notre \textit{« modèle à Table de Walker »}, se montre beaucoup plus robuste que le précédent.
 
\phantom{aaaaaaa}

Ainsi, nous faisons donc le pari de la \textit{robustesse} et de \textit{l'adaptabilité} de notre modèle. 


\begin{center}
\begin{tikzpicture}[->,>=stealth',shorten >=1.4pt,auto,node distance=2cm,
                    thick,main node/.style={circle,draw,font=\sffamily\Large\bfseries}]

\node[main node] (1) {1};
\node[main node] (2) [below left of=1] {2};
\node[main node] (3) [below right of=1] {3};

  \path[every node/.style={font=\sffamily\small}]
    (1) edge node [left] {$p_{1,3}$} (3)
        edge [bend right] node[left] {$p_{1,2}$} (2)
        edge [loop above] node {$p_{1,1}$} (1)
    (2) edge node [right] {$p_{2,1}$} (1)
        edge node {$p_{2,3}$} (3)
        edge [loop left] node {$p_{2,2}$} (2)
        %edge [bend right] node[left] {$p_{2,1}$} (1)
    (3) edge node [bend right] {$p_{3,2}$} (2)
        edge [bend right] node[right] {$p_{3,1}$} (1)
        edge [loop right] node[right] {$p_{3,3}$} (3);
\end{tikzpicture}
\end{center}
 


\footnotetext[1]{$n = |E|$ et $E$, l'ensemble des états de la variable aléatoire a support fini.}

\footnotetext[2]{Vous trouverez en annexe la construction de notre \textit{« Table de Walker »}.}

\footnotetext[3]{Nous ne comptons pas l'étape d'initialisation, qui est dans le pire des cas d'ordre $o(n^2)$.}
\end{minipage}
\end{center}


\newpage
\subsection{Occurrences des sinistres (modèle A)}
\begin{center}
\begin{minipage}[r]{0.1\textwidth}

\end{minipage}
\begin{minipage}[r]{0.8\textwidth}
À chaque état de notre \textit{chaine de Markov} ($(1,2,3)$) est associé une valeur $\lambda_k \in \mathbb{R}_{+}^{*}$ (respectivement $(\lambda_1,\lambda_2,\lambda_3)$.

Notons $N \in \mathbb{N}$, la taille de notre portefeuille.

\textit{« On suppose que, pour chaque jour $k \in \mathbb{N}$, les dates des sinistres déclarés par l'assuré le jour $k$ suivent, conditionnellement à la valeur de $H_k$, un processus de Poisson d'intensité $\lambda_{H_k}$ »}.

\phantom{aaaaaaa}

Ainsi, nous définissons : 

\end{minipage}
\end{center}


\begin{description}

\item[\bsc{* Fonction}]

\textit{$\Delta(\omega) : $ : $\mathbb{R}_{+} \to \mathbb{R}_{+}$}

\begin{displaymath}
	\Delta : 
	\begin{cases}
		\text{$\mathbb{R}_{+} \to \mathbb{R}_{+}$}\\
		t \longmapsto \mathds{1}_{[0,365]}(t) \lambda_{H_{\lfloor t \rfloor}}
	\end{cases}
	.
\end{displaymath}


\item[\bsc{* Fonction}]

\textit{$\mu(\omega) : $ : $\mathbb{R}_{+} \to \mathbb{R}_{+}$}

\begin{displaymath}
\mu(t) = \int_{0}^{t} \Delta(x) dx = \int_{0}^{t} \mathds{1}_{[0,365]}(x) \lambda_{H_{\lfloor x \rfloor}} dx
\end{displaymath}


\item[\bsc{* Suite de processus de poisson in-homogène mélange : }]

\textit{$(R_t^{(k)})_{k \in [|1,N|]}$}

\phantom{aaaaaaa} — \textit{$(R_t^{(k)})_{k \in [|1,N|]}$, une suite de processus de poisson in-homogène mélange indépendant.}

\phantom{aaaaaaa} — \textit{$\forall (k,t) \in [|1,N|] \times \mathbb{R}_{+}$,  $R_t^{(k)} \sim P(\mu(t))$, le  processus de poisson in-homogène mélange indépendants représentant les temps d'occurrence des sinistres du contrat $k$.}

\begin{displaymath}
\forall t \in \mathbb{R}_{+} \text{, } R_t = \sum_{i=1}^{N} R_t^{(i)}
\end{displaymath}

\end{description}


\begin{displaymath}
\forall t \in [0,365] \text{, } \mu(t) = \int_{0}^{t} \Delta(x) dx = \int_{0}^{t} \mathds{1}_{[0,365]}(x) \lambda_{H_{\lfloor x \rfloor}} dx = \int_{0}^{t} \lambda_{H_{\lfloor x \rfloor}} dx
\end{displaymath}

\begin{displaymath}
= \int_{0}^{1} \lambda_{H_{\lfloor x \rfloor}} dx + \int_{1}^{2} \lambda_{H_{\lfloor x \rfloor}} dx + ... + \int_{\lfloor t \rfloor - 1}^{\lfloor t \rfloor} \lambda_{H_{\lfloor x \rfloor}} dx + \int_{\lfloor t \rfloor}^{t} \lambda_{H_{\lfloor x \rfloor}} dx
\end{displaymath}

\begin{displaymath}
= \int_{0}^{1} \lambda_{H_{0}} dx + \int_{1}^{2} \lambda_{H_{1}} dx + ... + \int_{\lfloor t \rfloor - 1}^{\lfloor t \rfloor} \lambda_{H_{\lfloor t \rfloor - 1}} dx + \int_{\lfloor t \rfloor}^{t} \lambda_{H_{\lfloor t \rfloor}} dx
\end{displaymath}

\begin{displaymath}
= \lambda_{H_{0}} + \lambda_{H_{1}} + ... + \lambda_{H_{\lfloor t \rfloor - 1}} + \int_{\lfloor t \rfloor}^{t} \lambda_{H_{\lfloor t \rfloor}} dx
\end{displaymath}


\begin{displaymath}
= \sum_{i=0}^{\lfloor t \rfloor - 1} \lambda_{H_{i}} + \lambda_{H_{\lfloor t \rfloor}} \times (t - \lfloor t \rfloor)
\end{displaymath}


\newpage
\begin{displaymath}
\forall t \in \mathbb{R}_{+} \text{, } R_t = \sum_{i=1}^{N} \underbrace{R_t^{(i)}}_{\sim P(\mu(t))} \sim P(N\times \mu(t)) \iff
\end{displaymath}

\begin{displaymath}
R_t \text{est un processus de poisson in-homogène mélange d'intensité : } \Delta^{*} = N \Delta
\end{displaymath}


\begin{center}
\begin{minipage}[r]{0.1\textwidth}

\end{minipage}
\begin{minipage}[r]{0.8\textwidth}
Il nous suffit donc de simuler une seule loi de poisson pour nos $N$ contrats.
\end{minipage}

Posons donc : $\forall t \in \mathbb{R}$, \colorbox{black!30}{$\Delta^{*}(t) = N \mathds{1}_{[0,365]}(t) \lambda_{H_{\lfloor t \rfloor}}$.}
\end{center}


\begin{center}
\begin{minipage}[r]{0.1\textwidth}

\end{minipage}
\begin{minipage}[r]{0.8\textwidth}
Cette définition a le bon gout d'être aisément majorable par une formule simple : $\theta = N \times max(\lambda_1,\lambda_2,\lambda_3)$.
\end{minipage}
\end{center}




\begin{tcolorbox}[colback=black!30,colbacklower=black!20,colframe=black!20,rightrule=1mm,arc=0mm]


\begin{center}
Montrons nous toutefois sceptiques vis a vis de notre modèle.

Partir du postulat que nos assurés partage une météo commune, n'est pas une idée totalement absurde dans l'absolue, mais reste néanmoins extrêmement discutable dans les faits. Il faudrait pour cela faire l'hypothèse que nos assurés vivent sur un même territoire et que ce territoire est assez restreint pour que sa météo reste uniforme et uni-variée.

Le modèle B, fait l'hypothèse inverse (qui est tout aussi discutable).

Notre modèle A repose sur une autre hypothèse : que l'état de la météo au jour $n$, dépends uniquement de l'état de la météo au jours $n-1$.

Nous n'expliqueront pas a quel point cette hypothèse est absurde, néanmoins la valeur d'un modèle ne se limite pas a la somme de la valeur de ses axiomes (ex : les modèles de base de la micro-économie).
\end{center}

\end{tcolorbox}


\begin{center}
\includegraphics[width=12cm,height=3.4cm]{img6}
\end{center}









\newpage
\subsection{Probabilité de Ruine Annuelle (modèle A et B)}

\begin{description}

\item[\bsc{* Modèle de Réserves : }]

\textit{$\forall (N, u, c) \in \mathbb{N} \times \mathbb{R}^2$, $(T_i)_{i \in \mathbb{N}^{*}}$, une suite de variables aléatoires identiquement distribuées et croissantes.}

\phantom{aaaaaaa} — \textit{On note $N$, la taille de notre portefeuille.}

\phantom{aaaaaaa} — \textit{On note $u$, l'investissement initial et individuel par assurés.}

\phantom{aaaaaaa} — \textit{On note $c$, le taux de prime par assuré et par unité de temps.}

\phantom{aaaaaaa} — \textit{On note $(T_i)_{i \in \mathbb{N}^{*}}$, la suite des dates de sinistres déclarés (de tous les assurés). La suite est par ailleurs ordonnée.}

\phantom{aaaaaaaaaaaaaaa} — \textit{$\forall t \in \mathbb{R}^{+} :$}

\[ R_t = Nu + Nct - \sum_{i=1}^{+ \infty} \mathds{1}_{[0,t]}(T_i) \text{ } X_i \]


\item[\bsc{* Partition $A$ de $[0,365]$ : }]

\textit{$\forall k \in \mathbb{N}$.}

\phantom{aaaaaaa} — \textit{$n = inf \bigl\{ k \in \mathbb{N}^{*} | T_k \in [0,365] \bigr\}$}

\begin{displaymath}
A_k =
\begin{cases}
	[0,T_1[ \text{ , si k = } 0 \\
	[T_k, T_{k+1}[ \text{ , si } k \in [|1, n-1 |] \\
	[T_n,365] \text{ , si } k = n \\
	\emptyset \text{ , sinon }
\end{cases}
\end{displaymath}


\phantom{aaaaaaaaaaaaaaa} — \textit{$(A_k)_{k \in \mathbb{N}}$ forme une partition de $[0,365]$.}
\end{description}



\begin{center}
\begin{minipage}[r]{0.1\textwidth}

\end{minipage}
\begin{minipage}[r]{0.8\textwidth}
Soit : $\forall \omega \in \Omega$, $R_t(\omega)$, est bien définie sur $[0,365]$.
On a donc : 
\end{minipage}
\end{center}

\[ \min_{t \in [0,365]} R_t(\omega) = \min_{k \in [|0,n|]} (\min_{t \in A_k} R_t(\omega)) \]


\begin{center}
\begin{minipage}[r]{0.1\textwidth}

\end{minipage}
\begin{minipage}[r]{0.8\textwidth}
Cette partition ($(A_k)_{k \in \mathbb{N}}$), nous permet d'exprimer tout minimum local ($\min_{t \in A_k} R_t(\omega)$), sous une forme explicite (plus ou moins simple) : 
\end{minipage}
\end{center}

\[ \forall (k,t) \in \mathbb{N} \times A_k, \text{ } R_t(\omega) = Nu + Nct - \sum_{i=1}^{+ \infty} \mathds{1}_{[0,t]}(T_i(\omega)) \text{ } X_i(\omega) \]

\[ = Nu + Nct - \sum_{i=1}^{k} X_i(\omega) \iff \]

\begin{displaymath}
\min_{t \in A_k} R_t(\omega) =
\begin{cases}
	Nu \text{ , si k = } 0 \\
	Nu + NcT_k(\omega) - \sum_{i=1}^{k} X_i(\omega) \text{ , si } k \in [|1, n |]
\end{cases}
\end{displaymath}



\begin{center}
\begin{minipage}[r]{0.1\textwidth}

\end{minipage}
\begin{minipage}[r]{0.8\textwidth}
, car par soucis de réalisme l'on considère que $c \in \mathbb{R}_{+}^{*}.$
\end{minipage}
\end{center}




\begin{center}
\begin{minipage}[r]{0.1\textwidth}

\end{minipage}
\begin{minipage}[r]{0.8\textwidth}
Nous avons donc le résultat suivant : 
\end{minipage}
\end{center}

\[ \min_{t \in [0,365]} R_t(\omega) = Nu + \min_{k \in [|1,n|]} (NcT_k(\omega) - \sum_{i=1}^{k} X_i(\omega)) \]

\[ = Nu + \min_{k \in [|1,n|]} (\sum_{i=1}^{k} (\dfrac{NcT_k(\omega)}{k} - X_i(\omega))) \]


\begin{center}
\begin{minipage}[r]{0.1\textwidth}

\end{minipage}
\begin{minipage}[r]{0.8\textwidth}
Ce résultat nous permet de caractériser l'événement suivant :
\end{minipage}
\end{center}


\[ \left( \min_{t \in [0,365]} R_t < 0 \right) = \left( \exists k \in [|1,n|] \text{ , tel que : } \sum_{i=1}^{k} (\dfrac{NcT_k}{k} - X_i) < -Nu \right) \]

\begin{center}
\begin{minipage}[r]{0.1\textwidth}

\end{minipage}
\begin{minipage}[r]{0.8\textwidth}
Il nous suffirait donc de procédé pas à pas.
\end{minipage}
\end{center}

\[ \text{Soit } (V_j)_{j \in \mathbb{N}} \text{, une suite de v.a.i.i.d., tel que } \forall j \in \mathbb{N}, \]


\hypertarget{ref2}{\[ V_j \sim \mathbb{B}(\mathbb{P} \left( \exists k \in [|1,n|] \text{ , tel que : } \sum_{i=1}^{k} (\dfrac{NcT_k}{k} - X_i) < -Nu \right) )\]}



\begin{center}
\begin{minipage}[r]{0.1\textwidth}

\end{minipage}
\begin{minipage}[r]{0.8\textwidth}
Par loi des grands nombres nous avons :
\end{minipage}
\end{center}



\[ \dfrac{1}{p} \sum_{j=1}^{p} V_j \underset{p \to +\infty}{\overset{p.s.}{\longrightarrow}} \mathbb{P}\left( \min_{t \in [0,365]} R_t < 0 \right) \]



\begin{center}
\begin{minipage}[r]{0.1\textwidth}

\end{minipage}
\begin{minipage}[r]{0.8\textwidth}
Le fait que nous ayons deux sommes (d'une part $\sum_{i=1}^{k} (\dfrac{NcT_k}{k} - X_i)$ et d'une autre $\sum_{j=1}^{p} V_j$ ), rend le problème parallélisable.
\end{minipage}
\end{center}


\begin{center}
\includegraphics[width=12cm,height=3.4cm]{img7}
\end{center}


\phantom{aaaaaaa}

\phantom{aaaaaaa}


\begin{center}
\begin{minipage}[r]{0.1\textwidth}

\end{minipage}
\begin{minipage}[r]{0.8\textwidth}

\textbf{\textit{Réduction de variance}}

\phantom{aaaaaaa}

\end{minipage}
\end{center}









\subsection{Occurrences des sinistres (modèle B)}





\newpage
\part{Aspects Programmation}
\section{Commentaires sur les techniques de programmation}
%\pagecolor{blue!20}
\pagecolor{black!30}



\subsection{Dépendances}
\begin{center}
\begin{minipage}[r]{0.1\textwidth}
\textcolor{black!60}{1}

\textcolor{black!60}{2}

\textcolor{black!60}{3}

\textcolor{black!60}{4}

\textcolor{black!60}{5}

\textcolor{black!60}{6}
\end{minipage}
\begin{minipage}[r]{0.82\textwidth}

\textcolor{teal}{import} random as rd

\textcolor{teal}{import} numpy as np

\textcolor{teal}{import} matplotlib.pyplot as plt \textcolor{mymauve}{\# \textit{graphics}}

\textcolor{teal}{import} plotly.express as px \textcolor{mymauve}{\# \textit{graphics}}

\textcolor{teal}{import} threading \textcolor{mymauve}{\# \textit{parallélisation}}

\textcolor{teal}{import} bisect \textcolor{mymauve}{\# \textit{insertion dans une liste triée}}

\end{minipage}
\end{center}



\subsection{$X_{norm}$}
\begin{center}
\begin{minipage}[r]{0.1\textwidth}

\end{minipage}
\begin{minipage}[r]{0.8\textwidth}
$f_{norm}$, est une fonction complexe et au vue de sa forme, il parait fort peu probable de trouver une forme explicite à son intégrale (sur un intervalle quelconque).

\phantom{aaaaaaa}

Une méthode similaire à celle de \textit{Box-Muller}, a brièvement été évoquée, sans succès.

\phantom{aaaaaaa}

« La méthode du rejet semble donc s'imposer d'elle même ? ». Il s'agit encore d'une question d'arbitrage.
Faut-il faire le choix de la meilleure des complexités, en approchant la fonction de répartition de  $X_{norm}$, par des formules explicites incorrectes, ou préférer à la complexité une juste représentation de sa loi?

\phantom{aaaaaaa}

Nous avons de prime abord opté pour l'implémentation d'une méthode de rejet dont le support serait la loi uniforme $U([0,b])$\footnotemark[1].

De plus, la majoration suivante, apparait de façon quasi-immédiate : $f_{norm} \leq 2$.



\footnotetext[1]{La densité $f_{norm}$ étant nulle en dehors de l'intervalle $[0,b]$, il est naturel d'utiliser comme loi de proposition une uniforme sur ce même intervalle.}
\end{minipage}
\end{center}


\begin{algorithm}
\caption{Algorithme de rejet}
\begin{algorithmic}[1]
\State $i \gets True$
\While{$i$}
\State $U \gets \sim U([0,b])$
\State $Y \gets \sim U([0,2])$
\If {$Y \leq f_{norm}(U)$}
\textbf{return } $U$
\EndIf
\EndWhile
\end{algorithmic}
\end{algorithm}

\newpage
\textbf{Première approche :}




\begin{center}
\begin{minipage}[r]{0.1\textwidth}
\textcolor{black!60}{1}

\textcolor{black!60}{2}

\textcolor{black!60}{3}

\end{minipage}
\begin{minipage}[r]{0.88\textwidth}

\textcolor{teal}{def} \textcolor{blue}{f\_norm}(x : \textcolor{codegreen}{float}, x\_0 : \textcolor{codegreen}{float}, b : \textcolor{codegreen}{float}, sigma : \textcolor{codegreen}{float}, delta : \textcolor{codegreen}{float}):

\phantom{aaaa}ind = (x \textcolor{mymauve}{>=} \textcolor{codegreen}{0}) \textcolor{mymauve}{\&} (x \textcolor{mymauve}{<=} b)

\phantom{aaaa}\textcolor{teal}{return} ind\textcolor{mymauve}{*}(np.\textcolor{teal}{exp}(-((x - x0)\textcolor{mymauve}{**}\textcolor{codegreen}{2}) \textcolor{mymauve}{/} (\textcolor{codegreen}{2} \textcolor{mymauve}{*} sigma\textcolor{mymauve}{**}\textcolor{codegreen}{2})) \textcolor{mymauve}{*} (\textcolor{codegreen}{1} + np.\textcolor{teal}{cos}(\textcolor{codegreen}{2}\textcolor{mymauve}{*}np.\textcolor{teal}{pi}\textcolor{mymauve}{*}(x - x0)\textcolor{mymauve}{/}delta)\textcolor{mymauve}{**}\textcolor{codegreen}{2}))

\end{minipage}
\end{center}







\begin{center}
\begin{minipage}[r]{0.1\textwidth}
\textcolor{black!60}{1}

\phantom{aa}

\textcolor{black!60}{2}

\textcolor{black!60}{3}

\textcolor{black!60}{4}

\textcolor{black!60}{5}

\textcolor{black!60}{6}

\textcolor{black!60}{7}

\textcolor{black!60}{8}

\end{minipage}
\begin{minipage}[r]{0.88\textwidth}

\textcolor{teal}{def} \textcolor{blue}{echantillon\_f\_norm}(x\_0 : \textcolor{codegreen}{float}, b : \textcolor{codegreen}{float}, sigma : \textcolor{codegreen}{float}, delta : \textcolor{codegreen}{float}, n : \textcolor{codegreen}{int}):

\phantom{aaaa}res \textcolor{mymauve}{=} $[]$

\phantom{aaaa}\textcolor{teal}{while len}(res) \textcolor{mymauve}{<} n:

\phantom{aaaaaaaa}X \textcolor{mymauve}{=} np.\textcolor{teal}{random.uniform}(\textcolor{codegreen}{0}, b) \textcolor{mymauve}{\# \textit{f\_norm est nulle sur [b,inf]}}

\phantom{aaaaaaaa}Y \textcolor{mymauve}{=} np.\textcolor{teal}{random.uniform}(\textcolor{codegreen}{0}, M)

\phantom{aaaaaaaa}\textcolor{teal}{if} Y \textcolor{mymauve}{<=} f\_norm(X, x0, b, sigma, delta):

\phantom{aaaaaaaaaaaa}res.\textcolor{teal}{append}(X) \textcolor{mymauve}{\# \textit{condition d'acceptation}}

\phantom{aaaa}\textcolor{teal}{return} res
\end{minipage}
\end{center}

\phantom{aaaa}

\textbf{Deuxième approche :}
\begin{center}
\begin{minipage}[r]{0.1\textwidth}

\end{minipage}
\begin{minipage}[r]{0.8\textwidth}
Conscients que
cette méthode n'est sans doute pas la plus efficace au vue de la forme de $f_{norm}$ nous avons donc opté pour une seconde méthode.

La loi $\mathbb{P}_{norm}$ étant très proche d'une loi normale, nous avons pensé à faire une méthode de rejet vis à vis de cette dernière.

\phantom{aaaa}

Nous avons donc majoré le rapport $\dfrac{f_{norm}}{g}$, avec $g$ la densité d'une loi normale.

Cela garantit une meilleure efficacité du rejet : la probabilité d'acceptation augmente, et donc le
nombre moyen d'itérations\footnotemark[1] pour accepter un point diminue.

\footnotetext[1]{Qui fut précédemment de l'ordre de $2b$.}
\end{minipage}
\end{center}




\begin{algorithm}
\caption{Algorithme de rejet}
\begin{algorithmic}[1]
\State $i \gets True$
\While{$i$}
\State $U \gets \sim $ loi de densité $g$
\State $Y \gets \sim U([0,M])$
\If {$Y \times g(U) \leq f(U)$}
\textbf{return } $U$
\EndIf
\EndWhile
\end{algorithmic}
\end{algorithm}

\textbf{Nouvelle approche :}



\begin{center}
\begin{minipage}[r]{0.1\textwidth}
\textcolor{black!60}{1}

\textcolor{black!60}{2}

\end{minipage}
\begin{minipage}[r]{0.88\textwidth}

\textcolor{teal}{def} \textcolor{blue}{g}(x : \textcolor{codegreen}{float}, x\_0 : \textcolor{codegreen}{float}, sigma : \textcolor{codegreen}{float}):

\phantom{aaaa}ind = (x \textcolor{mymauve}{>=} \textcolor{codegreen}{0}) \textcolor{mymauve}{\&} (x \textcolor{mymauve}{<=} b)

\phantom{aaaa}\textcolor{teal}{return} (\textcolor{codegreen}{1} \textcolor{mymauve}{/} (np.\textcolor{teal}{sqrt}(\textcolor{codegreen}{2}\textcolor{mymauve}{*}np.\textcolor{teal}{pi})\textcolor{mymauve}{*}sigma)) \textcolor{mymauve}{*} np.\textcolor{teal}{exp}(-((x - x0)\textcolor{mymauve}{**}\textcolor{codegreen}{2}) \textcolor{mymauve}{/} (\textcolor{codegreen}{2} \textcolor{mymauve}{*} sigma\textcolor{mymauve}{**}\textcolor{codegreen}{2}))

\end{minipage}
\end{center}





\begin{center}
\begin{minipage}[r]{0.1\textwidth}
\textcolor{black!60}{1}

\phantom{aa}

\textcolor{black!60}{2}

\textcolor{black!60}{3}

\textcolor{black!60}{4}

\textcolor{black!60}{5}

\textcolor{black!60}{6}

\textcolor{black!60}{7}

\textcolor{black!60}{8}

\textcolor{black!60}{9}

\end{minipage}
\begin{minipage}[r]{0.88\textwidth}

\textcolor{teal}{def} \textcolor{blue}{echantillon\_f\_norm\_opt}(x\_0 : \textcolor{codegreen}{float}, b : \textcolor{codegreen}{float}, sigma : \textcolor{codegreen}{float}, delta : \textcolor{codegreen}{float}, n : \textcolor{codegreen}{int}):

\phantom{aaaa}M \textcolor{mymauve}{=} \textcolor{codegreen}{2}\textcolor{mymauve}{*}np.\textcolor{teal}{sqrt}(\textcolor{codegreen}{2}\textcolor{mymauve}{*}np.\textcolor{teal}{pi})\textcolor{mymauve}{*}sigma

\phantom{aaaa}res \textcolor{mymauve}{=} $[]$

\phantom{aaaa}\textcolor{teal}{while len}(res) \textcolor{mymauve}{<} n:

\phantom{aaaaaaaa}X \textcolor{mymauve}{=} np.\textcolor{teal}{random.normal}(\textcolor{codegreen}{x0}, sigma)

\phantom{aaaaaaaa}Y \textcolor{mymauve}{=} np.\textcolor{teal}{random.uniform}(\textcolor{codegreen}{0}, M)

\phantom{aaaaaaaa}\textcolor{teal}{if} Y\textcolor{mymauve}{*}g(X, x0, sigma) \textcolor{mymauve}{<=} f\_norm(X, x0, b, sigma, delta):

\phantom{aaaaaaaaaaaa}res.\textcolor{teal}{append}(X) \textcolor{mymauve}{\# \textit{condition d'acceptation}}

\phantom{aaaa}\textcolor{teal}{return} res
\end{minipage}
\end{center}





\subsection{$X_{puissance}$}
\begin{center}
\begin{minipage}[r]{0.1\textwidth}

\end{minipage}
\begin{minipage}[r]{0.8\textwidth}
Cette partie sera relativement succincte. Les causes de cette concision sont doubles : 

\phantom{aaaa}— Premièrement car tous les calculs ont déjà été traités dans la partie \hyperlink{ref1}{\textcolor{blue}{\textbf{\textit{Modélisation}}}}.
 
\phantom{aaaa}— Deuxièmement car le code qui y est associé est lui même relativement succint.

La complexité est ici en temps constant et nous voyons mal comment optimiser ce code sans passer par un \textit{interfacage c++}.
\end{minipage}
\end{center}



\textbf{Le code dans toute sa beauté fonctionnelle :}

\begin{center}
\begin{minipage}[r]{0.1\textwidth}
\textcolor{black!60}{1}

\textcolor{black!60}{2}

\end{minipage}
\begin{minipage}[r]{0.88\textwidth}

\textcolor{teal}{def} \textcolor{blue}{run\_loi\_de\_puissance}(a : \textcolor{codegreen}{float}, alpha : \textcolor{codegreen}{float}):

\phantom{aaaa}\textcolor{teal}{return} a\textcolor{mymauve}{*}(\textcolor{codegreen}{1} \textcolor{mymauve}{-} rd.\textcolor{teal}{random}())\textcolor{mymauve}{**}(\textcolor{codegreen}{1}\textcolor{mymauve}{/}(\textcolor{codegreen}{1}\textcolor{mymauve}{-}alpha))
\end{minipage}
\end{center}



\subsection{$Z$}
\begin{center}
\begin{minipage}[r]{0.1\textwidth}

\end{minipage}
\begin{minipage}[r]{0.8\textwidth}
$Z$ suit une loi de probabilité qui nous est inconnue, il n'existe donc aucune \textit{implémentation optimale} de cette dernière (que ce soit en terme de code et ou de complexité).

Il parait assez évident, qu'une approche par \textit{« inversion de la fonction de répartition »}, serait complètement hors propos.

A terme, nous avons finalement opter pour une méthode de rejet (bien que la \textit{« table de walker »} nous ait un instant effleurer l'esprit).

\phantom{aa}

Par la suite nous restructurons notre code pour le rendre moins sensible a la casse.

\phantom{aa}

La programmation orientée objet nous offre un paradigme bien plus adaptable et robuste au changement de paramètres.

Elle structure notre code et lui offre une architecture bien plus \textit{arborescente}.
\end{minipage}
\end{center}



\subsection{$X$}



\begin{center}
\begin{minipage}[r]{0.1\textwidth}
\textcolor{black!60}{1}

\textcolor{black!60}{2}

\phantom{aa}

\phantom{aa}

\phantom{aa}

\phantom{aa}

\phantom{aa}

\phantom{aa}

\textcolor{black!60}{3}

\textcolor{black!60}{4}

\textcolor{black!60}{5}

\textcolor{black!60}{6}

\textcolor{black!60}{7}

\textcolor{black!60}{8}

\textcolor{black!60}{9}

\textcolor{black!60}{10}

\textcolor{black!60}{11}

\textcolor{black!60}{12}

\textcolor{black!60}{13}

\textcolor{black!60}{14}

\textcolor{black!60}{15}

\textcolor{black!60}{16}

\phantom{aa}

\textcolor{black!60}{17}

\textcolor{black!60}{18}

\textcolor{black!60}{19}

\textcolor{black!60}{20}

\textcolor{black!60}{21}

\phantom{aa}

\phantom{aa}

\textcolor{black!60}{22}

\textcolor{black!60}{23}

\phantom{aa}

\phantom{aa}

\end{minipage}
\begin{minipage}[r]{0.88\textwidth}

\textcolor{teal}{class} \textcolor{blue}{Settings}():

\phantom{aaaa}\textcolor{teal}{def} \textcolor{blue}{\_\_init\_\_}(self, x\_0\textcolor{mymauve}{=}np.\textcolor{blue}{random.uniform}(\textcolor{codegreen}{0},\textcolor{codegreen}{1}), b\textcolor{mymauve}{=}np.\textcolor{blue}{random.uniform}(\textcolor{codegreen}{0.1},\textcolor{codegreen}{1}), sigma\textcolor{mymauve}{=}np.\textcolor{blue}{random.uniform}(\textcolor{codegreen}{0.1},\textcolor{codegreen}{1}), delta\textcolor{mymauve}{=}np.\textcolor{blue}{random.uniform}(\textcolor{codegreen}{0.1},\textcolor{codegreen}{1}), a\textcolor{mymauve}{=}np.\textcolor{blue}{random.uniform}(\textcolor{codegreen}{0.1},\textcolor{codegreen}{1}), alpha\textcolor{mymauve}{=}np.\textcolor{blue}{random.uniform}(\textcolor{codegreen}{1},\textcolor{codegreen}{10}), u\textcolor{mymauve}{=}np.\textcolor{blue}{random.uniform}(\textcolor{codegreen}{100},\textcolor{codegreen}{200}), c\textcolor{mymauve}{=}np.\textcolor{blue}{random.uniform}(\textcolor{codegreen}{0.1},\textcolor{codegreen}{1}), N\textcolor{mymauve}{=}rd.\textcolor{blue}{randint}(\textcolor{codegreen}{1},\textcolor{codegreen}{10000}), monte\_carlo\_limit\textcolor{mymauve}{=}\textcolor{codegreen}{10000}, lambda\_01\textcolor{mymauve}{=}np.\textcolor{blue}{random.uniform}(\textcolor{codegreen}{0.1},\textcolor{codegreen}{1}), lambda\_02\textcolor{mymauve}{=}np.\textcolor{blue}{random.uniform}(\textcolor{codegreen}{0.1},\textcolor{codegreen}{1}), lambda\_03\textcolor{mymauve}{=}np.\textcolor{blue}{random.uniform}(\textcolor{codegreen}{0.1},\textcolor{codegreen}{1})):

\phantom{aaaaaaaa}\textcolor{red}{"""}

\phantom{aaaaaaaa}\textcolor{red}{Contient toutes les variables initiales de nos modeles}

\phantom{aaaaaaaa}\textcolor{red}{"""}

\phantom{aaaaaaaa}self.\textcolor{blue}{colors} \textcolor{mymauve}{=} {\textcolor{red}{"bg"} : \textcolor{codegreen}{0}}

\phantom{aaaaaaaa}self.\textcolor{blue}{parameters} \textcolor{mymauve}{=} \{ \textcolor{red}{"x 0"} : x\_0,

\phantom{aaaaaaaaaaaaaaaa}\textcolor{red}{"b"} : b,

\phantom{aaaaaaaaaaaaaaaa}\textcolor{red}{"sigma"} : sigma,

\phantom{aaaaaaaaaaaaaaaa}\textcolor{red}{"delta"} : delta,

\phantom{aaaaaaaaaaaaaaaa}\textcolor{red}{"a"} : a,

\phantom{aaaaaaaaaaaaaaaa}\textcolor{red}{"alpha"} : alpha,

\phantom{aaaaaaaaaaaaaaaa}\textcolor{red}{"u"} : u,

\phantom{aaaaaaaaaaaaaaaa}\textcolor{red}{"c"} : c,

\phantom{aaaaaaaaaaaaaaaa}\textcolor{red}{"N"} : N,

\phantom{aaaaaaaaaaaaaaaa}\textcolor{red}{"limite machine de monte carlo limit"} : monte\_carlo\_limit,

\phantom{aaaaaaaaaaaaaaaa}\textcolor{red}{"lambda 01"} : lambda\_01,

\phantom{aaaaaaaaaaaaaaaa}\textcolor{red}{"lambda 02"} : lambda\_02,

\phantom{aaaaaaaaaaaaaaaa}\textcolor{red}{"lambda 03"} : lambda\_03 \}

\phantom{aaaa}\textcolor{teal}{def} \textcolor{blue}{\_\_repr\_\_}(self):

\phantom{aaaaaaaa}\textcolor{teal}{return} \textcolor{red}{"Parametres du modèle : "} \textcolor{mymauve}{+} \textcolor{red}{"$\backslash$n"} \textcolor{mymauve}{+} \textcolor{red}{"$\backslash$n"}.\textcolor{blue}{join}([\textcolor{red}{" - "} \textcolor{mymauve}{+} \textcolor{codegreen}{str}(elt) \textcolor{mymauve}{+} \textcolor{red}{" : "} \textcolor{mymauve}{+} \textcolor{codegreen}{str}(self.\textcolor{blue}{parameters}[elt]) \textcolor{codegreen}{for} elt \textcolor{codegreen}{in} self.\textcolor{blue}{parameters}.\textcolor{blue}{keys}()])
        
\phantom{aaaa}\textcolor{teal}{def} \textcolor{blue}{\_\_str\_\_}(self):

\phantom{aaaaaaaa}\textcolor{teal}{return} \textcolor{red}{"Parametres du modèle : "} \textcolor{mymauve}{+} \textcolor{red}{"$\backslash$n"} \textcolor{mymauve}{+} \textcolor{red}{"$\backslash$n"}.\textcolor{blue}{join}([\textcolor{red}{" - "} \textcolor{mymauve}{+} \textcolor{codegreen}{str}(elt) \textcolor{mymauve}{+} \textcolor{red}{" : "} \textcolor{mymauve}{+} \textcolor{codegreen}{str}(self.\textcolor{blue}{parameters}[elt]) \textcolor{codegreen}{for} elt \textcolor{codegreen}{in} self.\textcolor{blue}{parameters}.\textcolor{blue}{keys}()])
\end{minipage}
\end{center}


\phantom{aaaa}


\phantom{aaaa}


\begin{center}
\begin{minipage}[r]{0.1\textwidth}

\end{minipage}
\begin{minipage}[r]{0.8\textwidth}
\begin{center}
Bien que le choix de stocker nos paramètres ait brièvement été aborder, les nombreuses ouvertures et fermetures de fichiers successives auraient un impact néfaste et difficilement quantifiable sur la qualité de notre code.
\end{center}
\end{minipage}
\end{center}






\begin{center}
\begin{minipage}[r]{0.1\textwidth}
\textcolor{black!60}{1}

\textcolor{black!60}{2}

\phantom{aa}

\textcolor{black!60}{3}

\textcolor{black!60}{4}

\textcolor{black!60}{5}

\textcolor{black!60}{6}

\phantom{aa}

\textcolor{black!60}{7}

\textcolor{black!60}{8}

\phantom{aa}

\phantom{aa}

\phantom{aa}

\textcolor{black!60}{9}

\textcolor{black!60}{10}

\phantom{aa}

\phantom{aa}

\textcolor{black!60}{11}

\textcolor{black!60}{12}

\textcolor{black!60}{13}

\phantom{aa}

\textcolor{black!60}{14}

\phantom{aa}

\textcolor{black!60}{15}

\textcolor{black!60}{16}

\textcolor{black!60}{17}

\textcolor{black!60}{18}

\phantom{aa}

\textcolor{black!60}{19}

\textcolor{black!60}{20}

\textcolor{black!60}{21}

\textcolor{black!60}{22}

\textcolor{black!60}{23}

\textcolor{black!60}{24}

\textcolor{black!60}{25}

\textcolor{black!60}{26}

\textcolor{black!60}{27}

\textcolor{black!60}{28}

\textcolor{black!60}{29}

\phantom{aa}

\textcolor{black!60}{30}

\textcolor{black!60}{31}

\phantom{aa}

\phantom{aa}

\phantom{aa}

\textcolor{black!60}{32}

\textcolor{black!60}{33}

\phantom{aa}

\textcolor{black!60}{34}


\end{minipage}
\begin{minipage}[r]{0.88\textwidth}

\textcolor{teal}{class} \textcolor{blue}{Sinistre}():

\phantom{aaaa}\textcolor{teal}{def} \textcolor{blue}{\_\_init\_\_}(self, settings\textcolor{mymauve}{=}ProjectSettings, p\textcolor{mymauve}{=}get\_a\_random\_distribution(n\textcolor{mymauve}{=}\textcolor{codegreen}{10})):

\phantom{aaaaaaaa}self.\textcolor{blue}{settings} \textcolor{mymauve}{=} settings

\phantom{aaaaaaaa}self.\textcolor{blue}{p} \textcolor{mymauve}{=} p

\phantom{aaaa}\textcolor{teal}{def} \textcolor{blue}{f\_norm}(self, x : \textcolor{codegreen}{float}):

\phantom{aaaaaaaa}\textcolor{red}{"""f\_norm est la loi selon  laquelle on doit simuler pour obtenir Pnorm"""}

\phantom{aaaaaaaa}ind \textcolor{mymauve}{=} (x \textcolor{mymauve}{>=} \textcolor{codegreen}{0}) \& (x \textcolor{mymauve}{<=} self.\textcolor{blue}{settings.parameters}[\textcolor{red}{"b"}])

\phantom{aaaaaaaa}\textcolor{teal}{return} ind\textcolor{mymauve}{*}(np.\textcolor{blue}{exp}(\textcolor{mymauve}{-}((x \textcolor{mymauve}{-} self.\textcolor{blue}{settings.parameters}[\textcolor{red}{"x 0"}])\textcolor{mymauve}{**}\textcolor{codegreen}{2}) \textcolor{mymauve}{/} (\textcolor{codegreen}{2} \textcolor{mymauve}{*} self.\textcolor{blue}{settings.parameters}[\textcolor{red}{"sigma"}]\textcolor{mymauve}{**}\textcolor{codegreen}{2})) \textcolor{mymauve}{*} (\textcolor{codegreen}{1}\textcolor{mymauve}{+} np.\textcolor{blue}{cos}(\textcolor{codegreen}{2}\textcolor{mymauve}{*}np.\textcolor{blue}{pi}\textcolor{mymauve}{*}(x \textcolor{mymauve}{-} self.\textcolor{blue}{settings.parameters}[\textcolor{red}{"x 0"}])\textcolor{mymauve}{/}self.\textcolor{blue}{settings.parameters}[\textcolor{red}{"delta"}])\textcolor{mymauve}{**}\textcolor{codegreen}{2}))

\phantom{aaaa}\textcolor{teal}{def} \textcolor{blue}{g}(self, x : \textcolor{codegreen}{float}):

\phantom{aaaaaaaa}\textcolor{teal}{return} (\textcolor{codegreen}{1} \textcolor{mymauve}{/} (np.\textcolor{blue}{sqrt}(\textcolor{codegreen}{2}\textcolor{mymauve}{*}np.\textcolor{blue}{pi})\textcolor{mymauve}{*}self.\textcolor{blue}{settings.parameters}[\textcolor{red}{"sigma"}])) \textcolor{mymauve}{*} np.\textcolor{blue}{exp}(\textcolor{mymauve}{-}((x \textcolor{mymauve}{-} self.\textcolor{blue}{settings.parameters}[\textcolor{red}{"x 0"}])\textcolor{mymauve}{**}\textcolor{codegreen}{2}) \textcolor{mymauve}{/} (\textcolor{codegreen}{2} \textcolor{mymauve}{*} self.\textcolor{blue}{settings.parameters}[\textcolor{red}{"sigma"}]\textcolor{mymauve}{**}\textcolor{codegreen}{2}))

\phantom{aaaa}\textcolor{teal}{def} f\_norm\_run(self):

\phantom{aaaaaaaa}\textcolor{codegreen}{while} \textcolor{orange!80}{True}:

\phantom{aaaaaaaaaaaa}X \textcolor{mymauve}{=} np.\textcolor{blue}{random.normal}(self.\textcolor{blue}{settings.parameters}[\textcolor{red}{"x 0"}], self.\textcolor{blue}{settings.parameters}[\textcolor{red}{"sigma"}])   
            
\phantom{aaaaaaaaaaaa}Y \textcolor{mymauve}{=} np.\textcolor{blue}{random.uniform}(\textcolor{codegreen}{0}, \textcolor{codegreen}{2}\textcolor{mymauve}{*}np.\textcolor{blue}{sqrt}(\textcolor{codegreen}{2}\textcolor{mymauve}{*}np.\textcolor{blue}{pi})\textcolor{mymauve}{*}self.\textcolor{blue}{settings.parameters}[\textcolor{red}{"sigma"}])

\phantom{aaaaaaaaaaaa}\textcolor{codegreen}{if} Y\textcolor{mymauve}{*}self.\textcolor{blue}{g}(x\textcolor{mymauve}{=}X) \textcolor{mymauve}{<=} self.\textcolor{blue}{f\_norm}(x\textcolor{mymauve}{=}X):

\phantom{aaaaaaaaaaaaaaaa}\textcolor{teal}{return} X \textcolor{mymauve}{\#condition \textit{d'acceptation, boucle brisée}}

\phantom{aaaa}\textcolor{teal}{def} \textcolor{blue}{loi\_de\_puissance\_run}(self):

\phantom{aaaaaaaa}\textcolor{teal}{return} self.\textcolor{blue}{settings.parameters}[\textcolor{red}{"a"}]\textcolor{mymauve}{*}(\textcolor{codegreen}{1} \textcolor{mymauve}{-} rd.\textcolor{blue}{random}())\textcolor{mymauve}{**}(\textcolor{codegreen}{1}\textcolor{mymauve}{/}(\textcolor{codegreen}{1}\textcolor{mymauve}{-}self.\textcolor{blue}{settings.parameters}[\textcolor{red}{"alpha"}]))

\phantom{aaaa}\textcolor{teal}{def} \textcolor{blue}{loi\_z\_run}(self):

\phantom{aaaaaaaa}M \textcolor{mymauve}{=} np.\textcolor{blue}{max}(self.\textcolor{blue}{p})

\phantom{aaaaaaaa}k \textcolor{mymauve}{=} \textcolor{codegreen}{len}(self.\textcolor{blue}{p})

\phantom{aaaaaaaa}\textcolor{codegreen}{while} \textcolor{orange!80}{True}:

\phantom{aaaaaaaaaaaa}I \textcolor{mymauve}{=} np.\textcolor{blue}{random.randint}(\textcolor{codegreen}{0}, k) 

\phantom{aaaaaaaaaaaa}U \textcolor{mymauve}{=} np.\textcolor{blue}{random.uniform}(\textcolor{codegreen}{0}, M)

\phantom{aaaaaaaaaaaa}\textcolor{codegreen}{if} U \textcolor{mymauve}{<=} self.\textcolor{blue}{p}[I]:

\phantom{aaaaaaaaaaaaaaaa}\textcolor{teal}{return} I \textcolor{mymauve}{\# \textit{condition d'acceptation}}

\phantom{aaaa}\textcolor{teal}{def} \textcolor{blue}{loi\_X\_run}(self):

\phantom{aaaaaaaa}z \textcolor{mymauve}{=} self.\textcolor{blue}{loi\_z\_run}()

\phantom{aaaaaaaaaaaa}\textcolor{teal}{return} (z \textcolor{mymauve}{==} \textcolor{codegreen}{0})\textcolor{mymauve}{*}self.\textcolor{blue}{f\_norm\_run}() \textcolor{mymauve}{+} (z \textcolor{mymauve}{==} \textcolor{codegreen}{1})\textcolor{mymauve}{*}self.\textcolor{blue}{loi\_de\_puissance\_run}() \textcolor{mymauve}{+} (z \textcolor{mymauve}{>} \textcolor{codegreen}{1})\textcolor{mymauve}{*}z

\phantom{aaaa}\textcolor{teal}{def} \textcolor{blue}{empiricLikelihood}(self, n\textcolor{mymauve}{=}\textcolor{codegreen}{4000}):

\phantom{aaaaaaaa}hist\_data \textcolor{mymauve}{=} [[self.\textcolor{blue}{f\_norm\_run}() \textcolor{codegreen}{for} i \textcolor{codegreen}{in} \textcolor{codegreen}{range}(n)],[self.\textcolor{blue}{loi\_de\_puissance\_run}() \textcolor{codegreen}{for} i \textcolor{codegreen}{in} \textcolor{codegreen}{range}(n)],[self.\textcolor{blue}{loi\_z\_run}() \textcolor{codegreen}{for} i \textcolor{codegreen}{in} \textcolor{codegreen}{range}(n)],[self.\textcolor{blue}{loi\_X\_run}() \textcolor{codegreen}{for} i \textcolor{codegreen}{in} \textcolor{codegreen}{range}(n)]]

\phantom{aaaaaaaa}group\_labels \textcolor{mymauve}{=} [\textcolor{red}{"X\_norm"}, \textcolor{red}{"X\_puissance"},\textcolor{red}{"Z"},\textcolor{red}{"X"}]

\phantom{aaaaaaaa}fig \textcolor{mymauve}{=} ff.\textcolor{blue}{create\_distplot}(hist\_data, group\_labels, show\_hist=\textcolor{orange!80}{False})

\phantom{aaaaaaaa}fig.\textcolor{blue}{show}()
\end{minipage}
\end{center}







\subsection{chaines de Markov $(H_k)_{k \in \mathbb{N}^{*}}$}
\begin{center}
\begin{minipage}[r]{0.1\textwidth}

\end{minipage}
\begin{minipage}[r]{0.8\textwidth}
Nous voulons cette partie relativement succincte. Dans cet effort continu de concision, nous ne détaillerons ici que le code de notre première implémentation\footnotemark[1].

\footnotetext[1]{Le code de la version optimisée étant de toute évidence disponible sur le \textit{notebook Master}.}
\end{minipage}
\end{center}



\begin{center}
\begin{minipage}[r]{0.1\textwidth}
\textcolor{black!60}{1}

\textcolor{black!60}{2}

\textcolor{black!60}{3}

\textcolor{black!60}{4}

\textcolor{black!60}{5}

\textcolor{black!60}{6}

\textcolor{black!60}{7}

\textcolor{black!60}{8}

\textcolor{black!60}{9}

\textcolor{black!60}{10}

\end{minipage}
\begin{minipage}[r]{0.88\textwidth}

\textcolor{teal}{def} \textcolor{blue}{simuler\_chaine\_markov}(M, H0, N):

\phantom{aaaa}d1, d2 \textcolor{mymauve}{=} M.\textcolor{blue}{shape}

\phantom{aaaa}\textcolor{codegreen}{assert} d1 \textcolor{mymauve}{==} d2, \textcolor{red}{"M doit être une matrice carrée"}

\phantom{aaaa}\textcolor{codegreen}{assert} \textcolor{codegreen}{1} \textcolor{mymauve}{<=} H0 \textcolor{mymauve}{<=} \textcolor{codegreen}{3}, \textcolor{red}{f"H0 doit être dans {{1,...,{d1}}}"}

\phantom{aaaa}H \textcolor{mymauve}{=} []

\phantom{aaaa}H.\textcolor{blue}{append}(H0)

\phantom{aaaa}\textcolor{codegreen}{for} i \textcolor{codegreen}{in range}(\textcolor{codegreen}{1}, N \textcolor{mymauve}{+} \textcolor{codegreen}{1}):

\phantom{aaaaaaaa}ligne \textcolor{mymauve}{=} M[H[i \textcolor{mymauve}{-} \textcolor{codegreen}{1}] \textcolor{mymauve}{-} \textcolor{codegreen}{1}]

\phantom{aaaaaaaa}H.\textcolor{blue}{append}(np.\textcolor{blue}{random.choice}(np.\textcolor{blue}{arange}(\textcolor{codegreen}{1},\textcolor{codegreen}{4}), p\textcolor{mymauve}{=}ligne))

\phantom{aaaa}\textcolor{teal}{return} np.\textcolor{blue}{array}(H)
\end{minipage}
\end{center}













\subsection{Vérifications d'usage}
\textbf{$X$ :}

\begin{center}
\begin{minipage}[r]{0.1\textwidth}

\end{minipage}
\begin{minipage}[r]{0.8\textwidth}
Nos \textit{densités empiriques}, sont visiblement conformes (ou du moins vraisemblables) aux densités $f_{norm}$, $f_{puissance}$ et $f_{Z}$ (ou $\mathbb{P}_{Z}$ conditionnellement a la nature de $Z$).
\end{minipage}
\end{center}

\begin{center}
\includegraphics[width=12cm,height=3.4cm]{img5}
\captionof{figure}{Densités respectives}
\end{center}


\textbf{Table de Walker :}

\begin{center}
\begin{minipage}[r]{0.1\textwidth}

\end{minipage}
\begin{minipage}[r]{0.8\textwidth}
Qui plus est, nous tenons (dans un soucis de concision) a notifier que les vérifications d'usage pour nos \textit{« tables de walker »} et autres \textit{chaines de markov} (dont les codes ne seront pas détaillés ci-dessous au vu de leurs complexités) sont libre access sur les \href{https://github.com/LaboiteNoire/techniques-de-simulations-}{\textcolor{blue}{\textbf{\textit{notebook}}}}.

\end{minipage}
\end{center}



\begin{center}
\begin{tikzpicture}[scale=0.50]
\begin{axis}[ybar interval, ymax=1 ,ymin=0, xmax=7 ,xmin=1, minor y tick num = 4]
\addplot coordinates { (1, 0.1) (2, 0.3) (3, 0.2) (4, 0.1) (5, 0.2) (6, 0.1)  (55, 0.2)};
\end{axis}
\end{tikzpicture}
\end{center}


\begin{center}
\includegraphics[width=12cm,height=3.4cm]{img9}
\captionof{figure}{Valeurs empiriques de notre \textit{« table de walker »} (n = $1000$)}
\end{center}



\begin{center}
\begin{minipage}[r]{0.1\textwidth}

\end{minipage}
\begin{minipage}[r]{0.8\textwidth}
Notre \textit{« table de walker »}, semble représenter fidèlement la distribution voulue.
\end{minipage}
\end{center}



\textbf{Chaine de Markov :}

\begin{center}
\begin{minipage}[r]{0.1\textwidth}

\end{minipage}
\begin{minipage}[r]{0.8\textwidth}
Afin de valider empiriquement la bonne implémentation de $(H_k)_{k \in \mathbb{N}^{*}}$, nous avons voulu comparer ses valeurs moyennes prises a grandes échéances avec nos valeurs théoriques espérées.

La chaine $(H_k)_{k \in \mathbb{N}^{*}}$ étant \textit{irréductible} et son ensemble d'états $E$ fini, nous sommes assurés de l'existence et par la même et l'unicité d'une \textit{« loi invariante »}, propre a $(H_k)_{k \in \mathbb{N}^{*}}$. 

\end{minipage}
\end{center}


\begin{center}
\begin{minipage}[r]{0.1\textwidth}
\textcolor{black!60}{1}

\textcolor{black!60}{2}

\textcolor{black!60}{3}

\phantom{aa}

\textcolor{black!60}{4}

\phantom{aa}

\textcolor{black!60}{5}

\phantom{aa}

\textcolor{black!60}{6}

\phantom{aa}

\end{minipage}
\begin{minipage}[r]{0.88\textwidth}

\textcolor{teal}{def} \textcolor{blue}{loi\_stationnaire}(M):

\phantom{aaaa}\textcolor{red}{"""calcul de la loi stationnaire"""}

\phantom{aaaa}vals, vecs \textcolor{mymauve}{=} np.\textcolor{blue}{linalg.eig}(M.T) \textcolor{mymauve}{\# \textit{on cherche un vecteur propre de M transposée pour la v.p. 1}}

\phantom{aaaa}idx \textcolor{mymauve}{=} np.\textcolor{blue}{argmin}(np.\textcolor{blue}{abs}(vals \textcolor{mymauve}{-} \textcolor{codegreen}{1})) \textcolor{mymauve}{\# \textit{cherche la position de la valeur 1 (ou environ 1 parfois arrondis)}}

\phantom{aaaa}pi \textcolor{mymauve}{=} np.\textcolor{blue}{real}(vecs[:, idx]) \textcolor{mymauve}{\# \textit{récupérer le vecteur : uniquement sa partie réelle (parfois partie imaginaire existe)}}

\phantom{aaaa}\textcolor{teal}{return} pi \textcolor{mymauve}{/} np.\textcolor{blue}{sum}(pi) \textcolor{mymauve}{\# \textit{normaliser pour avoir une mesure de proba}}
\end{minipage}
\end{center}




\begin{center}
\begin{minipage}[r]{0.1\textwidth}

\end{minipage}
\begin{minipage}[r]{0.8\textwidth}
\phantom{aa}

La \textbf{\textit{fonction}} \textcolor{blue}{loi\_stationnaire} renvoie un vecteur caractérisant la loi stationnaire de $(H_k)_{k \in \mathbb{N}^{*}}$.

\phantom{aa}
\end{minipage}
\end{center}




\begin{center}
\begin{minipage}[r]{0.1\textwidth}
\textcolor{black!60}{1}

\textcolor{black!60}{2}

\textcolor{black!60}{3}

\textcolor{black!60}{4}

\textcolor{black!60}{5}

\textcolor{black!60}{6}

\textcolor{black!60}{7}

\textcolor{black!60}{8}

\textcolor{black!60}{9}

\textcolor{black!60}{10}

\textcolor{black!60}{11}
\end{minipage}
\begin{minipage}[r]{0.88\textwidth}
pi1 \textcolor{mymauve}{=} loi\_stationnaire(M\_real)

H0 \textcolor{mymauve}{=} \textcolor{codegreen}{1}

N \textcolor{mymauve}{=} \textcolor{codegreen}{10000}

traj \textcolor{mymauve}{=} np.\textcolor{blue}{array}(simuler\_chaine\_markov(M\_real, H0, N))

plt.\textcolor{blue}{figure}()

plt.\textcolor{blue}{hist}(traj, bins\textcolor{mymauve}{=}[\textcolor{codegreen}{0.5}, \textcolor{codegreen}{1.5}, \textcolor{codegreen}{2.5}, \textcolor{codegreen}{3.5}], density\textcolor{mymauve}{=}\textcolor{orange!80}{True}, rwidth\textcolor{mymauve}{=}\textcolor{codegreen}{0.6})

plt.\textcolor{blue}{hlines}(pi1, xmin\textcolor{mymauve}{=}[\textcolor{codegreen}{0.5}, \textcolor{codegreen}{1.5}, \textcolor{codegreen}{2.5}], xmax\textcolor{mymauve}{=}[\textcolor{codegreen}{1.5}, \textcolor{codegreen}{2.5}, \textcolor{codegreen}{3.5}])

plt.\textcolor{blue}{xlabel}(\textcolor{red}{"État"})

plt.\textcolor{blue}{ylabel}(\textcolor{red}{"Fréquence"})

plt.\textcolor{blue}{title}(\textcolor{red}{"Fréquences empiriques et mesure invariante"})

plt.\textcolor{blue}{show}()
\end{minipage}
\end{center}




\begin{center}
\includegraphics[width=5cm,height=4.4cm]{img13}
\captionof{figure}{Résultat console...}
\end{center}




\begin{center}
\begin{minipage}[r]{0.1\textwidth}

\end{minipage}
\begin{minipage}[r]{0.8\textwidth}
\phantom{aa}

La superposition des barres correspondant aux fréquences empiriques et des lignes représentant la \textit{« mesure invariante »} a été rendue possible par un ajustement des largeurs de barres et permet de constater que la distribution empirique est cohérente avec le résultat théorique attendu, illustrant ainsi la convergence de la chaine.

\phantom{aa}
\end{minipage}
\end{center}






\newpage
\section{Les différents modèles}
\subsection{Modèle A}
\textbf{Première approche :}
\begin{center}
\begin{minipage}[r]{0.1\textwidth}

\end{minipage}
\begin{minipage}[r]{0.8\textwidth}
De prime abord, nous avons envisager de simuler étape par étapes notre sinistralité journalière, partant du postulat que l'agglomération de ces dernières formerait a terme notre sinistralité annuelle.  

En cette idée réside le cœur de notre implémentation première. 
\end{minipage}
\end{center}


\begin{center}
\begin{minipage}[r]{0.1\textwidth}
\textcolor{black!60}{1}

\textcolor{black!60}{2}

\textcolor{black!60}{3}

\textcolor{black!60}{4}

\textcolor{black!60}{5}

\textcolor{black!60}{6}

\textcolor{black!60}{7}

\textcolor{black!60}{8}

\textcolor{black!60}{9}

\end{minipage}
\begin{minipage}[r]{0.88\textwidth}

\textcolor{teal}{def} \textcolor{blue}{simuler\_processus\_poisson}(lambd, horizon\textcolor{mymauve}{=}\textcolor{codegreen}{1.0}):

\phantom{aaaa}T \textcolor{mymauve}{=} []

\phantom{aaaa}tn \textcolor{mymauve}{=} \textcolor{codegreen}{0}

\phantom{aaaa}\textcolor{codegreen}{while} \textcolor{orange!80}{True}:

\phantom{aaaaaaaa}tn \textcolor{mymauve}{+=} np.\textcolor{blue}{random.exponential}(\textcolor{codegreen}{1}\textcolor{mymauve}{/}lambd)

\phantom{aaaaaaaa}\textcolor{codegreen}{if} tn \textcolor{mymauve}{>} horizon:

\phantom{aaaaaaaaaaaa}\textcolor{codegreen}{break};

\phantom{aaaaaaaa}T.\textcolor{blue}{append}(tn)

\phantom{aaaa}\textcolor{teal}{return} np.\textcolor{blue}{array}(T)
\end{minipage}
\end{center}





\begin{center}
\begin{minipage}[r]{0.1\textwidth}

\end{minipage}
\begin{minipage}[r]{0.8\textwidth}
\phantom{aa}

La \textbf{\textit{fonction}} \textcolor{blue}{simuler\_sinistres\_avec\_temps} renvoie une liste de tuples : ($T_i$ : temps occurrence, $X_i$ : montant sinistre associé).

\phantom{aa}

La \textbf{\textit{fonction}} \textcolor{blue}{simuler\_processus\_poisson}, simule un processus de Poisson homogène sur $[0, horizon]$, puis renvoie la liste des temps d'occurrences $T_n$.

\phantom{aa}
\end{minipage}
\end{center}







\begin{center}
\begin{minipage}[r]{0.1\textwidth}
\textcolor{black!60}{1}

\phantom{aa}

\textcolor{black!60}{2}

\textcolor{black!60}{3}

\textcolor{black!60}{4}

\textcolor{black!60}{5}

\textcolor{black!60}{6}

\textcolor{black!60}{7}

\phantom{aa}

\textcolor{black!60}{8}

\textcolor{black!60}{9}

\textcolor{black!60}{10}

\textcolor{black!60}{11}


\end{minipage}
\begin{minipage}[r]{0.88\textwidth}

\textcolor{teal}{def} \textcolor{blue}{simuler\_sinistres\_avec\_temps}(H, lambd, p, x0, b, sigma, delta, a, alpha):

\phantom{aaaa}liste\_T\_X \textcolor{mymauve}{=} []  \textcolor{mymauve}{\# \textit{liste des couples (temps, montant)}}

\phantom{aaaa}\textcolor{codegreen}{for} jour \textcolor{codegreen}{in} \textcolor{codegreen}{range}(\textcolor{codegreen}{len}(H)):

\phantom{aaaaaaaa}etat \textcolor{mymauve}{=} H[jour] \textcolor{mymauve}{\# \textit{on récupère la météo du jour}}

\phantom{aaaaaaaa}lambda\_j \textcolor{mymauve}{=} lambd[etat \textcolor{mymauve}{-} \textcolor{codegreen}{1}] \textcolor{mymauve}{\# \textit{lambda associé à cette météo}}

\phantom{aaaaaaaa}temps \textcolor{mymauve}{=} simuler\_processus\_poisson(lambda\_j)

\phantom{aaaaaaaa}montants \textcolor{mymauve}{=} echantillon\_X\_rejet(p, x0, b, sigma, delta, a, alpha, \textcolor{codegreen}{len}(temps)) \textcolor{mymauve}{\# \textit{Simuler un montant pour chaque temps}}

\phantom{aaaaaaaa}\textcolor{codegreen}{for} i \textcolor{codegreen}{in} \textcolor{codegreen}{range}(\textcolor{codegreen}{len}(temps)):

\phantom{aaaaaaaaaaaa}t\textcolor{mymauve}{=}temps[i]

\phantom{aaaaaaaaaaaa}liste\_T\_X.\textcolor{blue}{append}((jour \textcolor{mymauve}{+} t, montants[i]))

\phantom{aaaa}\textcolor{teal}{return} liste\_T\_X

\end{minipage}
\end{center}






\newpage
\textbf{Seconde approche :}
\begin{center}
\begin{minipage}[r]{0.1\textwidth}

\end{minipage}
\begin{minipage}[r]{0.8\textwidth}
Cette partie bénéficiera grandement des formules exposés en \hyperlink{ref2}{\textcolor{blue}{\textbf{\textit{$3^e$ partie}}}}, sur notre capacité a procéder étapes par étapes, afin d'optimiser notre code.

En premier lieux, nous générons nos possibles dates d'occurrences par une \textit{simili} méthode de rejet, puis nous générons la trajectoire de la \textit{chaine de markov} portant en elle l'information nécessaire a la bonne formation de nos critères de rejet.

Il n'est ainsi pas nécessaire de générer toute la trajectoire de la météo journalière, si l'information que celle-ci nous apporte ne nous est pas indispensable.
\end{minipage}
\end{center}




\begin{algorithm}
\caption{Algorithme de rejet}
\begin{algorithmic}[1]
\State $\theta \gets N \times max(\lambda_1,\lambda_2,\lambda_3)$
\State $k \gets 0$
\State $N_{sim} \gets \sim P(\theta)$

$\text{Simuler } (T_1, . . . , T_N) \text{ suivant les points d’un processus de}$

$\text{Poisson homogène d'intensité } \theta \text{ dans } [0,356]$

$\text{Trier le vecteur } (T_1, . . . , T_N)$

\For{$i = 0$ \textbf{to} $N_{sim}$} 

$U \gets \sim U([0,1[)$ 

\If {La $\lfloor T_i \rfloor$-ème étape de $(H_k)_k$ a été simulée}
\If {$\theta*U \leq \Delta(T_i)$}
\State $k \gets k + 1$
\State $T_k^{'} \gets T_i$
\EndIf
\Else

Simuler la trajectoire jusqu'à la $\lfloor T_i \rfloor$-ème étape

\If {$\theta*U \leq \Delta(T_i)$}
\State $k \gets k + 1$
\State $T_k^{'} \gets T_i$
\EndIf
\EndIf
\EndFor

\Return{$(T_1^{'},...,T_k^{'})$}

\end{algorithmic}
\end{algorithm}





\begin{center}
\begin{minipage}[r]{0.1\textwidth}

\end{minipage}
\begin{minipage}[r]{0.8\textwidth}
L'implémentation ci-dessus est quelque peu inspirée d'une méthode de rejet. Par soucis d'honnêteté intellectuelle il nous faut reconnaitre la sensibilité de ce dernier aux valeurs importantes prises par $(\lambda_1, \lambda_2, \lambda_3)$.
\end{minipage}
\end{center}





\begin{center}
\begin{minipage}[r]{0.1\textwidth}
\textcolor{black!60}{1}

\textcolor{black!60}{2}

\phantom{aa}

\phantom{aa}

\phantom{aa}

\textcolor{black!60}{3}

\textcolor{black!60}{4}

\textcolor{black!60}{5}

\textcolor{black!60}{6}

\phantom{aa}

\textcolor{black!60}{7}

\phantom{aa}

\textcolor{black!60}{8}

\textcolor{black!60}{9}

\textcolor{black!60}{10}

\phantom{aa}

\phantom{aa}

\textcolor{black!60}{11}

\phantom{aa}

\phantom{aa}

\textcolor{black!60}{12}

\phantom{aa}

\phantom{aa}

\phantom{aa}

\textcolor{black!60}{13}

\textcolor{black!60}{14}

\textcolor{black!60}{15}

\textcolor{black!60}{16}

\textcolor{black!60}{17}

\phantom{aa}

\end{minipage}
\begin{minipage}[r]{0.88\textwidth}

\textcolor{teal}{def} \textcolor{blue}{run\_ruine}(self, rounds\textcolor{mymauve}{=}\textcolor{codegreen}{365}, draw\textcolor{mymauve}{=}\textcolor{orange!80}{True}):

\phantom{aaaa}N\_sim \textcolor{mymauve}{=} np.\textcolor{blue}{random.poisson}(lam\textcolor{mymauve}{=}self.\textcolor{blue}{theta}\textcolor{mymauve}{*}rounds)
        \textcolor{mymauve}{\# \textit{Nous essayer d'optimiser le code de façon a que l'on ait besoin de simuler toute la trajectoire de la chaine de markov, si et seulement si l'information qu'elle apport nous ait nécessaire.}}
        
\phantom{aaaa}\textcolor{codegreen}{for} k \textcolor{codegreen}{in} \textcolor{codegreen}{range}(N\_sim):

\phantom{aaaaaaaa}va\_transitoire \textcolor{mymauve}{=} np.\textcolor{blue}{random.uniform}(\textcolor{codegreen}{0},rounds)

\phantom{aaaaaaaa}va\_transitoire\_aux \textcolor{mymauve}{=} \textcolor{codegreen}{int}(va\_transitoire)

\phantom{aaaaaaaa}\textcolor{codegreen}{if} (va\_transitoire\_aux \textcolor{codegreen}{in} self.\textcolor{blue}{trajectory}): \textcolor{mymauve}{\# \textit{recherche en temps constant}}

\phantom{aaaaaaaaaaaa}\textcolor{codegreen}{if} (np.\textcolor{blue}{random.uniform}(\textcolor{codegreen}{0},self.\textcolor{blue}{theta}) \textcolor{mymauve}{<=} self.\textcolor{blue}{settings.parameters}[\textcolor{red}{"N"}]\textcolor{mymauve}{*}self.\textcolor{blue}{trajectory}[va\_transitoire\_aux]):
                
\phantom{aaaaaaaaaaaaaaaa}bisect.\textcolor{blue}{insort}(self.\textcolor{blue}{T},va\_transitoire) \textcolor{mymauve}{\# \textit{o(lnn)}}

\phantom{aaaaaaaaaaaa}\textcolor{codegreen}{else}:

\phantom{aaaaaaaaaaaaaaaa}\textcolor{codegreen}{for} i \textcolor{codegreen}{in} \textcolor{codegreen}{range}(va\_transitoire\_aux \textcolor{mymauve}{-} self.round \textcolor{mymauve}{+} \textcolor{codegreen}{2}): \textcolor{mymauve}{\# \textit{Nombre de tours qu'il nous reste pour que va\_transitioire\_aux soit dans le dictionnaire}}

\phantom{aaaaaaaaaaaaaaaaaaaa}self.\textcolor{blue}{state}, self.\textcolor{blue}{round}, self.\textcolor{blue}{trajectory}[self.\textcolor{blue}{round}] \textcolor{mymauve}{=} self.\textcolor{blue}{transitions\_walker\_table}[self.\textcolor{blue}{indexa}[self.\textcolor{blue}{state}]].\textcolor{blue}{run}(), self.\textcolor{blue}{round} \textcolor{mymauve}{+} \textcolor{codegreen}{1}, self.\textcolor{blue}{state}

\phantom{aaaaaaaaaaaaaaaaaaaa}\textcolor{codegreen}{if} (np.\textcolor{blue}{random.uniform}(\textcolor{codegreen}{0},self.\textcolor{blue}{theta}) \textcolor{mymauve}{<=} self.\textcolor{blue}{settings.parameters}[\textcolor{red}{"N"}]\textcolor{mymauve}{*}self.\textcolor{blue}{trajectory}[va\_transitoire\_aux]):

\phantom{aaaaaaaaaaaaaaaaaaaaaaaa}bisect.\textcolor{blue}{insort}(self.\textcolor{blue}{T},va\_transitoire) \textcolor{mymauve}{\# \textit{ o(lnn)}}

\phantom{aaaa}\textcolor{codegreen}{if} draw:

\phantom{aaaaaaaa}X \textcolor{mymauve}{=} [self.\textcolor{blue}{sinister.loi\_X\_run}() \textcolor{codegreen}{for} k \textcolor{codegreen}{in} \textcolor{codegreen}{range}(\textcolor{codegreen}{len}(self.\textcolor{blue}{T}))]

\phantom{aaaaaaaa}X[\textcolor{codegreen}{0}] \textcolor{mymauve}{=} \textcolor{codegreen}{0}

\phantom{aaaaaaaa}drawP(T\textcolor{mymauve}{=}self.\textcolor{blue}{T}, X\textcolor{mymauve}{=}X)

\phantom{aaaaaaaa}drawRt(T\textcolor{mymauve}{=}self.\textcolor{blue}{T}, X\textcolor{mymauve}{=}X, N\textcolor{mymauve}{=}self.\textcolor{blue}{settings.parameters}[\textcolor{red}{"N"}], u\textcolor{mymauve}{=}self.\textcolor{blue}{settings.parameters}[\textcolor{red}{"u"}], c\textcolor{mymauve}{=}self.\textcolor{blue}{settings.parameters}[\textcolor{red}{"c"}])
\end{minipage}
\end{center}



\subsection{Vérifications d'usage}

\begin{center}
\includegraphics[width=12cm,height=3.4cm]{img6}
\end{center}

\begin{center}
\includegraphics[width=12cm,height=3.4cm]{img8}
\end{center}





\subsection{Probabilité de ruine}
\textbf{Première approche :}

\begin{center}
\begin{minipage}[r]{0.1\textwidth}
\textcolor{black!60}{1}

\phantom{aa}

\textcolor{black!60}{2}

\textcolor{black!60}{3}

\textcolor{black!60}{4}

\textcolor{black!60}{5}

\textcolor{black!60}{6}

\phantom{aa}

\textcolor{black!60}{7}

\textcolor{black!60}{8}

\textcolor{black!60}{9}

\textcolor{black!60}{10}

\textcolor{black!60}{11}

\textcolor{black!60}{12}

\textcolor{black!60}{13}

\textcolor{black!60}{14}

\textcolor{black!60}{15}

\textcolor{black!60}{16}

\textcolor{black!60}{17}

\textcolor{black!60}{18}

\phantom{aa}

\textcolor{black!60}{19}

\textcolor{black!60}{20}

\textcolor{black!60}{21}

\textcolor{black!60}{22}

\phantom{aa}

\textcolor{black!60}{23}

\textcolor{black!60}{24}

\textcolor{black!60}{25}

\textcolor{black!60}{26}

\textcolor{black!60}{27}

\textcolor{black!60}{28}



\end{minipage}
\begin{minipage}[r]{0.88\textwidth}

\textcolor{teal}{def} \textcolor{blue}{modele\_A\_meteo\_commune}(N\_assures, u, c, horizon, M, H0, lambd, p, x0, b, sigma, delta, a, alpha):

\phantom{aaaa}H \textcolor{mymauve}{=} simuler\_chaine\_markov(M, H0, horizon)

\phantom{aaaa}T\_all \textcolor{mymauve}{=} []

\phantom{aaaa}X\_all \textcolor{mymauve}{=} []

\phantom{aaaa}\textcolor{codegreen}{for} i \textcolor{codegreen}{in} \textcolor{codegreen}{range}(N\_assures):

\phantom{aaaaaaaa}sinistres\_i \textcolor{mymauve}{=} simuler\_sinistres\_avec\_temps(H, lambd, p, x0, b, sigma, delta, a, alpha)

\phantom{aaaaaaaa}\textcolor{codegreen}{if} \textcolor{codegreen}{len}(sinistres\_i) \textcolor{mymauve}{>} \textcolor{codegreen}{0}:

\phantom{aaaaaaaaaaaa}T\_i \textcolor{mymauve}{=} np.\textcolor{blue}{array}([t \textcolor{codegreen}{for} (t, x) \textcolor{codegreen}{in} sinistres\_i])

\phantom{aaaaaaaaaaaa}X\_i \textcolor{mymauve}{=} np.\textcolor{blue}{array}([x \textcolor{codegreen}{for} (t, x) \textcolor{codegreen}{in} sinistres\_i])

\phantom{aaaaaaaaaaaa}T\_all.\textcolor{blue}{append}(T\_i)

\phantom{aaaaaaaaaaaa}X\_all.\textcolor{blue}{append}(X\_i)

\phantom{aaaa}\textcolor{mymauve}{\# \textit{S'il n'y a aucun sinistre chez tous les assurés}}

\phantom{aaaa}\textcolor{codegreen}{if} \textcolor{codegreen}{len}(T\_all) \textcolor{mymauve}{==} \textcolor{codegreen}{0}:

\phantom{aaaaaaaa}\textcolor{teal}{return} np.\textcolor{blue}{array}([]), np.\textcolor{blue}{array}([]), \textcolor{codegreen}{None}

\phantom{aaaa}\textcolor{mymauve}{\# \textit{On fusionne tous les sinistres dans une seule chronologie}}

\phantom{aaaa}T\_global \textcolor{mymauve}{=} np.\textcolor{blue}{concatenate}(T\_all)

\phantom{aaaa}X\_global \textcolor{mymauve}{=} np.\textcolor{blue}{concatenate}(X\_all)

\phantom{aaaa}indices\_tri \textcolor{mymauve}{=} np.\textcolor{blue}{argsort}(T\_global) \textcolor{mymauve}{\# \textit{retourne une permutation d'indices pour avoir les temps triés par ordre croissant}}

\phantom{aaaa}T\_global \textcolor{mymauve}{=} T\_global[indices\_tri]

\phantom{aaaa}X\_global \textcolor{mymauve}{=} X\_global[indices\_tri]

\phantom{aaaa}\textcolor{mymauve}{\# \textit{Calcul du processus de réserve agrégée}}

\phantom{aaaa}Rt \textcolor{mymauve}{=} N\_assures \textcolor{mymauve}{*} u \textcolor{mymauve}{+} N\_assures \textcolor{mymauve}{*} c \textcolor{mymauve}{*} T\_global \textcolor{mymauve}{-} np.\textcolor{blue}{cumsum}(X\_global)

\phantom{aaaa}\textcolor{mymauve}{\# \textit{Détection de la ruine}}

\phantom{aaaa}indices\_ruine \textcolor{mymauve}{=} np.\textcolor{blue}{where}(Rt \textcolor{mymauve}{<} \textcolor{mymauve}{0})[\textcolor{mymauve}{0}]

\phantom{aaaa}t\_ruine \textcolor{mymauve}{=} \textcolor{codegreen}{None}

\phantom{aaaa}\textcolor{codegreen}{if} \textcolor{codegreen}{len}(indices\_ruine) \textcolor{mymauve}{>} \textcolor{codegreen}{0}:

\phantom{aaaaaaaa}t\_ruine \textcolor{mymauve}{=} T\_global[indices\_ruine[\textcolor{codegreen}{0}]]

\phantom{aaaa}\textcolor{teal}{return} T\_global, Rt, t\_ruine

\end{minipage}
\end{center}








\textbf{Seconde approche :}
\begin{center}
\begin{minipage}[r]{0.1\textwidth}
\textcolor{black!60}{1}

\textcolor{black!60}{2}

\textcolor{black!60}{3}

\textcolor{black!60}{4}

\textcolor{black!60}{5}

\textcolor{black!60}{6}

\textcolor{black!60}{7}

\textcolor{black!60}{8}

\phantom{aa}

\textcolor{black!60}{9}

\textcolor{black!60}{10}

\textcolor{black!60}{11}




\end{minipage}
\begin{minipage}[r]{0.88\textwidth}

\textcolor{teal}{def} \textcolor{blue}{run}(self):

\phantom{aaaa}self.\textcolor{blue}{run\_ruine}(draw\textcolor{mymauve}{=}\textcolor{orange!80}{False})

\phantom{aaaa}d\_sum \textcolor{mymauve}{=} \textcolor{codegreen}{0} 

\phantom{aaaa}x\_sum \textcolor{mymauve}{=} \textcolor{codegreen}{0}

\phantom{aaaa}\textcolor{codegreen}{for} k \textcolor{codegreen}{in} \textcolor{codegreen}{range}(\textcolor{codegreen}{1},\textcolor{codegreen}{len}(self.\textcolor{blue}{T})):

\phantom{aaaaaaaa}d\_sum \textcolor{mymauve}{=} d\_sum \textcolor{mymauve}{+} self.\textcolor{blue}{settings.parameters}[\textcolor{red}{"N"}]\textcolor{mymauve}{*}self.\textcolor{blue}{settings.parameters}[\textcolor{red}{"c"}]\textcolor{mymauve}{*}self.\textcolor{blue}{T}[k]

\phantom{aaaaaaaa}x\_sum \textcolor{mymauve}{=} x\_sum \textcolor{mymauve}{+} self.\textcolor{blue}{sinister.loi\_X\_run}()

\phantom{aaaaaaaa}\textcolor{codegreen}{if} (d\_sum\textcolor{mymauve}{/}k \textcolor{mymauve}{-} x\_sum \textcolor{mymauve}{<= -}self.\textcolor{blue}{settings.parameters}[\textcolor{red}{"N"}]\textcolor{mymauve}{*}self.\textcolor{blue}{settings.parameters}[\textcolor{red}{"u"}]):

\phantom{aaaaaaaaaaaa}\textcolor{codegreen}{global} globsum\_moda

\phantom{aaaaaaaaaaaa}globsum\_moda \textcolor{mymauve}{=} globsum\_moda \textcolor{mymauve}{+} \textcolor{codegreen}{1}

\phantom{aaaaaaaaaaaa}\textcolor{codegreen}{break};


\end{minipage}
\end{center}





\begin{center}
\includegraphics[width=12cm,height=3.4cm]{img11}
\captionof{figure}{Évolution de la probabilité de ruine en fonction de $u$ et de $c$}
\end{center}



\begin{center}
\begin{minipage}[r]{0.1\textwidth}

\end{minipage}
\begin{minipage}[r]{0.8\textwidth}

Par égard pour notre exercice premier, nous avons trouver pertinente l'idée d'étudier le comportement de notre probabilité de ruine comparativement a nos niveaux de réserves($u$ et $c$). 

Ce résultat (conforme a nos prédictions, il faut bien l'admettre), renforce d'autant plus la crédibilité de notre modèle.

\phantom{aaaa}

En effet, il parait assez intuitif que réduire nos réserves (que cela se fasse par le biais de de l'investissement initial $u$, ou par le biais du taux de prime journalière $c$), expose un peu plus l'assureur au risque d'insolvabilité (entendez par la que la probabilité de ruine serait une fonction décroissante de nos réserves). 

\phantom{aaaa}

Cela nous offre d'une certaine façon des perspectives nouvelles.
Notre modèle stochastique pouvant se révélé lourd par certains aspects, nous pourrions interpoler ses résultats, ou entrainer un modèle d'apprentissage statistique quelconque a prédire les sorties de ce dernier. 
\end{minipage}
\end{center}




\begin{center}
\includegraphics[width=12cm,height=3.4cm]{img12}
\captionof{figure}{Évolution de la probabilité de ruine en fonction de $a$ et de $\alpha$}
\end{center}




\begin{center}
\begin{minipage}[r]{0.1\textwidth}

\end{minipage}
\begin{minipage}[r]{0.8\textwidth}

Ce dernier résultat semble mettre en lumière une certaine dépendance du modèle a la variable $a$.

Cette remarque nous offre une opportunité toute espérée pour entamer un dialogue autour de la crédibilité de nos \textit{« lois paramétriques »} $(\mathbb{P}_{X_{puissance}}, \mathbb{P}_{X_{norm}}, \mathbb{P}_X)$.
\end{minipage}
\end{center}







\begin{center}
\begin{minipage}[r]{0.6\textwidth}
Nous avons tracé ici l'histogramme de $X_{puissance}$ par la méthode de simulation et la densité
de la loi d'origine selon laquelle on cherche à simuler. Nous
avons ici rencontré une difficulté la décroissance étant très
rapide, les valeurs sont vite « tassées » vers $0$.

\end{minipage}
\begin{minipage}[r]{0.38\textwidth}

\begin{center}
\includegraphics[width=5cm,height=4.4cm]{img14}
\captionof{figure}{Résultat console...}
\end{center}
\end{minipage}
\end{center}




\begin{center}
\begin{minipage}[r]{0.42\textwidth}
\begin{center}
\includegraphics[width=5cm,height=4.4cm]{img15}
\captionof{figure}{Résultat console...}
\end{center}

\end{minipage}
\begin{minipage}[r]{0.56\textwidth}
Pour remédier à cela et avoir une meilleure vue du
graphique, nous avons fait le graphique en échelle
logarithmique. Une autre idée aurait aussi pu être de
prendre $\alpha < 1$ pour avoir une convergence moins rapide.
Ainsi, notre programme semblait adapté et conforme aux
attentes.
\end{minipage}
\end{center}



\begin{center}
\begin{minipage}[r]{0.6\textwidth}
Nous avons fait des tests où $Z$ était relativement
simple et prenait trois valeurs $0,1$ ou $2$. Un premier test
avec une forte probabilité que $Z=0$ se produise ce qui
veut dire une forte probabilité d'occurrence de petits
sinistres avec faible perte. On a donc tracé
l'histogramme. Celui ci nous a effectivement
permis de voir une forte concentration des sinistres avec
faibles valeurs même si on pouvait tout de même
laisser apparaître quelques autres sinistres.

\end{minipage}
\begin{minipage}[r]{0.38\textwidth}

\begin{center}
\includegraphics[width=5cm,height=4.4cm]{img16}
\captionof{figure}{Résultat console...}
\end{center}
\end{minipage}
\end{center}




\begin{center}
\begin{minipage}[r]{0.42\textwidth}
\begin{center}
\includegraphics[width=5cm,height=4.4cm]{img17}
\captionof{figure}{Résultat console...}
\end{center}

\end{minipage}
\begin{minipage}[r]{0.56\textwidth}
Ensuite, nous avons diminué la probabilité de $Z=0$ pour
vérifier que l'algorithme pouvait produire des sinistres plus
rares mais plus coûteux, c'est-à-dire générer une queue de
distribution plus prononcée. Les résultats ont confirmé ce
comportement, avec l'apparition de sinistres aux coûts élevés,
comme attendu.
\end{minipage}
\end{center}





\subsection{Modèle B}
\subsection{Complexités algorithmiques}


\part{Conclusion}
\section{Commentaires sur la pertinence du modèle}
\section{Évolutions possibles du modèle}
\begin{center}
\begin{minipage}[r]{0.1\textwidth}

\end{minipage}
\begin{minipage}[r]{0.8\textwidth}

Interfaçage avec d'autres langages peut-être plus performants : R, C++

Apprentissage statistique de notre modèle.

NB : vérifier que R soit plus performant que python.

\end{minipage}
\end{center}
\section{Commentaires}
\section{Annexes et contacts}

\subsection*{Annexes et contacts}



\begin{center}
\begin{minipage}[r]{0.4\textwidth}

\end{minipage}
\begin{minipage}[r]{0.4\textwidth}


\end{minipage}
\end{center}






\end{document}
