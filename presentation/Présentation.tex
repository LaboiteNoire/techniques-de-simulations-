\documentclass[10pt,a4paper]{article}
\title{Techniques de Simulations}
\author{
  PRISCILLA, GOGUY\\
  \texttt{priscilla.goguy@etu.univ-lyon1.fr}
  \and
  MAHLÎ, REINETTE\\
  \texttt{mahli.reinette@etu.univ-lyon1.fr}
}
\date{13/10/2025}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[french]{babel}
\usepackage{graphicx}
\usepackage{hyperref}

\usepackage{listings}
\usepackage{xcolor}


\usepackage[many]{tcolorbox}
\usepackage{lipsum}
\usepackage{tikz}
\usetikzlibrary{automata, positioning, arrows}
\usepackage{pgfplots}
\usepackage{xcolor}
\usepackage{amsfonts}
\usepackage{dsfont}
\usepackage{xr-hyper} 
\usepackage{hyperref} 
\usepackage{algpseudocode}
\usepackage{algorithm}
\externaldocument[B-]{docB}[Annexe01.pdf]% <- full or relative path


% le préambule











% initialisation des couleurs
\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}
\definecolor{mymauve}{rgb}{0.58,0,0.82}






%block de code 
\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},   
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,         
    breaklines=true,                 
    captionpos=b,                    
    keepspaces=true,                 
    numbers=left,                    
    numbersep=5pt,                  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    tabsize=2
}

\lstset{style=mystyle}






%initialisation graphics
\tikzset{
->,
node distance = 2cm}



















% le corps du document






% le préambule
\begin{document}
%titre
\pagecolor{black!20}
\maketitle


\begin{center}
\textbf{\textit{M1 Actuariat}}

\textbf{\textit{ISFA}}

\includegraphics[width=4cm,height=2cm]{img1}

\href{https://github.com/LaboiteNoire/techniques-de-simulations-}{\includegraphics[width=1cm,height=1cm]{img2}}

\end{center}


\newpage

\phantom{aaaaaa}

\tableofcontents

\newpage

\part{Préambule}

\subsection{Avant-propos}
\begin{center}
\begin{minipage}[r]{0.1\textwidth}

\end{minipage}
\begin{minipage}[r]{0.8\textwidth}

Toutes les ressources utilisées seront présentes en annexes et sur le \href{https://github.com/LaboiteNoire/techniques-de-simulations-}{\textit{\textbf{repository}}} github ci-dessus.
Dans une optique de rigueur absolue, nous tenterons de commenter chaque partie de notre code et essaierons de justifier nos méthodes de simulation.

\end{minipage}
\end{center}


\subsection{Notations}

\begin{description}

\item[\bsc{* $\mathcal{P}(\textbf{X})$ : }]

\textit{Soit \textbf{$\Omega$}, un ensemble quelconque.}

\phantom{aaaaaaa} — \textit{On note $\mathcal{P}(\Omega)$, l'ensemble des parties de $\Omega$.}

\item[\bsc{* $\sigma$-Algèbre de $\Omega$ : }]

\textit{Soit $\Omega$, un ensemble quelconque. $\mathcal{A} \subseteq \mathcal{P}(\Omega)$ est dite $\sigma$-Algèbre de $\Omega$ si :}

\phantom{aaaaaaa} — \textit{$\Omega$ $\in \mathcal{A}$}

\phantom{aaaaaaa} — \textit{$\forall A \in \mathcal{A}$, $\bar{A} \in \mathcal{A}$}

\phantom{aaaaaaa} — \textit{$\forall (A_n)_{n \in \mathbb{N}} \in \mathcal{A}^{\mathbb{N}}$, $\bigcup_{n \in \mathbb{N}} A_n \in \mathcal{A}$}

\phantom{aaaaaaaaaaaaaaa} — \textit{On notera la « tribu borélienne » : $\mathbb{B}(\mathbb{R}^n)$ et \phantom{aaaaaaaaaaaaaa} $\lambda$ : « mesure de Lebesgue ».}


\item[\bsc{* $\mu$ Mesure de probabilité sur $(\Omega, \mathcal{A})$ : }]

\textit{Soit $(\Omega, \mathcal{A})$, un couple dit « espace probabilisable »}

\phantom{aaaaaaa} — \textit{$\mu : \mathcal{A} \longrightarrow [0,1]$}

\phantom{aaaaaaa} — \textit{$\mu(\emptyset) = 0$}

\phantom{aaaaaaa} — \textit{$\forall (A_n)_{n \in \mathbb{N}} \in \mathcal{A}^{\mathbb{N}}$, une famille disjointe, $\mu(\bigsqcup_{n \in \mathbb{N}} A_n)$ = \phantom{aaaaaaaaaaaaaa} $\sum_{n \in \mathbb{N}} \mu(A_n)$}

\phantom{aaaaaaaaaaaaaaa} — \textit{On notera la « probabilité historique » : $\mathbb{P}$.}

\phantom{aaaaaaaaaaaaaaa} — \textit{On notera $(\Omega, \mathcal{A}, \mu)$ : « espace probabilisé ».}


\item[\bsc{* \textbf{X}, une variable aléatoire sur $(\Omega, \mathcal{A}, \mathbb{P})$ : }]

\textit{Soit $(\Omega, \mathcal{A}, \mathbb{P})$ : « espace probabilisé »}

\phantom{aaaaaaa} — \textit{$(\textbf{E}, \mathcal{E})$ : « espace mesurable »}

\phantom{aaaaaaa} — \textit{\textbf{X : } $(\Omega, \mathcal{A}, \mathbb{P})$ $\longrightarrow$ $(\textbf{E}, \mathcal{E})$}

\phantom{aaaaaaaaaaaaaaa} — \textit{$\forall B \in \mathcal{E}$, $\mathbb{P}_{X}(B)$ = $\mathbb{P}(\{ \omega \in \Omega | X(\omega) \in \mathcal{B} \})$}


\item[\bsc{* \textbf{X}, une variable aléatoire continue sur $(\Omega, \mathcal{A}, \mathbb{P})$ : }]

\textit{Soit $(\Omega, \mathcal{A}, \mathbb{P})$ : « espace probabilisé »}

\phantom{aaaaaaa} — \textit{$(\mathbb{R}^n, \mathbb{B}(\mathbb{R}^n), \lambda)$ : « espace mesuré »}

\phantom{aaaaaaa} — \textit{\textbf{X : } $(\Omega, \mathcal{A}, \mathbb{P})$ $\longrightarrow$ $(\mathbb{R}^n, \mathbb{B}(\mathbb{R}^n), \lambda)$}

\phantom{aaaaaaa} — \textit{$\mathbb{P}_{X}$ << $\lambda$\footnotemark[1]}

\phantom{aaaaaaaaaaaaaaa} — \textit{$\exists ! \rho : (\mathbb{R}^n, \mathbb{B}(\mathbb{R}^n), \lambda) \longrightarrow \mathbb{R}^{+}$\footnotemark[2], mesurable, tel que :}

\[ \mathbb{P}_{X}(A) = \int_{A} \rho(x) \,dx \]

\end{description}


\footnotetext[1]{$\forall A \in \mathbb{B}(\mathbb{R}^n)$, tel que $\lambda(A) = 0 \Longrightarrow \mathbb{P}_{X}(A) = 0$.}

\footnotetext[2]{Dite : \textit{« densité de \textbf{X} ».}}








\begin{description}

\item[\bsc{* Espérance \textbf{E[X]}, de la variable aléatoire \textbf{X} : }]

\textit{Soit \textbf{X}, une variable aléatoire sur $(\Omega, \mathcal{A}, \mathbb{P})$}

\phantom{aaaaaaa} — \textit{On note} \textbf{E[X]}, \textit{« l'espérance de \textbf{X} ».}

\phantom{aaaaaaaaaaaaaaa} — \textit{Si \textbf{X}, est discrète\footnotemark[1], alors :}

\[ \textbf{E[X]} = \sum_{k \in X(\Omega)} k \mathbb{P}_{X}(\{ k \}) \]

\phantom{aaaaaaaaaaaaaaa} — \textit{Si \textbf{X}, est continue de densité $\rho$, alors :}

\[  \textbf{E[X]} = \int x\rho(x) \,dx \]



\item[\bsc{* Fonction de Répartition $F_X$, de la variable aléatoire \textbf{X} : }]

\textit{Soit \textbf{X}, une variable aléatoire sur $(\Omega, \mathcal{A}, \mathbb{P})$}

\phantom{aaaaaaa} — \textit{On note} $\forall x \in \mathbb{R}$, $F_X(x) = \mathbb{P}_{X}(]-\infty, x])$ \textit{« la fonction de \phantom{aaaaaaaaaaaaaaa} répartition de \textbf{X} ».}



\item[\bsc{* Espace $L^p(\Omega, \mathcal{A}, \mathbb{P})$ : }]

\textit{Soit $(\Omega, \mathcal{A}, \mathbb{P})$}

\phantom{aaaaaaa} — \textit{On note} $L^p(\Omega, \mathcal{A}, \mathbb{P})$, \textit{l'ensemble :}

\begin{displaymath}
\{ \textbf{X} \text{variable aléatoire sur } (\Omega, \mathcal{A}, \mathbb{P}) | \textbf{E[}|\textbf{X}|^p\textbf{]} < + \infty \}
\end{displaymath}


\item[\bsc{* Moment d'ordre $p$ $m_p$\textbf{[X]}, de la variable aléatoire \textbf{X} : }]

\textit{$\forall$ \textbf{X}, $\in L^p(\Omega, \mathcal{A}, \mathbb{P})$}

\phantom{aaaaaaa} — \textit{On note} $m_p$\textbf{[X]} = $\textbf{E[}\textbf{X}^p\textbf{]}$


\item[\bsc{* Moment centré d'ordre $p$ $\mu_p$\textbf{[X]}, de la variable aléatoire \textbf{X} : }]

\textit{$\forall$ \textbf{X}, $\in L^p(\Omega, \mathcal{A}, \mathbb{P})$}

\phantom{aaaaaaa} — \textit{On note} $\mu_p$\textbf{[X]} = $\textbf{E[}(\textbf{X} - \textbf{E[X]})^p\textbf{]}$


\item[\bsc{* Variantes du moment centré d'ordre $2$, de la variable aléatoire \textbf{X} : }]

\textit{$\forall$ \textbf{X}, $\in L^2(\Omega, \mathcal{A}, \mathbb{P})$}

\phantom{aaaaaaa} — \textit{On note} \textbf{V}$(X)$ = $\mu_2$\textbf{[X]}, \textit{la : « variance de \textbf{X} »} 

\phantom{aaaaaaa} — \textit{On note $\sigma_{X}$ = $\sqrt{V(X)}$, « l'écart-type de \textbf{X} »} 





\item[\bsc{* Covariance, entre les variables aléatoires \textbf{X} et \textbf{Y} : }]

\textit{$\forall ($\textbf{X}, \textbf{Y}$)$ $\in L^2(\Omega, \mathcal{A}, \mathbb{P})^2$}


\phantom{aaaaaaa} — \textit{On note} \textbf{Cov}$(X,Y)$ = $\textbf{E[} (\textbf{X} - \textbf{E[X]})(\textbf{Y} - \textbf{E[Y]}) \textbf{]} $, \textit{la : « covariance entre \textbf{X} et \textbf{Y} »} 

\phantom{aaaaaaaaaaaaaaa} — \textit{$(L^2(\Omega, \mathcal{A}, \mathbb{P})$, \textbf{Cov}$)$, forme un « espace euclidien »} 



\item[\bsc{* Coefficient de corrélation linéaire, entre les variables aléatoires \textbf{X} et \textbf{Y} : }]

\textit{$\forall ($\textbf{X}, \textbf{Y}$)$ $\in L^2(\Omega, \mathcal{A}, \mathbb{P})^2$}


\phantom{aaaaaaa} — \textit{On note} $\rho_{X,Y}$ = $\dfrac{\textbf{Cov(X,Y)}}{\sigma_{X} \sigma_{Y}}$, \textit{la : « le coefficient de corrélation linéaire entre \textbf{X} et \textbf{Y} »}



\end{description}

\footnotetext[1]{$\mathbb{P}_{X}$ << $\mu$, ou $\mu$ est : la « mesure de comptage ».}



\newpage
\subsection{Objets du Problème}
\begin{center}
\begin{minipage}[r]{0.1\textwidth}

\end{minipage}
\begin{minipage}[r]{0.8\textwidth}

On cherche à approximer la probabilité de ruine pour un modèle de théorie de la ruine en
assurance moto. On étudie deux cas : un cas où les assurés sont indépendants, et un cas où ils
sont corrélés à travers des conditions météo communes.

\end{minipage}
\end{center}



\begin{description}

\item[\bsc{* La variable aléatoire $X_{norm}$ sur $(\mathbb{R},\mathbb{B}(\mathbb{R}))$ : }]

\textit{$\forall (x_0,b,\sigma,\delta) \in \mathbb{R} \times (\mathbb{R}_{+}^{*})^3$}

\phantom{aaaaaaa} — \textit{On note} $X_{norm}$,

\phantom{aaaaaaaaaaaaaaa} — \textit{la variable aléatoire continue de densité : $f_{norm}$ :}

\[ \forall x \in \mathbb{R}, \text{  } f_{norm}(x) = \mathds{1}_{[0,b]}(x) \text{ } exp(-\dfrac{(x-x_0)^2}{2\sigma^2}) \text{ } (1 + cos(2 \pi \dfrac{x - x_0}{\delta} )^2) \]



\item[\bsc{* La variable aléatoire $X_{puissance}$ sur $(\mathbb{R},\mathbb{B}(\mathbb{R}))$ : }]

\textit{$\forall (a, \alpha) \in \mathbb{R}_{+}^{*} \times ]1 : + \infty [$}

\phantom{aaaaaaa} — \textit{On note} $X_{puissance}$,

\phantom{aaaaaaaaaaaaaaa} — \textit{la variable aléatoire continue de densité : $f_{puissance}$\footnotemark[1] :}

\[ \forall x \in \mathbb{R}, \text{  } f_{puissance}(x) = \mathds{1}_{[a,+\infty [}(x) \text{ } x^{-\alpha} \times \dfrac{\alpha - 1}{a^{1-\alpha}} \]



\item[\bsc{* La variable aléatoire $Z$ sur $(\Omega, \mathcal{A}, \mathbb{P})$ : }]

\textit{Soit $Z(\Omega)$ = $\mathbb{N}$ et $(p_n)_{n \in \mathbb{N}} \in [0,1]^{\mathbb{N}}$ et tel que : $\sum_{n \in \mathbb{N}} p_n$ = 1}

\phantom{aaaaaaa} — \textit{On note} $Z$,

\phantom{aaaaaaaaaaaaaaa} — \textit{la variable aléatoire discrète, dont les probabilités \phantom{aaaaaaaaaaaaaaaaaaa} respectives sont ainsi notées :}

\[ \forall n \in \mathbb{N}, \text{  } p_n = \mathbb{P}(Z = n) \]


\phantom{aaaaaaaaaaaaaaaaaa} — \textit{On désignera par la suite sa probabilité de la sorte : $\mathbb{P}_Z$}



\item[\bsc{* La variable aléatoire \textbf{X} sur $(\Omega, \mathcal{A}, \mathbb{P})$ : }]

\textit{Soit : $X_{norm}$, $X_{puissance}$, $Z$, des variables aléatoires mutuellement indépendantes, de lois (et ou de densités) respectives : $f_{norm}$, $f_{puissance}$ et $\mathbb{P}_Z$.}

\phantom{aaaaaaa} — \textit{On note} \textbf{X},

\phantom{aaaaaaaaaaaaaaa} — \textit{la variable aléatoire, définie de la sorte :}

\begin{displaymath}
\textbf{X} = 
\begin{cases}
	X_{norm} \text{ si Z = } 0 \\
	X_{puissance} \text{ si Z = } 1 \\
	Z \text{ sinon}
\end{cases}
\end{displaymath}





\end{description}




\footnotetext[1]{\href{run:./Annexe01.pdf}{This is my link}}


\href{file:ax01.pdf}{File keyword}

\href{run:./Annexe01.pdf}{Run keyword}

\href{run:foo.pdf}{Ouvrir l'annexe}

\href{run:./foo.tex}{test}

\href{run:./file.txt}{File.txt}



\section{Organisation du travail}
\begin{center}
\begin{minipage}[r]{0.1\textwidth}

\end{minipage}
\begin{minipage}[r]{0.8\textwidth}

Concernant l'organisation du travail, nous avons jugé nécessaire de mettre en place un
environnement permettant de partager facilement nos ébauches de code, l'avancée du rendu ainsi
que tout document utile au bon déroulement du projet. Pour cela, nous avons créé une page \href{https://github.com/LaboiteNoire/techniques-de-simulations-}{\textit{GitHub}}
dédiée.

\phantom{aaaaaaa}

La communication s'est faite principalement via un groupe de discussion sur les réseaux sociaux,
mais aussi lors d'échanges directs en classe ou au cours de réunions informelles consacrées à
l'avancement du projet.

\phantom{aaaaaaa}

Sur le plan technique, la première séance en classe a été consacrée à l'analyse de chaque question
afin de déterminer les méthodes de simulation à utiliser et les optimisations possibles. Suite à cela,
le rôle de \href{https://github.com/priscilla1269}{\textit{Priscilla}} a été plutôt dirigé vers les implémentations de techniques de simulations
« classiques » tandis que \href{https://github.com/LaboiteNoire}{\textit{Mahlî}} a lui été plutôt chargé du côté optimisation du code notamment :
\textit{table de Walker}, classes...

\phantom{aaaaaaa}

Cela dit, de nombreuses parties du code ont été développées conjointement : chacun ayant parfois
besoin des conseils, des idées ou de l'expertise de l'autre pour la mise en place de structures de
données adaptées et pour garantir la cohérence globale de l'implémentation.

\phantom{aaaaaaa}


Enfin, nous avons choisi de travailler sur un \textit{Notebook Python}, un format qui nous a semblé plus
pratique pour organiser notre code, structurer nos sections et ajouter facilement titres et
commentaires. Par souci de clarté et de rigueur, nous avons rédigé les démonstrations
mathématiques associées aux différentes étapes de nos algorithmes. Conscients que ces éléments ne
constituent pas le cœur de la matière, nous avons choisi de les regrouper dans une annexe, où elles
restent consultables si nécessaire.

\end{minipage}
\end{center}


\subsection{Notes d'updates}
\begin{center}
\begin{minipage}[r]{0.1\textwidth}

\end{minipage}
\begin{minipage}[r]{0.8\textwidth}

Une section que l'on supprimera lors du projet final, mais qui me permet de laisser quelques petits commentaires.

Autant je peux concevoir l'utilité de faire une section optimisée et non optimisée pour $X_{norm}$, autant (comme tu l'as très justement fait remarquer) je ne pense pas que cela soit pertinent pour $X_{puissance}$.

\textbf{Il faut paralléliser la génération des sinistres du modèle A (compliqué, mais largement faisable)}


\textbf{Note a moi même : enlevé les tests en fin de page 5.}

\textbf{Note a moi même : enlevé les \_ de x\_0 dans les codeblock}



\end{minipage}
\end{center}


\part{Modélisation}
\section{modélisation}
\subsection{simulation de $X_{norm}$}
\subsection{Simulation de $X_{puissance}$}
\begin{displaymath}
\forall (a, \alpha) \in \mathbb{R}_{+}^{*} \times ]1 : + \infty [,
\end{displaymath}

\begin{center}
\begin{minipage}[r]{0.1\textwidth}

\end{minipage}
\begin{minipage}[r]{0.8\textwidth}
$X_{puissance}$ est une variable aléatoire continue, de densité $f_{puissance}$, tel que $\forall x \in \mathbb{R}$ :
\end{minipage}
\end{center}

\begin{displaymath}
f_{puissance}(x) = \mathds{1}_{[a,+\infty [}(x) \text{ } x^{-\alpha} \times \dfrac{\alpha - 1}{a^{1-\alpha}}
\end{displaymath}

\begin{center}
$\Updownarrow$
\end{center}

\begin{displaymath}
\forall t \in \mathbb{R}, F_{X_{puissance}}(t) = \mathbb{P}_{X_{puissance}}(]-\infty: t]) = \int_{-\infty}^{t} f_{puissance}(x) dx
\end{displaymath}

\begin{displaymath}
= \int_{-\infty}^{t} \mathds{1}_{[a,+\infty [}(x) \text{ } x^{-\alpha} \times \dfrac{\alpha - 1}{a^{1-\alpha}} dx
\end{displaymath}

\begin{displaymath}
= \mathds{1}_{[a,+\infty [}(t) \int_{a}^{t} \text{ } x^{-\alpha} \times \dfrac{\alpha - 1}{a^{1-\alpha}} dx = \mathds{1}_{[a,+\infty [}(t) \dfrac{\alpha - 1}{a^{1-\alpha}} \int_{a}^{t} \text{ } x^{-\alpha} dx
\end{displaymath}

\begin{displaymath}
= \mathds{1}_{[a,+\infty [}(t) \times \dfrac{\overbrace{\alpha - 1}^{= -(1 - \alpha)}}{a^{1-\alpha}} \times \left[ \dfrac{x^{1-\alpha}}{1-\alpha}\right]^{t}_{a} = - \mathds{1}_{[a,+\infty [}(t) \times \left[ \dfrac{x^{1-\alpha}}{a^{1-\alpha}}\right]^{t}_{a}
\end{displaymath}


\begin{displaymath}
= \mathds{1}_{[a,+\infty [}(t) \times \left[ \dfrac{x^{1-\alpha}}{a^{1-\alpha}}\right]^{a}_{t} = \mathds{1}_{[a,+\infty [}(t) \times \underbrace{\left[ x^{1-\alpha} \right]^{a}_{t}}_{= a^{1- \alpha} - t^{1- \alpha}} \times a^{\alpha - 1}
\end{displaymath}

\begin{displaymath}
= \mathds{1}_{[a,+\infty [}(t) \times \left(1- \left(\dfrac{t}{a}\right)^{1-\alpha} \right)
\end{displaymath}


\begin{center}
\begin{minipage}[r]{0.1\textwidth}

\end{minipage}
\begin{minipage}[r]{0.8\textwidth}
Posons $F_{X_{puissance}}^{\phantom{aa}-}$, la fonction définit de la sorte : $\forall y \in ]0,1[$ :

$F_{X_{puissance}}^{\phantom{aa}-}(y)$ = inf $\bigl\{ x \in \mathbb{R} \text{ | } y \leq \mathds{1}_{[a,+\infty [}(x) \times \left(1- \left(\dfrac{x}{a}\right)^{1-\alpha} \right) \bigr\}$
\end{minipage}
\end{center}



\begin{center}
\begin{minipage}[r]{0.1\textwidth}

\end{minipage}
\begin{minipage}[r]{0.8\textwidth}
Or $y \in ]0,1[ \iff 0 < y \iff \bigl\{ x \in \mathbb{R} \text{ | } y \leq \mathds{1}_{[a,+\infty [}(x) \times \left(1- \left(\dfrac{x}{a}\right)^{1-\alpha} \right) \bigr\}$ = $\bigl\{ x \in [a,+\infty [ \text{ | } y \leq \left(1- \left(\dfrac{x}{a}\right)^{1-\alpha} \right) \bigr\}$
\end{minipage}
\end{center}


\newpage

\begin{center}
\begin{minipage}[r]{0.1\textwidth}

\end{minipage}
\begin{minipage}[r]{0.8\textwidth}
inf$\bigl\{ x \in [a,+\infty [ \text{ | } y \leq 1- \left(\dfrac{x}{a}\right)^{1-\alpha} \bigr\}$ = inf$\bigl\{ x \in [a,+\infty [ \text{ | } y - 1 \leq - \left(\dfrac{x}{a}\right)^{1-\alpha} \bigr\}$ = sup$\bigl\{ x \in [a,+\infty [ \text{ | } \left(\dfrac{x}{a}\right)^{1-\alpha} \leq 1-y \bigr\}$ = sup$\bigl\{ x \in [a,+\infty [ \text{ | } \left(\dfrac{x}{a}\right) \leq \sqrt[1-\alpha]{1-y} \bigr\}$ = sup$\bigl\{ x \in [a,+\infty [ \text{ | } x \leq a\sqrt[1-\alpha]{1-y} \bigr\}$

\end{minipage}

Or $a\sqrt[1-\alpha]{1-y} = \dfrac{a}{\underbrace{\sqrt[\alpha-1]{1-y}}_{\in ]0,1[}} \in [a,+\infty [ \iff$

$F_{X_{puissance}}^{\phantom{aa}-}(y) = sup\bigl\{ x \in [a,+\infty [ \text{ | } x \leq a\sqrt[1-\alpha]{1-y} \bigr\}$ = $sup[a,a\sqrt[1-\alpha]{1-y} ]$ = \colorbox{black!30}{$a\sqrt[1-\alpha]{1-y}$}
\end{center}


\begin{center}
\begin{minipage}[r]{0.1\textwidth}

\end{minipage}
\begin{minipage}[r]{0.8\textwidth}
\hypertarget{ref1}{A l'aune de cette information nouvelle, nous pouvons établir notre modèle de la sorte} :  
\end{minipage}

\colorbox{black!30}{Soit $U \sim \mathcal{U}(]0,1[)$, $F_{X_{puissance}}^{\phantom{aa}-}(U) \sim X_{puissance}$}
\end{center}


\subsection{Conditions météorologiques et chaines de Markov $(H_k)_{k \in \mathbb{N}^{*}}$}

\begin{center}
\begin{minipage}[r]{0.1\textwidth}

\end{minipage}
\begin{minipage}[r]{0.8\textwidth}
L'on cherche a réaliser un modèle simulant des observations journalières de nos états météorologique.

Pour ce faire (et de façon assez naturelle, nous établirons une \textit{chaine de Markov} $(H_k)_{k \in \mathbb{N}^{*}}$, possédant les propriétés suivantes :

\end{minipage}
\end{center}





\begin{description}

\item[\bsc{* Processus Aléatoire $(H_k)_{k \in \mathbb{N}^{*}}$ : }]

\textit{Soit $(H_k)_{k \in \mathbb{N}^{*}} \in (E, \mathcal{A}, \mathbb{P})^{\mathbb{N}^{*}}$}

\phantom{aaaaaaa} — \textit{On note} $E = \{ \text{beau temps}, \text{temps couvert}, \text{pluie} \}$, dit \textit{« ensemble des états de $(H_k)_{k \in \mathbb{N}^{*}}$ »}.

\phantom{aaaaaaa} — \textit{On note} $\mu_0$, \textit{une mesure de probabilité sur $(E, \mathcal{A})$, dite « loi initiale de $(H_k)_{k \in \mathbb{N}^{*}}$ », tel que $(\mu_0(i))_{i \in [|1,3|]}$, est une permutation quelconque de $(1,0,0)$}.

\phantom{aaaaaaa} — \textit{On note} $Q \in M_3(\mathbb{R})$, \textit{une matrice stochastique, dite « matrice de transition de $(H_k)_{k \in \mathbb{N}^{*}}$ », tel que $\forall k \in \mathbb{N}^{*}$\footnotemark[1]} : 

\begin{displaymath}
\begin{bmatrix}
\mathbb{P}(H_{k+1} = 1 | H_k = 1) & \mathbb{P}(H_{k+1} = 2 | H_k = 1) & \mathbb{P}(H_{k+1} = 3 | H_k = 1)\\
\mathbb{P}(H_{k+1} = 1 | H_k = 2) & \mathbb{P}(H_{k+1} = 2 | H_k = 2) & \mathbb{P}(H_{k+1} = 3 | H_k = 2)\\
\mathbb{P}(H_{k+1} = 1 | H_k = 3) & \mathbb{P}(H_{k+1} = 2 | H_k = 3) & \mathbb{P}(H_{k+1} = 3 | H_k = 3)
\end{bmatrix}
\end{displaymath}


\end{description}




\begin{tcolorbox}[colback=black!30,colbacklower=black!20,colframe=black!20,rightrule=1mm,sidebyside,arc=0mm]


\begin{displaymath}
\begin{bmatrix}
p_{1,1} & p_{1,2} & p_{1,3}\\
p_{2,1} & p_{2,2} & p_{2,3}\\
p_{3,1} & p_{3,2} & p_{3,3}
\end{bmatrix}
\end{displaymath}


\tcblower
\begin{tikzpicture}[->,>=stealth',shorten >=1.4pt,auto,node distance=2cm,
                    thick,main node/.style={circle,draw,font=\sffamily\Large\bfseries}]

\node[main node] (1) {1};
\node[main node] (2) [below left of=1] {2};
\node[main node] (3) [below right of=1] {3};

  \path[every node/.style={font=\sffamily\small}]
    (1) edge node [left] {$p_{1,3}$} (3)
        edge [bend right] node[left] {$p_{1,2}$} (2)
        edge [loop above] node {$p_{1,1}$} (1)
    (2) edge node [right] {$p_{2,1}$} (1)
        edge node {$p_{2,3}$} (3)
        edge [loop left] node {$p_{2,2}$} (2)
        %edge [bend right] node[left] {$p_{2,1}$} (1)
    (3) edge node [bend right] {$p_{3,2}$} (2)
        edge [bend right] node[right] {$p_{3,1}$} (1)
        edge [loop right] node[right] {$p_{3,3}$} (3);
\end{tikzpicture}

\end{tcolorbox}



\footnotetext[1]{Pour des raisons évidentes de lisibilité nous confondrons les états \textit{« beau temps »}, \textit{« temps couvert »} et \textit{« pluie »} avec les états respectifs : $1$, $2$, et $3$.}



\begin{center}
\begin{minipage}[r]{0.1\textwidth}

\end{minipage}
\begin{minipage}[r]{0.8\textwidth}

\textbf{\textit{Commentaires sur l'implémentation de la chaine de markov}}

\phantom{aaaaaaa}

Une première approche a été de partitionner notre intervalle : $[0,1]$, de telle sorte a pouvoir simuler n'importe qu'elle variable aléatoire a support fini, a l'aide d'une loi uniforme.

Cette approche a le malheureux inconvénient d'avoir (parmi ses implémentations les moins naïves), une complexité de l'ordre de $o(nln(n))$\footnotemark[1].

\phantom{aaaaaaa}

Comparativement, une autre approche dite de \textit{« Table de Walker\footnotemark[2] »} (certes plus couteuse en temps d'initialisation), a le bon gout d'avoir une complexité de l'ordre : $o(1)$.

\phantom{aaaaaaa}

« La \textit{méthode optimale} serait-elle fonction des conditions initiales? ». La question ne manque pas pertinence, après tout notre loi a support finie ne possède que 3 états. En ce sens une \textit{« Table de Walker »} est-elle réellement une méthode plus optimale que notre \textit{approche naïve}?

\phantom{aaaaaaa}

A cela nous avons deux objections :

\phantom{aaaaaaa}

 — Pour $k \in \mathbb{N}$, la simulation d'un trajectoire a $k$ étapes, d'une \textit{chaine de Markov} a $n$ états serait de l'ordre de $o(knln(n))$ avec notre approche naïve et de $o(k)$ avec notre \textit{table de walker\footnotemark[3]}.
 
 — Simuler convenablement des conditions météorologique a l'aide d'une unique \textit{chaine de Markov} a 3 états, nous apparait fort improbable. Il est fort a parier que l'utilisateur sera amené a faire varier le nombre d'états : $n$. En ce sens, notre \textit{« modèle a Table de Walker »}, se montre beaucoup plus robuste que le précédent.
 
\phantom{aaaaaaa}

Ainsi, nous faisons donc le pari de la \textit{robustesse} et de \textit{l'adaptabilité} de notre modèle. 


\begin{center}
\begin{tikzpicture}[->,>=stealth',shorten >=1.4pt,auto,node distance=2cm,
                    thick,main node/.style={circle,draw,font=\sffamily\Large\bfseries}]

\node[main node] (1) {1};
\node[main node] (2) [below left of=1] {2};
\node[main node] (3) [below right of=1] {3};

  \path[every node/.style={font=\sffamily\small}]
    (1) edge node [left] {$p_{1,3}$} (3)
        edge [bend right] node[left] {$p_{1,2}$} (2)
        edge [loop above] node {$p_{1,1}$} (1)
    (2) edge node [right] {$p_{2,1}$} (1)
        edge node {$p_{2,3}$} (3)
        edge [loop left] node {$p_{2,2}$} (2)
        %edge [bend right] node[left] {$p_{2,1}$} (1)
    (3) edge node [bend right] {$p_{3,2}$} (2)
        edge [bend right] node[right] {$p_{3,1}$} (1)
        edge [loop right] node[right] {$p_{3,3}$} (3);
\end{tikzpicture}
\end{center}
 


\footnotetext[1]{$n = |E|$ et $E$, l'ensemble des états de la variable aléatoire a support fini.}

\footnotetext[2]{Vous trouverez en annexe la construction de notre \textit{« Table de Walker »}.}

\footnotetext[3]{Nous ne comptons pas l'étape d'initialisation, qui est dans le pire des cas d'ordre $o(n^2)$.}
\end{minipage}
\end{center}


\newpage
\subsection{Occurrences des sinistres (modèle A)}
\begin{center}
\begin{minipage}[r]{0.1\textwidth}

\end{minipage}
\begin{minipage}[r]{0.8\textwidth}
A chaque états de notre \textit{chaine de Markov} ($(1,2,3)$) est associée une valeur $\lambda_k \in \mathbb{R}_{+}^{*}$ (respectivement $(\lambda_1,\lambda_2,\lambda_3)$.

Notons $N \in \mathbb{N}$, la taille de notre portefeuille.

\textit{« On suppose que, pour chaque jour $k \in \mathbb{N}$, les dates des sinistres déclarés par l'assuré le jour $k$ suivent, conditionnellement à la valeur de $H_k$, un processus de Poisson d'intensité $\lambda_{H_k}$ »}.

\phantom{aaaaaaa}

Ainsi, nous définissons : 

\end{minipage}
\end{center}


\begin{description}

\item[\bsc{* Fonction}]

\textit{$\Delta(\omega) : $ : $\mathbb{R}_{+} \to \mathbb{R}_{+}$}

\begin{displaymath}
	\Delta : 
	\begin{cases}
		\text{$\mathbb{R}_{+} \to \mathbb{R}_{+}$}\\
		t \longmapsto \mathds{1}_{[0,365]}(t) \lambda_{H_{\lfloor t \rfloor}}
	\end{cases}
	.
\end{displaymath}


\item[\bsc{* Fonction}]

\textit{$\mu(\omega) : $ : $\mathbb{R}_{+} \to \mathbb{R}_{+}$}

\begin{displaymath}
\mu(t) = \int_{0}^{t} \Delta(x) dx = \int_{0}^{t} \mathds{1}_{[0,365]}(x) \lambda_{H_{\lfloor x \rfloor}} dx
\end{displaymath}


\item[\bsc{* Suite de processus de poisson in-homogène mélange : }]

\textit{$(R_t^{(k)})_{k \in [|1,N|]}$}

\phantom{aaaaaaa} — \textit{$(R_t^{(k)})_{k \in [|1,N|]}$, une suite de processus de poisson in-homogène mélange indépendants.}

\phantom{aaaaaaa} — \textit{$\forall (k,t) \in [|1,N|] \times \mathbb{R}_{+}$,  $R_t^{(k)} \sim P(\mu(t))$, le  processus de poisson in-homogène mélange indépendants représentant les temps d'occurrence des sinistres du contrat $k$.}

\begin{displaymath}
\forall t \in \mathbb{R}_{+} \text{, } R_t = \sum_{i=1}^{N} R_t^{(i)}
\end{displaymath}

\end{description}


\begin{displaymath}
\forall t \in [0,365] \text{, } \mu(t) = \int_{0}^{t} \Delta(x) dx = \int_{0}^{t} \mathds{1}_{[0,365]}(x) \lambda_{H_{\lfloor x \rfloor}} dx = \int_{0}^{t} \lambda_{H_{\lfloor x \rfloor}} dx
\end{displaymath}

\begin{displaymath}
= \int_{0}^{1} \lambda_{H_{\lfloor x \rfloor}} dx + \int_{1}^{2} \lambda_{H_{\lfloor x \rfloor}} dx + ... + \int_{\lfloor t \rfloor - 1}^{\lfloor t \rfloor} \lambda_{H_{\lfloor x \rfloor}} dx + \int_{\lfloor t \rfloor}^{t} \lambda_{H_{\lfloor x \rfloor}} dx
\end{displaymath}

\begin{displaymath}
= \int_{0}^{1} \lambda_{H_{0}} dx + \int_{1}^{2} \lambda_{H_{1}} dx + ... + \int_{\lfloor t \rfloor - 1}^{\lfloor t \rfloor} \lambda_{H_{\lfloor t \rfloor - 1}} dx + \int_{\lfloor t \rfloor}^{t} \lambda_{H_{\lfloor t \rfloor}} dx
\end{displaymath}

\begin{displaymath}
= \lambda_{H_{0}} + \lambda_{H_{1}} + ... + \lambda_{H_{\lfloor t \rfloor - 1}} + \int_{\lfloor t \rfloor}^{t} \lambda_{H_{\lfloor t \rfloor}} dx
\end{displaymath}


\begin{displaymath}
= \sum_{i=0}^{\lfloor t \rfloor - 1} \lambda_{H_{i}} + \lambda_{H_{\lfloor t \rfloor}} \times (t - \lfloor t \rfloor)
\end{displaymath}


\newpage
\begin{displaymath}
\forall t \in \mathbb{R}_{+} \text{, } R_t = \sum_{i=1}^{N} \underbrace{R_t^{(i)}}_{\sim P(\mu(t))} \sim P(N\times \mu(t)) \iff
\end{displaymath}

\begin{displaymath}
R_t \text{est un processus de poisson in-homogène mélange d'intensité : } \Delta^{*} = N \Delta
\end{displaymath}


\begin{center}
\begin{minipage}[r]{0.1\textwidth}

\end{minipage}
\begin{minipage}[r]{0.8\textwidth}
Il nous suffit donc de simuler une seule loi de poisson pour nos $N$ contrats.
\end{minipage}

Posons donc : $\forall t \in \mathbb{R}$, \colorbox{black!30}{$\Delta^{*}(t) = N \mathds{1}_{[0,365]}(t) \lambda_{H_{\lfloor t \rfloor}}$.}
\end{center}


\begin{center}
\begin{minipage}[r]{0.1\textwidth}

\end{minipage}
\begin{minipage}[r]{0.8\textwidth}
Cette définition a le bon gout d'être aisément majorable par une formule simple : $\theta = N \times max(\lambda_1,\lambda_2,\lambda_3)$.
\end{minipage}
\end{center}




\begin{tcolorbox}[colback=black!30,colbacklower=black!20,colframe=black!20,rightrule=1mm,arc=0mm]


\begin{center}
Montrons nous toutefois sceptiques vis a vis de notre modèle.

Partir du postulat que nos assurés partage une météo commune, n'est pas une idée totalement absurde dans l'absolue, mais reste néanmoins extrêmement discutable dans les faits. Il faudrait pour cela faire l'hypothèse que nos assurés vivent sur un même territoire et que ce territoire est assez restreint pour que sa météo reste uniforme et uni-variée.

Le modèle B, fait l'hypothèse inverse (qui est tout aussi discutable).

Notre modèle A repose sur une autre hypothèse : que l'état de la météo au jour $n$, dépends uniquement de l'état de la météo au jours $n-1$.

Nous n'expliqueront pas a quel point cette hypothèse est absurde, néanmoins la valeur d'un modèle ne se limite pas a la somme de la valeur de ses axiomes (ex : les modèles de base de la micro-économie).
\end{center}

\end{tcolorbox}


\begin{center}
\includegraphics[width=12cm,height=3.4cm]{img3}
\end{center}









\newpage
\subsection{Probabilité de Ruine Annuelle (modèle A)}

\begin{description}

\item[\bsc{* Modèle de Réserves : }]

\textit{$\forall (N, u, c) \in \mathbb{N} \times \mathbb{R}^2$, $(T_i)_{i \in \mathbb{N}^{*}}$, une suite de variables aléatoires identiquement distribuées et croissantes.}

\phantom{aaaaaaa} — \textit{On note $N$, la taille de notre portefeuille.}

\phantom{aaaaaaa} — \textit{On note $u$, l'investissement initial et individuel par assurés.}

\phantom{aaaaaaa} — \textit{On note $c$, le taux de prime par assuré et par unité de temps.}

\phantom{aaaaaaa} — \textit{On note $(T_i)_{i \in \mathbb{N}^{*}}$, la suite des dates de sinistres déclarés (de tous les assurés). La suite est par ailleurs ordonnée.}

\phantom{aaaaaaaaaaaaaaa} — \textit{$\forall t \in \mathbb{R}^{+} :$}

\[ R_t = Nu + Nct - \sum_{i=1}^{+ \infty} \mathds{1}_{[0,t]}(T_i) \text{ } X_i \]


\item[\bsc{* Partition $A$ de $[0,365]$ : }]

\textit{$\forall k \in \mathbb{N}$.}

\phantom{aaaaaaa} — \textit{$n = inf \bigl\{ k \in \mathbb{N}^{*} | T_k \in [0,365] \bigr\}$}

\begin{displaymath}
A_k =
\begin{cases}
	[0,T_1[ \text{ , si k = } 0 \\
	[T_k, T_{k+1}[ \text{ , si } k \in [|1, n-1 |] \\
	[T_n,365] \text{ , si } k = n \\
	\emptyset \text{ , sinon }
\end{cases}
\end{displaymath}


\phantom{aaaaaaaaaaaaaaa} — \textit{$(A_k)_{k \in \mathbb{N}}$ forme une partition de $[0,365]$.}
\end{description}



\begin{center}
\begin{minipage}[r]{0.1\textwidth}

\end{minipage}
\begin{minipage}[r]{0.8\textwidth}
Soit : $\forall \omega \in \Omega$, $R_t(\omega)$, est bien définie sur $[0,365]$.
On a donc : 
\end{minipage}
\end{center}

\[ \min_{t \in [0,365]} R_t(\omega) = \min_{k \in [|0,n|]} (\min_{t \in A_k} R_t(\omega)) \]


\begin{center}
\begin{minipage}[r]{0.1\textwidth}

\end{minipage}
\begin{minipage}[r]{0.8\textwidth}
Cette partition ($(A_k)_{k \in \mathbb{N}}$), nous permet d'exprimer tout minimum local ($\min_{t \in A_k} R_t(\omega)$), sous une forme explicite (plus ou moins simple) : 
\end{minipage}
\end{center}

\[ \forall (k,t) \in \mathbb{N} \times A_k, \text{ } R_t(\omega) = Nu + Nct - \sum_{i=1}^{+ \infty} \mathds{1}_{[0,t]}(T_i(\omega)) \text{ } X_i(\omega) \]

\[ = Nu + Nct - \sum_{i=1}^{k} X_i(\omega) \iff \]

\begin{displaymath}
\min_{t \in A_k} R_t(\omega) =
\begin{cases}
	Nu \text{ , si k = } 0 \\
	Nu + NcT_k(\omega) - \sum_{i=1}^{k} X_i(\omega) \text{ , si } k \in [|1, n |]
\end{cases}
\end{displaymath}



\begin{center}
\begin{minipage}[r]{0.1\textwidth}

\end{minipage}
\begin{minipage}[r]{0.8\textwidth}
, car par soucis de réalisme l'on considère (par soucis de réalisme) que $c \in \mathbb{R}_{+}^{*}.$
\end{minipage}
\end{center}




\begin{center}
\begin{minipage}[r]{0.1\textwidth}

\end{minipage}
\begin{minipage}[r]{0.8\textwidth}
Nous avons donc le résultat suivant : 
\end{minipage}
\end{center}

\[ \min_{t \in [0,365]} R_t(\omega) = Nu + \min_{k \in [|1,n|]} (NcT_k(\omega) - \sum_{i=1}^{k} X_i(\omega)) \]

\[ = Nu + \min_{k \in [|1,n|]} (\sum_{i=1}^{k} (\dfrac{NcT_k(\omega)}{k} - X_i(\omega))) \]


\begin{center}
\begin{minipage}[r]{0.1\textwidth}

\end{minipage}
\begin{minipage}[r]{0.8\textwidth}
Ce résultat nous permet de caractériser l'événement suivant :
\end{minipage}
\end{center}


\[ \left( \min_{t \in [0,365]} R_t < 0 \right) = \left( \exists k \in [|1,n|] \text{ , tel que : } \sum_{i=1}^{k} (\dfrac{NcT_k}{k} - X_i) < -Nu \right) \]

\begin{center}
\begin{minipage}[r]{0.1\textwidth}

\end{minipage}
\begin{minipage}[r]{0.8\textwidth}
Il nous suffirait donc de procédé pas a pas.
\end{minipage}
\end{center}

\[ \text{Soit } (V_j)_{j \in \mathbb{N}} \text{, une suite de v.a.i.i.d., tel que } \forall j \in \mathbb{N}, \]


\[ V_j \sim \mathbb{B}(\mathbb{P} \left( \exists k \in [|1,n|] \text{ , tel que : } \sum_{i=1}^{k} (\dfrac{NcT_k}{k} - X_i) < -Nu \right) )\]



\begin{center}
\begin{minipage}[r]{0.1\textwidth}

\end{minipage}
\begin{minipage}[r]{0.8\textwidth}
Par loi des grands nombres nous avons :
\end{minipage}
\end{center}



\[ \dfrac{1}{p} \sum_{j=1}^{p} V_j \underset{p \to +\infty}{\overset{p.s.}{\longrightarrow}} \mathbb{P}\left( \min_{t \in [0,365]} R_t < 0 \right) \]



\begin{center}
\begin{minipage}[r]{0.1\textwidth}

\end{minipage}
\begin{minipage}[r]{0.8\textwidth}
Le fait que nous ayons deux sommes (d'une part $\sum_{i=1}^{k} (\dfrac{NcT_k}{k} - X_i)$ et d'une autre $\sum_{j=1}^{p} V_j$ ), rend le problème parallélisable.
\end{minipage}
\end{center}


\begin{center}
\includegraphics[width=12cm,height=3.4cm]{img4}
\end{center}


\phantom{aaaaaaa}

\phantom{aaaaaaa}


\begin{center}
\begin{minipage}[r]{0.1\textwidth}

\end{minipage}
\begin{minipage}[r]{0.8\textwidth}

\textbf{\textit{Réduction de variance}}

\phantom{aaaaaaa}

\end{minipage}
\end{center}









\subsection{Occurrences des sinistres (modèle B)}
\subsection{Probabilité de Ruine Annuelle (modèle B)}





\newpage
\section{Commentaires sur les techniques de programmation}
\pagecolor{blue!20}



\subsection{Dépendances}
\begin{center}
\begin{minipage}[r]{0.1\textwidth}
\textcolor{black!60}{1}

\textcolor{black!60}{2}

\textcolor{black!60}{3}

\textcolor{black!60}{4}

\textcolor{black!60}{5}

\textcolor{black!60}{6}
\end{minipage}
\begin{minipage}[r]{0.82\textwidth}

\textcolor{teal}{import} random as rd

\textcolor{teal}{import} numpy as np

\textcolor{teal}{import} matplotlib.pyplot as plt \textcolor{mymauve}{\# graphics}

\textcolor{teal}{import} plotly.express as px \textcolor{mymauve}{\# graphics}

\textcolor{teal}{import} threading \textcolor{mymauve}{\# parallélisation}

\textcolor{teal}{import} bisect \textcolor{mymauve}{\# insertion dans une liste triée}

\end{minipage}
\end{center}



\subsection{$X_{norm}$}
\begin{center}
\begin{minipage}[r]{0.1\textwidth}

\end{minipage}
\begin{minipage}[r]{0.8\textwidth}
$f_{norm}$, est une fonction complexe et au vu de sa forme, il parait fort peu probable de trouver une forme explicite a son intégrale (sur un intervalle quelconque).

\phantom{aaaaaaa}

Une méthode similaire a celle de \textit{Box-Muller}, a brièvement été évoquer, sans succès.

\phantom{aaaaaaa}

« La méthode du rejet semble donc s'imposer d'elle même ? ». Il s'agit encore d'une question d'arbitrage.
Faut-il faire le choix de la meilleure des complexité, en approchant la fonction de répartition de  $X_{norm}$, par des formules explicites incorrectes, ou préférer a la complexité une juste représentation de sa loi?

\phantom{aaaaaaa}

Nous avons de prime abord opté pour l'implémentation d'une méthode de rejet dont le support serait une la loi uniforme $U([0,b])$\footnotemark[1].

De plus, la majoration suivante, apparait de façon quasi-immédiate : $f_{norm} \leq 2$.



\footnotetext[1]{La densité $f_{norm}$ étant nulle en dehors de l'intervalle $[0,b]$, il est naturel d'utiliser comme loi de proposition une uniforme sur ce même intervalle.}
\end{minipage}
\end{center}


\begin{algorithm}
\caption{Algorithme de rejet}
\begin{algorithmic}[1]
\State $i \gets True$
\While{$i$}
\State $U \gets \sim U([0,b])$
\State $Y \gets \sim U([0,2])$
\If {$Y \leq f_{norm}(U)$}
\textbf{return } $U$
\EndIf
\EndWhile
\end{algorithmic}
\end{algorithm}

\newpage
\textbf{Première approche :}




\begin{center}
\begin{minipage}[r]{0.1\textwidth}
\textcolor{black!60}{1}

\textcolor{black!60}{2}

\textcolor{black!60}{3}

\end{minipage}
\begin{minipage}[r]{0.88\textwidth}

\textcolor{teal}{def} \textcolor{blue}{f\_norm}(x : \textcolor{codegreen}{float}, x\_0 : \textcolor{codegreen}{float}, b : \textcolor{codegreen}{float}, sigma : \textcolor{codegreen}{float}, delta : \textcolor{codegreen}{float}):

\phantom{aaaa}ind = (x \textcolor{mymauve}{>=} \textcolor{codegreen}{0}) \textcolor{mymauve}{\&} (x \textcolor{mymauve}{<=} b)

\phantom{aaaa}\textcolor{teal}{return} ind\textcolor{mymauve}{*}(np.\textcolor{teal}{exp}(-((x - x0)\textcolor{mymauve}{**}\textcolor{codegreen}{2}) \textcolor{mymauve}{/} (\textcolor{codegreen}{2} \textcolor{mymauve}{*} sigma\textcolor{mymauve}{**}\textcolor{codegreen}{2})) * (\textcolor{codegreen}{1} + np.\textcolor{teal}{cos}(\textcolor{codegreen}{2}\textcolor{mymauve}{*}np.\textcolor{teal}{pi}\textcolor{mymauve}{*}(x - x0)\textcolor{mymauve}{/}delta)\textcolor{mymauve}{**}\textcolor{codegreen}{2}))

\end{minipage}
\end{center}







\begin{center}
\begin{minipage}[r]{0.1\textwidth}
\textcolor{black!60}{1}

\phantom{aa}

\textcolor{black!60}{2}

\textcolor{black!60}{3}

\textcolor{black!60}{4}

\textcolor{black!60}{5}

\textcolor{black!60}{6}

\textcolor{black!60}{7}

\textcolor{black!60}{8}

\end{minipage}
\begin{minipage}[r]{0.88\textwidth}

\textcolor{teal}{def} \textcolor{blue}{echantillon\_f\_norm}(x\_0 : \textcolor{codegreen}{float}, b : \textcolor{codegreen}{float}, sigma : \textcolor{codegreen}{float}, delta : \textcolor{codegreen}{float}, n : \textcolor{codegreen}{int}):

\phantom{aaaa}res \textcolor{mymauve}{=} $[]$

\phantom{aaaa}\textcolor{teal}{while len}(res) \textcolor{mymauve}{<} n:

\phantom{aaaaaaaa}X \textcolor{mymauve}{=} np.\textcolor{teal}{random.uniform}(\textcolor{codegreen}{0}, b) \textcolor{mymauve}{\# \textit{f\_norm est nulle sur [b,inf]}}

\phantom{aaaaaaaa}Y \textcolor{mymauve}{=} np.\textcolor{teal}{random.uniform}(\textcolor{codegreen}{0}, M)

\phantom{aaaaaaaa}\textcolor{teal}{if} Y \textcolor{mymauve}{<=} f\_norm(X,x0,b,sigma,delta):

\phantom{aaaaaaaaaaaa}res.\textcolor{teal}{append}(X) \textcolor{mymauve}{\# \textit{condition d'acceptation}}

\phantom{aaaa}\textcolor{teal}{return} res
\end{minipage}
\end{center}

\phantom{aaaa}

\textbf{Deuxième approche :}
\begin{center}
\begin{minipage}[r]{0.1\textwidth}

\end{minipage}
\begin{minipage}[r]{0.8\textwidth}
Conscients que
cette méthode n'est sans doute pas la plus efficace au vue de la forme de $f_{norm}$ nous avons donc opté pour une seconde méthode.

La loi $\mathbb{P}_{norm}$ étant très proches d'une loi normale, nous avons pensé à faire une méthode de rejet vis a vis de cette dernière.

\phantom{aaaa}

Nous avons donc majoré le rapport $\dfrac{f_{norm}}{g}$, avec $g$ la densité d'une loi normale.

Cela garantit une meilleure efficacité du rejet : la probabilité d'acceptation augmente, et donc le
nombre moyen d'itérations\footnotemark[1] pour accepter un point diminue.

\footnotetext[1]{Qui fut précédemment de l'ordre de $2b$.}
\end{minipage}
\end{center}




\begin{algorithm}
\caption{Algorithme de rejet}
\begin{algorithmic}[1]
\State $i \gets True$
\While{$i$}
\State $U \gets \sim $ loi de densité $g$
\State $Y \gets \sim U([0,M])$
\If {$Y \times g(U) \leq f(U)$}
\textbf{return } $U$
\EndIf
\EndWhile
\end{algorithmic}
\end{algorithm}

\textbf{Nouvelle approche :}



\begin{center}
\begin{minipage}[r]{0.1\textwidth}
\textcolor{black!60}{1}

\textcolor{black!60}{2}

\end{minipage}
\begin{minipage}[r]{0.88\textwidth}

\textcolor{teal}{def} \textcolor{blue}{g}(x : \textcolor{codegreen}{float}, x\_0 : \textcolor{codegreen}{float}, sigma : \textcolor{codegreen}{float}):

\phantom{aaaa}ind = (x \textcolor{mymauve}{>=} \textcolor{codegreen}{0}) \textcolor{mymauve}{\&} (x \textcolor{mymauve}{<=} b)

\phantom{aaaa}\textcolor{teal}{return} (\textcolor{codegreen}{1} \textcolor{mymauve}{/} (np.\textcolor{teal}{sqrt}(\textcolor{codegreen}{2}\textcolor{mymauve}{*}np.\textcolor{teal}{pi})\textcolor{mymauve}{*}sigma)) \textcolor{mymauve}{*} np.\textcolor{teal}{exp}(-((x - x0)\textcolor{mymauve}{**}\textcolor{codegreen}{2}) \textcolor{mymauve}{/} (\textcolor{codegreen}{2} \textcolor{mymauve}{*} sigma\textcolor{mymauve}{**}\textcolor{codegreen}{2}))

\end{minipage}
\end{center}





\begin{center}
\begin{minipage}[r]{0.1\textwidth}
\textcolor{black!60}{1}

\phantom{aa}

\textcolor{black!60}{2}

\textcolor{black!60}{3}

\textcolor{black!60}{4}

\textcolor{black!60}{5}

\textcolor{black!60}{6}

\textcolor{black!60}{7}

\textcolor{black!60}{8}

\textcolor{black!60}{9}

\end{minipage}
\begin{minipage}[r]{0.88\textwidth}

\textcolor{teal}{def} \textcolor{blue}{echantillon\_f\_norm\_opt}(x\_0 : \textcolor{codegreen}{float}, b : \textcolor{codegreen}{float}, sigma : \textcolor{codegreen}{float}, delta : \textcolor{codegreen}{float}, n : \textcolor{codegreen}{int}):

\phantom{aaaa}M \textcolor{mymauve}{=} \textcolor{codegreen}{2}\textcolor{mymauve}{*}np.\textcolor{teal}{sqrt}(\textcolor{codegreen}{2}\textcolor{mymauve}{*}np.\textcolor{teal}{pi})\textcolor{mymauve}{*}sigma

\phantom{aaaa}res \textcolor{mymauve}{=} $[]$

\phantom{aaaa}\textcolor{teal}{while len}(res) \textcolor{mymauve}{<} n:

\phantom{aaaaaaaa}X \textcolor{mymauve}{=} np.\textcolor{teal}{random.normal}(\textcolor{codegreen}{x0}, sigma)

\phantom{aaaaaaaa}Y \textcolor{mymauve}{=} np.\textcolor{teal}{random.uniform}(\textcolor{codegreen}{0}, M)

\phantom{aaaaaaaa}\textcolor{teal}{if} Y\textcolor{mymauve}{*}g(X,x0,sigma) <= f\_norm(X,x0,b,sigma,delta):

\phantom{aaaaaaaaaaaa}res.\textcolor{teal}{append}(X) \textcolor{mymauve}{\# \textit{condition d'acceptation}}

\phantom{aaaa}\textcolor{teal}{return} res
\end{minipage}
\end{center}





\subsection{$X_{puissance}$}
\begin{center}
\begin{minipage}[r]{0.1\textwidth}

\end{minipage}
\begin{minipage}[r]{0.8\textwidth}
Cette partie sera relativement succincte. Les causes de cette concision sont doubles : 

\phantom{aaaa}— Premièrement car tous les calculs ont déjà été traités dans la partie \hyperlink{ref1}{\textcolor{blue}{\textbf{\textit{Modélisation}}}}.
 
\phantom{aaaa}— Deuxièmement car le code qui y est associé est lui même relativement succin.

La complexité est ici en temps constant et nous voyons mal comment optimiser ce code sans passer par un \textit{interfacage c++}.
\end{minipage}
\end{center}



\textbf{Le code dans toute sa beauté fonctionnelle :}

\begin{center}
\begin{minipage}[r]{0.1\textwidth}
\textcolor{black!60}{1}

\textcolor{black!60}{2}

\end{minipage}
\begin{minipage}[r]{0.88\textwidth}

\textcolor{teal}{def} \textcolor{blue}{run\_loi\_de\_puissance}():

\phantom{aaaa}\textcolor{teal}{return} a\textcolor{mymauve}{*}(1 - rd.\textcolor{teal}{random}())\textcolor{mymauve}{**}(1\textcolor{mymauve}{/}(1-alpha))
\end{minipage}
\end{center}



\subsection{$Z$}



\subsection{$X$}




\subsection{Vérifications d'usage}
\section{Les différents modèles}
\subsection{Complexité algorithmique}
\subsection{Implémentation CuPy}


\part{Conclusion}
\section{Commentaires sur la pertinence du modèle}
\section{Évolutions possibles du modèle}
\begin{center}
\begin{minipage}[r]{0.1\textwidth}

\end{minipage}
\begin{minipage}[r]{0.8\textwidth}

Interfaçage avec d'autres langages peut-être plus performants : R, C++

NB : vérifier que R soit plus performant que python.

\end{minipage}
\end{center}
\section{Commentaires}
\section{Annexes et contacts}

\subsection*{Annexes et contacts}



\begin{center}
\begin{minipage}[r]{0.4\textwidth}

\end{minipage}
\begin{minipage}[r]{0.4\textwidth}


\end{minipage}
\end{center}






\end{document}